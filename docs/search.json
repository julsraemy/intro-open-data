[
  {
    "objectID": "why-open-data-matters.html#public-engagement-and-empowerment",
    "href": "why-open-data-matters.html#public-engagement-and-empowerment",
    "title": "Why Open Data Matters",
    "section": "Public Engagement and Empowerment",
    "text": "Public Engagement and Empowerment\n\n\nEmpowering the Public\n\nAccess to previously inaccessible information\nDemocratisation of knowledge\n\n\nActive Participation\n\nMore informed citizenry\nEnables civic and cultural discourse\n\n\n\nOpen data fundamentally changes the relationship between institutions and the public by making information accessible to everyone."
  },
  {
    "objectID": "why-open-data-matters.html#transparency-and-accountability",
    "href": "why-open-data-matters.html#transparency-and-accountability",
    "title": "Why Open Data Matters",
    "section": "Transparency and Accountability",
    "text": "Transparency and Accountability\n\n\nBuilding Trust\n\nCritical in sectors requiring public trust\nFree accessibility enables scrutiny\n\n\nBetter Governance\n\nGreater analysis capabilities\nMore accountable practices\nInstitutional transparency\n\n\n\nTransparency through open data creates accountability mechanisms that benefit both institutions and society."
  },
  {
    "objectID": "why-open-data-matters.html#the-evolution-of-open-data",
    "href": "why-open-data-matters.html#the-evolution-of-open-data",
    "title": "Why Open Data Matters",
    "section": "The Evolution of Open Data",
    "text": "The Evolution of Open Data\n\nOpen Data: A commendable starting point\nLinked Open Data: Interconnected and discoverable\nLinked Open Usable Data (LOUD): Enhanced usability and semantic interoperability; Community-driven standards and practices\n\n\nOpen data has evolved from simple availability to sophisticated interconnected systems that maximise usability."
  },
  {
    "objectID": "why-open-data-matters.html#ogd-and-ord-for-glam-galleries-libraries-archives-museums",
    "href": "why-open-data-matters.html#ogd-and-ord-for-glam-galleries-libraries-archives-museums",
    "title": "Why Open Data Matters",
    "section": "OGD and ORD for GLAM (Galleries, Libraries, Archives, Museums)",
    "text": "OGD and ORD for GLAM (Galleries, Libraries, Archives, Museums)\nOpen Government Data (OGD) & Open Research Data (ORD)\n\n\nDual Nature\n\nService to the public\nActive management process\n\n\nGLAM Applications\n\nResearch contributions\nCuration practices\nPublic engagement\n\n\n\nGLAM institutions play a crucial role in both producing and using open data for cultural heritage preservation and access."
  },
  {
    "objectID": "why-open-data-matters.html#ai-and-machine-learning",
    "href": "why-open-data-matters.html#ai-and-machine-learning",
    "title": "Why Open Data Matters",
    "section": "AI and Machine Learning",
    "text": "AI and Machine Learning\n\nTraining Data: Large, diverse datasets for robust AI models\nInclusive Development: High-quality open datasets enable better AI\nTransparency: External validation of AI systems\nEthics: Reducing biases through openness\nGrounding Truth: Open data provides verifiable sources for fact-checking AI outputs\n\n\nOpen data can be the foundation for responsible AI\n\n\nThe relationship between open data and AI is symbiotic - good AI requires good data, and open data ensures AI development is transparent and ethical. Open data also helps ground AI outputs in verifiable reality."
  },
  {
    "objectID": "why-open-data-matters.html#collaboration-is-key",
    "href": "why-open-data-matters.html#collaboration-is-key",
    "title": "Why Open Data Matters",
    "section": "Collaboration is Key",
    "text": "Collaboration is Key\n\n\nBest Practices\n\nCollections as Data checklist\nCommunity-driven standards\nShared resources\n\n\nCommunities\n\nIIIF (International Image Interoperability Framework)\nLinked Art\nOGD meet-ups (Open Data Beer)\n\n\n\nOpen data is not just about availability—it’s about creating value through accessibility, interoperability, and collaboration.\n\n\nCollaboration across institutions and communities is essential for developing and maintaining effective open data practices."
  },
  {
    "objectID": "sections/techniques.html",
    "href": "sections/techniques.html",
    "title": "Techniques, Software, and Tools",
    "section": "",
    "text": "Data scraping is the automated process of extracting information from websites or other online sources. This technique can be useful for collecting data from multiple sites and automating repetitive tasks. However, challenges include adapting to changes in website layouts, legal and ethical issues, and handling dynamic content (e.g. data loaded via JavaScript). For example, Python libraries such as Beautiful Soup or frameworks like Scrapy are frequently used for these purposes.\n\n\n\nAPI integration involves connecting to external services in order to retrieve structured data, often in real time. This method provides standardised data access and can streamline automated processes. Nevertheless, it requires managing API rate limits, adapting to changes in the API, and integrating data from various systems.\n\n\n\nData mining refers to the analysis of large datasets to identify patterns, correlations, and trends. This process can support data-driven decision-making, though it requires significant computational resources and expertise, and may also raise privacy concerns. Software such as RapidMiner and WEKA is commonly used in this field.\n\n\n\nData wrangling (or data munging) is the process of cleaning, transforming, and organising raw data into a structured format that is suitable for analysis. Although this process can be time-consuming and technically challenging, it is essential for improving data quality. Python’s pandas library is a widely used tool in this area.\n\n\n\nData integration involves combining data from different sources to create a unified dataset. This technique helps provide a comprehensive view for analysis but may involve challenges such as reconciling differing formats and schemas, and ensuring consistent data quality.\n\n\n\nStream processing refers to analysing data in real time as it is generated. This technique is especially useful for handling time-sensitive data and high volumes of information. Tools such as Apache Kafka and Apache Flink are commonly used to manage data flows and enable real-time analytics.\n\n\n\nData quality management is the process of ensuring that data is accurate, complete, and consistent. High-quality data is critical for reliable analysis, although maintaining such quality requires ongoing monitoring and may be resource-intensive.\n\n\n\nETL stands for Extract, Transform, Load and describes the process of extracting data from various sources, transforming it into a standard format, and loading it into a target system for analysis. This approach supports data consolidation but also poses challenges in maintaining transformation accuracy and managing diverse data sources.",
    "crumbs": [
      "Techniques, Software, and Tools"
    ]
  },
  {
    "objectID": "sections/techniques.html#techniques",
    "href": "sections/techniques.html#techniques",
    "title": "Techniques, Software, and Tools",
    "section": "",
    "text": "Data scraping is the automated process of extracting information from websites or other online sources. This technique can be useful for collecting data from multiple sites and automating repetitive tasks. However, challenges include adapting to changes in website layouts, legal and ethical issues, and handling dynamic content (e.g. data loaded via JavaScript). For example, Python libraries such as Beautiful Soup or frameworks like Scrapy are frequently used for these purposes.\n\n\n\nAPI integration involves connecting to external services in order to retrieve structured data, often in real time. This method provides standardised data access and can streamline automated processes. Nevertheless, it requires managing API rate limits, adapting to changes in the API, and integrating data from various systems.\n\n\n\nData mining refers to the analysis of large datasets to identify patterns, correlations, and trends. This process can support data-driven decision-making, though it requires significant computational resources and expertise, and may also raise privacy concerns. Software such as RapidMiner and WEKA is commonly used in this field.\n\n\n\nData wrangling (or data munging) is the process of cleaning, transforming, and organising raw data into a structured format that is suitable for analysis. Although this process can be time-consuming and technically challenging, it is essential for improving data quality. Python’s pandas library is a widely used tool in this area.\n\n\n\nData integration involves combining data from different sources to create a unified dataset. This technique helps provide a comprehensive view for analysis but may involve challenges such as reconciling differing formats and schemas, and ensuring consistent data quality.\n\n\n\nStream processing refers to analysing data in real time as it is generated. This technique is especially useful for handling time-sensitive data and high volumes of information. Tools such as Apache Kafka and Apache Flink are commonly used to manage data flows and enable real-time analytics.\n\n\n\nData quality management is the process of ensuring that data is accurate, complete, and consistent. High-quality data is critical for reliable analysis, although maintaining such quality requires ongoing monitoring and may be resource-intensive.\n\n\n\nETL stands for Extract, Transform, Load and describes the process of extracting data from various sources, transforming it into a standard format, and loading it into a target system for analysis. This approach supports data consolidation but also poses challenges in maintaining transformation accuracy and managing diverse data sources.",
    "crumbs": [
      "Techniques, Software, and Tools"
    ]
  },
  {
    "objectID": "sections/techniques.html#softwaretools",
    "href": "sections/techniques.html#softwaretools",
    "title": "Techniques, Software, and Tools",
    "section": "Software/Tools",
    "text": "Software/Tools\nBelow is a summary table that presents some key software tools, outlining their main functions and providing examples of typical deployments or customers.\n\n\n\n\n\n\n\n\nTool\nPurpose & Function\nExample Deployments/Customers\n\n\n\n\nCKAN\nData management system for building and maintaining data hubs and portals.\nUsed in government open data portals such as data.gov.uk, data.gov, and various international bodies.\n\n\nPiveau\nPlatform for metadata management, data harmonisation, and linked data.\nDeployed in several European open data initiatives.\n\n\nEntryScape\nEnables semantic integration and linked data for complex datasets.\nMainly adopted by Swedish public organisations.\n\n\nuData\nFacilitates the publication and management of open datasets.\nEmployed by municipalities and local governments for open data portals.\n\n\nOpenRefine\nTool for cleaning, transforming, and reconciling messy data.\nWidely used in academic research, journalism, and by data professionals.\n\n\nLOMAS\nAllows secure processing of sensitive data with Differential Privacy.\nPiloted within the Swiss public sector to enable secondary data usage while preserving privacy.\n\n\n\n\nCKAN\nCKAN is an open source data management system developed by the Open Knowledge Foundation. It is designed to support the creation and maintenance of data hubs and portals, offering a standardised platform for publishing and accessing datasets. CKAN employs a PostgreSQL database, a Solr index, and a comprehensive API to facilitate data discovery and integration (see its GitHub repository for more technical information). It has been deployed widely in national and local government open data portals (for example, data.gov.uk and data.gov), as well as by various international organisations\n\n\nPiveau\nPiveau is an open data platform comprising several integrated components that focus on the management and integration of open data, with a particular emphasis on metadata management, data harmonisation, and linked data capabilities (Kirstein et al., 2020). It supports a wide range of data protocols and formats—including OAI-PMH, RDF, CKAN, uData, OwnCloud, JSON, SPARQL, Socrata, and Drupal—allowing for dynamic, programmable data transformation using JavaScript or XSLT. Harvesting processes can be individually scheduled, and the platform provides export capabilities into DCAT(-AP) and related standards.\nKey features include:\n\nData Acquisition and Transformation:\nPiveau supports scalable harvesting (up to hundreds of thousands of datasets per source) and flexible, configuration-based orchestration, enabling custom processing steps and integration with third-party services.\nLinked Data and Storage:\nIt stores DCAT metadata as RDF in a triplestore and utilises URI harmonisation to create a consistent knowledge graph. The platform also integrates external vocabularies and ontologies to enhance linked data capabilities.\nSearch and Frontend:\nA powerful search engine based on Elasticsearch and a rich, customisable, multilingual frontend allow users to efficiently search and filter metadata. Additionally, extensive backend tools facilitate the creation and management of metadata.\nQuality Assurance:\nPiveau periodically generates quality assessments based on SHACL validations. These assessments are stored alongside the metadata using the Data Quality Vocabulary (DQV), with reports available in various formats.\nAccess Control and Operations:\nIntegration with Keycloak provides robust identity and access management, while containerisation with Docker and support for Kubernetes (with ready-to-use Helm charts) ensure efficient operations. The backends are primarily written in Java and Kotlin (using the Vert.x framework), and the frontends are developed with Vue.js.\n\nPiveau is open source and its code is available on GitLab. Below is an overview of its architecture.\n\nhttps://doc.piveau.io/general/basic-architecture/\n\n\nEntryScape\nEntryScape is an information management platform developed by Metasolutions to handle complex datasets through semantic integration and linked data principles (Ebner & Palmér, 2014). It facilitates the organisation and enrichment of heterogeneous data sources, making it easier to create interoperable and semantically rich datasets.\nIts customers include a broad range of public organisations such as municipalities, regional authorities, and national agencies. For example, in Sweden, EntryScape is used by national agencies like Skatteverket or Riksarkivet. Further information is available on the EntryScape website and via its repository on Bitbucket.\n\n\nuData\nuData is an open data management platform developed by the Open Data Team. It aims to simplify the publication and management of data, offering a user-friendly interface that makes it accessible for both data providers and users. uData is often employed by municipalities and local governments to publish open data portals, and its modular architecture allows for easy integration with existing IT infrastructures. The source code is available on its GitHub repository.\n\n\nOpenRefine\nOpenRefine is an open source tool for data cleaning and transformation. Initially released in 2010 (originally as Freebase Gridworks, later renamed Google Refine), it operates as a local web application designed to help users clean messy data, standardise formats, and reconcile datasets. It supports various data formats (including CSV, TSV, JSON, and XML) and allows for advanced data manipulation using scripting languages such as GREL and Jython. For more details, see the GitHub repository.\n\n\nLOMAS\nLOMAS is an open source platform developed by the Data Science Competence Center (DSCC) of the Swiss Federal Statistical Office. Public services collect large volumes of data, yet strict privacy regulations often limit their secondary use. LOMAS addresses this challenge by enabling authorised users—such as approved researchers and government analysts—to execute algorithms on sensitive datasets without directly accessing the data. Instead, users submit algorithms to the platform, which then processes the data within a secure, trusted computing environment. The results are returned protected by Differential Privacy, a framework that introduces controlled noise to prevent the extraction of identifiable information. This approach allows for the quantification and control of disclosure risk while ensuring transparency about data protection (see Aymon et al., 2024).",
    "crumbs": [
      "Techniques, Software, and Tools"
    ]
  },
  {
    "objectID": "sections/principles.html",
    "href": "sections/principles.html",
    "title": "Associated Principles",
    "section": "",
    "text": "NoteSlide Presentation\n\n\n\nMost of the following content can be found in presentation format: Associated Movements and Principles (slides 89-161). Please note this is the 2024 version of the course and will not be kept updated.",
    "crumbs": [
      "Associated Principles"
    ]
  },
  {
    "objectID": "sections/principles.html#fair-data-principles",
    "href": "sections/principles.html#fair-data-principles",
    "title": "Associated Principles",
    "section": "FAIR Data Principles",
    "text": "FAIR Data Principles\n\nhttps://www.go-fair.org/fair-principles/ (Wilkinson et al., 2016)\n\nFindable\n\nF1. (Meta)data are assigned a globally unique and persistent identifier\nF2. Data are described with rich metadata (defined by R1)\nF3. Metadata clearly and explicitly include the identifier of the data they describe\nF4. (Meta)data are registered or indexed in a searchable resource\n\n\n\nAccessible\n\nA1. (Meta)data are retrievable by their identifier using a standardised communications protocol\n\nA1.1 The protocol is open, free, and universally implementable\nA1.2 The protocol allows for an authentication and authorisation procedure, where necessary\n\nA2. Metadata are accessible, even when the data are no longer available\n\n\n\nInteroperable\n\nI1. (Meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation.\nI2. (Meta)data use vocabularies that follow FAIR principles\nI3. (Meta)data include qualified references to other (meta)data\n\n\n\nReusable\n\nR1. (Meta)data are richly described with a plurality of accurate and relevant attributes\n\nR1.1. (Meta)data are released with a clear and accessible data usage license\nR1.2. (Meta)data are associated with detailed provenance\nR1.3. (Meta)data meet domain-relevant community standards",
    "crumbs": [
      "Associated Principles"
    ]
  },
  {
    "objectID": "sections/principles.html#care-principles-for-indigenous-data-governance",
    "href": "sections/principles.html#care-principles-for-indigenous-data-governance",
    "title": "Associated Principles",
    "section": "CARE Principles for Indigenous Data Governance",
    "text": "CARE Principles for Indigenous Data Governance\n\nCarroll et al. (2020)\n\nCollective Benefit\n\nC1. For inclusive development and innovation\nC2. For improved governance and citizen engagement\nC3. For equitable outcomes\n\n\n\nAuthority to Control\n\nA1. Recognizing rights and interests\nA2. Data for governance\nA3. Governance of data\n\n\n\nResponsibility\n\nR1. For positive relationships\nR2. For expanding capability and capacity\nR3. For Indigenous languages and worldviews\n\n\n\nEthics\n\nE1. For minimizing harm and maximizing benefit\nE2. For justice\nE3. For future use\n\n\n\nCARE and FAIR\n\nCarroll et al. (2021)",
    "crumbs": [
      "Associated Principles"
    ]
  },
  {
    "objectID": "sections/principles.html#collections-as-data",
    "href": "sections/principles.html#collections-as-data",
    "title": "Associated Principles",
    "section": "Collections as Data",
    "text": "Collections as Data\n\n\nSummits\n\n2017: Santa Barbara Statement (Padilla et al., 2017)\n2023: Vancouver Statement (Padilla, Scates Kettler, Varner, et al., 2023)\n\n\n\nMain outputs\n\n10 principles\n‘Part to Whole’ Report\nRelated checklist and initiatives\n\nhttps://collectionsasdata.github.io/statement/\n\n\n10 Principles\n\nCollections as Data development aims to encourage computational use of digitised and born digital collections.\nCollections as Data stewards are guided by ongoing ethical commitments.\nCollections as Data stewards aim to lower barriers to use.\nCollections as Data designed for everyone serve no one.\nShared documentation helps others find a path to doing the work.\nCollections as Data should be made openly accessible by default, except in cases where ethical or legal obligations preclude it.\nCollections as Data development values interoperability.\nCollections as Data stewards work transparently in order to develop trustworthy, long-lived collections.\nData as well as the data that describe those data are considered in scope.\nThe development of collections as data is an ongoing process and does not necessarily conclude with a final version.\n\n\n\nPart to Whole\n\nBoundary Object Concept: Collections-as-data serve as flexible tools adaptable to various needs while maintaining a common identity (see Star & Griesemer, 1989).\nEthical Considerations: Emphasis on ethical development and use of collections, especially concerning marginalized communities.\nCommunity Engagement: Essential for respecting and understanding the context of collections.\nOrganisational Structure Support: Effective initiatives require collaboration across various organisational departments.\nDocumentation Importance: Crucial for understanding and maintaining collections in the future.\nCommunity of Practice: Emphasises the need for skill sharing and collaborative environments.\nFuture Challenges and Opportunities\n\nIntegration of AI and computational tools in collections.\nNavigating the balance between global collaboration and local cultural sensitivities.\nAddressing financial and resource limitations for global community growth.\nPotential and risks of using collections as data for AI training.\n\n\nPadilla, Scates Kettler, & Shorish (2023)\n\n\nChecklist to publish Collections as Data in GLAM institutions\n\nProvide a clear license allowing reuse of the dataset without restrictions\nProvide a suggestion of how to cite your dataset\nInclude documentation about the dataset\nUse a public platform to publish the dataset\nShare examples of use as additional documentation\nGive structure to the dataset\nProvide machine-readable metadata (about the dataset itself)\nInclude your dataset in collaborative edition platforms\nOffer an API to access your repository\nDevelop a portal page\nAdd a terms of use\n\nCandela et al. (2023)\n\n\nWorkflow\n\nhttps://marketplace.sshopencloud.eu/workflow/I3JvP6\n\n\nImplementation at the Royal Library of Belgium\n\nData-level access to collections\nDigital Humanities Research\n\n\nhttps://www.kbr.be/en/projects/data-kbr-be/",
    "crumbs": [
      "Associated Principles"
    ]
  },
  {
    "objectID": "sections/principles.html#linked-open-usable-data",
    "href": "sections/principles.html#linked-open-usable-data",
    "title": "Associated Principles",
    "section": "Linked (Open) (Usable) Data",
    "text": "Linked (Open) (Usable) Data\n\nAn Open Vision of the Web\n\nThe [World Wide Web] project merges the techniques of information retrieval and hypertext to make an easy but powerful global information system. The project started with the philosophy that much academic information should be freely available to anyone.\n\nBerners-Lee (1991)\n\n\nLinked Data\nLinked Data refers to a method of publishing structured data so that it can be interlinked and become more useful through semantic queries. It builds upon standard Web technologies such as HTTP, RDF, and URIs, but rather than using them to serve web pages for human readers, it extends them to share information in a way that can be read automatically by computers. This enables data from different sources to be connected and queried.\n\n\nLinked Data Principles\n\nUse Uniform Resource Identifiers (URIs) as names for things\nUse HTTP URIs so that people can look up those names.\nWhen someone looks up a URI, provide useful information, using the standards (e.g. RDF, RDFS, SPARQL, etc.)\nInclude links to other URIs so that they can discover more things.\n\nBerners-Lee (2006)\n\n\nLinked Open Data (LOD)\nLinked Open Data is a subset of Linked Data that is open, meaning it is freely accessible and reusable by anyone. It adheres to the principles of being accessible under an open license, available in a machine-readable format, using open standards from the W3C (such as RDF and SPARQL), and linked to other datasets to increase its utility.\n\n5-star deployment scheme for Open Data: https://5stardata.info/\n\n\nThe Semantic Web or the Web of Data\nThe Semantic Web is an extension of the World Wide Web, through standards, to make it machine-readable.\n\nIdehen (2017)\n\n\nResource Description Framework (RDF)\nWith RDF, everything goes in threes. Most of the triples’ components have Uniform Resource Identifiers (URIs).  Syntax: subject, predicate, object \\((s \\ \\vec{p} \\ o)\\)\n\nWith RDF, everything goes in threes, the data model contains so-called triples: that is subject, predicate, object that form graphs. Most of the components of these triples use Uniform Resource Identifiers (URIs) and are generally web-addressable, whether for naming subjects and objects (which may themselves also be objects of other triples) or relationships\n\n\nLinked Open Usable Data (LOUD)\nThe concept of LOUD extends LOD by emphasising not just the openness and interlinking of data but also its usability.\n\nThe term was coined by Robert Sanderson (2018, 2019) who has been involved in the conception and maintenance of web standards, mainly in the cultural heritage field.\nLOUD’s goal is to achieve the Semantic Web’s intent on a global scale in a usable fashion by leveraging community-driven and JSON-LD-based specifications.\nIt has five main design principles to make the data more easily accessible to software developers, who play a key role in interacting with the data and building software and services on top of it, and to some extent to academics.\n\n\nLOUD Design Principles\n\nThe right Abstraction for the audience\nFew Barriers to entry\nComprehensible by introspection\nDocumentation with working examples\nFew Exceptions, instead many consistent patterns\n\nhttps://linked.art/loud/\n\n\nLOUD Standards/Communities\n\nInternational Image Interoperability Framework (IIIF)\nW3C Web Annotation Data Model\nLinked Art\n\nThe IIIF and Linked Art communities are built on a synergy of social and technical integration, with a strong focus on usability. They are unified by shared expertise and leadership, fostering collaboration across technical boundaries. These communities prioritise inclusivity and diversity of participation, ensuring that a wide range of perspectives contribute to their work. Openness and friendliness are core values, along with a strong commitment to transparency in processes and decision-making. To facilitate engagement and knowledge sharing, they organise both online and face-to-face meetings to strengthen connections across the community.\n(see Newbury, 2018; Raemy, 2023)\n\nInternational Image Interoperability Framework (IIIF)\n\nA model for presenting and annotating content\nA global community that develops shared application programming interfaces (APIs), implements them in software, and exposes interoperable content\n\nSnydman et al. (2015)\n\n \n\n\nIIIF Community\nhttps://bit.ly/iiifmap\n\nState and National Libraries: Bavarian State Library, French National Library (BnF), British Library, National Library of Estonia, New York Public Library, Vatican Library, Zentralbibliothek Zürich, etc.\nArchives: Blavatnik Foundation Archive, Indigenous Digital Archive, Internet Archive, Swedish National Archives, Swiss Federal Archives, etc.\nMuseums & Galleries: Art Institute Chicago, J. Paul Getty Trust, Smithsonian, Victoria & Albert Museum, MIT Museum, National Gallery of Art, Van Gogh Worldwide, etc.\nUniversities & Research Institutions: Cambridge, Cornell University, Ghent University, Swiss National Data and Service Center for the Humanities (DaSCH), Kyoto University, Oxford, Stanford, University of Toronto, Yale University, etc.\nAggregators/Facilitators: Europeana, Cuba-IIIF, Cultural Japan, OCLC ContentDM, etc.\n\n\n\nPractices\n\nRaemy (2024)\n\n\nCapabilities\nDeep zoom with large images\n\nŌmi Kuni-ezu – 近江國絵圖 https://purl.stanford.edu/hs631zg4177\nCompare images\n\nLetter from Alexander Hamilton Papers (September 6, 1780), Library of Congress. https://prtd.app/#72f604db-6869-4c08-91ce-7c79502a7f35. IIIF Manifest: https://dvp.prtd.app/hamilton/manifest.json\nReunify\n\nManuscrit reconstitué : Châteauroux, Bibliothèque municipale, ms. 5 (Grandes Chroniques de France). https://demos.biblissima.fr/chateauroux/demo/\nSearch within\n\nFranks, Kendal; Royal College of Surgeons of England. The Germ Theory. via Wellcome Library.\nStorytelling\n\nStoriiies. https://www.cogapp.com/r-d/storiiies\nCrowdsource\n\nCrowdsourcing initiative from the National Library of Wales\nMachine-generated annotations\n\n(see cornutAnnotationsKnowledgePractices2023?)\nIIIF – Beyond Images\n\nhttps://ddmal.ca/IIIF-AV-player/\nLayers of digitisation\n\nLeiden Collection’s Curtain Viewer. https://www.theleidencollection.com/viewer/david-and-uriah/\n\n\nIIIF Specifications\n\n\n\n\n\n\n\nApplication programming interface (API)\nDescription\n\n\n\n\nImage API\nThe IIIF Image API specifies a web service that returns an image in response to a standard HTTP(S) request. The URI can specify the region, size, rotation, quality characteristics and format of the requested image.\n\n\nPresentation API\nThe IIIF Presentation API provides the information necessary to allow a rich, online viewing environment for compound digital objects to be presented to a human user, often in conjunction with the IIIF Image API.\n\n\nAuthorization Flow API\nThe IIIF Authorization Flow specification describes a set of workflows for guiding the user through an existing access control system.\n\n\nChange Discovery API\nThe IIIF Change Discovery API provides the information needed to discover and make use of IIIF resources.\n\n\nContent Search API\nThe IIIF Content Search API specification lays out the interoperability mechanism for performing searches of text annotations associated with an object within the IIIF context.\n\n\nContent State API\nThe IIIF Content State API provides a way to refer to a IIIF Presentation API resource, or a part of a resource, in a compact format that can be used to initialize the view of that resource in any client.\n\n\n\nhttps://iiif.io/api\nThe Image and Presentation APIs are referred to as the core IIIF APIs\n\nIIIF Image API\n\n\n\n\nType\nSyntax\nExample\n\n\n\n\nBase URI\n{scheme}://{server}{/prefix}/{identifier}\nhttps://iiif.dasch.swiss/0812/276uIbjSulF-k5RrtYZ3LUA.jpx\n\n\nImage Request\n{$BASE}/{region}/{size}/{rotation}/{quality}.{format}\nhttps://iiif.dasch.swiss/0812/276uIbjSulF-k5RrtYZ3LUA.jpx/full/1000,/0/default.jpg\n\n\nImage Information (Metadata)\n{$BASE}/info.json\nhttps://iiif.dasch.swiss/0812/276uIbjSulF-k5RrtYZ3LUA.jpx/info.json\n\n\n\nIIIF Presentation API\nPresentation API Data Model\n\nMain types\n\nManifest\n{\n  \"@context\": \"http://iiif.io/api/presentation/3/context.json\",\n  \"id\": \"https://manifests.collections.yale.edu/yuag/obj/293797\",\n  \"type\": \"Manifest\",\n  \"label\": {\n    \"en\": [\n      \"Simon de Vlieger, Fisherfolk and Other Figures on a Beach, 1642\"\n    ]\n  },\n  \"metadata\": [\n    {\n      \"label\": {\n        \"en\": [\n          \"Copyright Statement\"\n        ]\n      },\n      \"value\": {\n        \"en\": [\n          \"Public Domain\"\n        ]\n      }\n    },\n    {\n      \"label\": {\n        \"en\": [\n          \"Title\"\n        ]\n      },\n      \"value\": {\n        \"en\": [\n          \"Fisherfolk and Other Figures on a Beach\"\n        ]\n      }\n    },\n    {\n      \"label\": {\n        \"en\": [\n          \"Creator(s)\"\n        ]\n      },\n      \"value\": {\n        \"en\": [\n          \"Artist: Simon de Vlieger (Dutch, 1601–1653)\"\n        ]\n      }\n    },\n    {\n      \"label\": {\n        \"en\": [\n          \"Culture\"\n        ]\n      },\n      \"value\": {\n        \"en\": [\n          \"Dutch\"\n        ]\n      }\n    },\n    {\n      \"label\": {\n        \"en\": [\n          \"Date\"\n        ]\n      },\n      \"value\": {\n        \"en\": [\n          \"1642\"\n        ]\n      }\n    },\n    {\n      \"label\": {\n        \"en\": [\n          \"Medium\"\n        ]\n      },\n      \"value\": {\n        \"en\": [\n          \"Oil on panel\"\n        ]\n      }\n    },\n    {\n      \"label\": {\n        \"en\": [\n          \"Dimensions\"\n        ]\n      },\n      \"value\": {\n        \"en\": [\n          \"32 1/8 × 52 13/16 in. (81.6 × 134.2 cm)\"\n        ]\n      }\n    },\n    {\n      \"label\": {\n        \"en\": [\n          \"Creditline\"\n        ]\n      },\n      \"value\": {\n        \"en\": [\n          \"Dr. Herbert and Monika Schaefer Fund\"\n        ]\n      }\n    },\n    {\n      \"label\": {\n        \"en\": [\n          \"Classification\"\n        ]\n      },\n      \"value\": {\n        \"en\": [\n          \"Paintings\"\n        ]\n      }\n    },\n    {\n      \"label\": {\n        \"en\": [\n          \"Department\"\n        ]\n      },\n      \"value\": {\n        \"en\": [\n          \"European Art\"\n        ]\n      }\n    },\n    {\n      \"label\": {\n        \"en\": [\n          \"Institution\"\n        ]\n      },\n      \"value\": {\n        \"en\": [\n          \"Yale University Art Gallery\"\n        ]\n      }\n    },\n    {\n      \"label\": {\n        \"en\": [\n          \"Object Number\"\n        ]\n      },\n      \"value\": {\n        \"en\": [\n          \"2021.16.1\"\n        ]\n      }\n    }\n  ],\n  \"rights\": \"https://creativecommons.org/publicdomain/zero/1.0/\",\n  \"requiredStatement\": {\n    \"label\": {\n      \"en\": [\n        \"Rights Description\"\n      ]\n    },\n    \"value\": {\n      \"en\": [\n        \"Data Provided about Yale University Art Gallery collections are public domain. Rights restrictions may apply to cultural works or images of those works.\"\n      ]\n    }\n  },\n  \"logo\": [\n    {\n      \"id\": \"https://artgallery.yale.edu/sites/default/files/2023-03/LUX_YUAG_logo.png\",\n      \"type\": \"Image\"\n    }\n  ],\n  \"homepage\": [\n    {\n      \"format\": \"text/html\",\n      \"id\": \"https://artgallery.yale.edu/collections/objects/293797\",\n      \"label\": {\n        \"en\": [\n          \"catalog entry at the Yale University Art Gallery\"\n        ]\n      },\n      \"language\": \"en\",\n      \"type\": \"Text\"\n    }\n  ],\n  \"items\": [\n    {\n      \"id\": \"https://manifests.collections.yale.edu/canvas/yuag/ca7804d1-5fbc-4bce-9343-007bcb018c32\",\n      \"type\": \"Canvas\",\n      \"label\": {\n        \"en\": [\n          \"Image from Yale University\"\n        ]\n      },\n      \"height\": 5940,\n      \"width\": 9833,\n      \"items\": [\n        {\n          \"id\": \"https://manifests.collections.yale.edu/annopage/yuag/ca7804d1-5fbc-4bce-9343-007bcb018c32\",\n          \"type\": \"AnnotationPage\",\n          \"items\": [\n            {\n              \"id\": \"https://manifests.collections.yale.edu/annotation/yuag/ca7804d1-5fbc-4bce-9343-007bcb018c32\",\n              \"type\": \"Annotation\",\n              \"motivation\": \"painting\",\n              \"body\": {\n                \"id\": \"https://images.collections.yale.edu/iiif/2/yuag:ca7804d1-5fbc-4bce-9343-007bcb018c32/full/full/0/default.jpg\",\n                \"type\": \"Image\",\n                \"format\": \"image/jpeg\",\n                \"service\": [\n                  {\n                    \"@id\": \"https://images.collections.yale.edu/iiif/2/yuag:ca7804d1-5fbc-4bce-9343-007bcb018c32\",\n                    \"@type\": \"ImageService2\",\n                    \"profile\": \"http://iiif.io/api/image/2/level2.json\"\n                  }\n                ],\n                \"height\": 5940,\n                \"width\": 9833\n              },\n              \"target\": \"https://manifests.collections.yale.edu/canvas/yuag/ca7804d1-5fbc-4bce-9343-007bcb018c32\"\n            }\n          ]\n        }\n      ],\n      \"rendering\": [\n        {\n          \"id\": \"https://media.collections.yale.edu/tiff/yuag/ca7804d1-5fbc-4bce-9343-007bcb018c32.tif\",\n          \"type\": \"Image\",\n          \"label\": {\n            \"en\": [\n              \"TIFF for download\"\n            ]\n          },\n          \"format\": \"image/tiff\"\n        }\n      ],\n      \"thumbnail\": [\n        {\n          \"id\": \"https://media.collections.yale.edu/thumbnail/yuag/ca7804d1-5fbc-4bce-9343-007bcb018c32\",\n          \"type\": \"Image\",\n          \"format\": \"image/jpeg\",\n          \"width\": 480,\n          \"height\": 290\n        }\n      ],\n      \"metadata\": [\n        {\n          \"label\": {\n            \"en\": [\n              \"Image Use Rights\"\n            ]\n          },\n          \"value\": {\n            \"en\": [\n              \"No Copyright - United States\"\n            ]\n          }\n        }\n      ]\n    }\n  ]\n}\nhttps://manifests.collections.yale.edu/yuag/obj/293797\n\n\nEcosytem\n\n\n\n\nWeb Annotation Data Model\nThe Web Annotation Data Model, standardized by the World Wide Web Consortium (W3C) in 2017, provides an extensible and interoperable framework for creating and sharing annotations across different platforms. It supports a wide range of use cases, from simple annotations to linking content with multimedia data points. It leverages JSON-LD for serialization, enabling integration with the web’s structured data ecosystem while following Linked Data principles (see Haslhofer et al., 2011; Sanderson et al., 2013).\nThe model follows a three-part structure: - Target: The resource being annotated. - Body: The annotation content (text, image, media, etc.). - Annotation: The entity linking the body and target.\nThis model ensures compatibility with web architecture and facilitates cross-platform sharing of annotations.\n\nThe Web Annotation Data Model in a IIIF setting\n{\n  \"@context\": \"http://iiif.io/api/presentation/3/context.json\",\n  \"id\": \"https://iiif.participatory-archives.ch/annotations/SGV_12N_08589-p1-list.json\",\n  \"type\": \"AnnotationPage\",\n  \"items\": [\n    {\n      \"@context\": \"http://www.w3.org/ns/anno.jsonld\",\n      \"id\": \"https://iiif.participatory-archives.ch/annotations/SGV_12N_08589-p1-list/annotation-436121.json\",\n      \"motivation\": \"commenting\",\n      \"type\": \"Annotation\",\n      \"body\": [\n        {\n          \"type\": \"TextualBody\",\n          \"value\": \"person\",\n          \"purpose\": \"commenting\"\n        },\n        {\n          \"type\": \"TextualBody\",\n          \"value\": \"Object Detection (vitrivr)\",\n          \"purpose\": \"tagging\"\n        },\n        {\n          \"type\": \"TextualBody\",\n          \"value\": \"&lt;br&gt;&lt;small&gt;Detection score: 0.9574&lt;/small&gt;\",\n          \"purpose\": \"commenting\"\n        }\n      ],\n      \"target\": {\n        \"source\": \"https://iiif.participatory-archives.ch/SGV_12N_08589/canvas/p1\",\n        \"selector\": {\n          \"type\": \"FragmentSelector\",\n          \"conformsTo\": \"http://www.w3.org/TR/media-frags/\",\n          \"value\": \"xywh=319,2942,463,523\"\n        },\n        \"dcterms:isPartOf\": {\n          \"type\": \"Manifest\",\n          \"id\": \"https://iiif.participatory-archives.ch/SGV_12N_08589/manifest.json\"\n        }}},\n\n\nLinked Art\nLinked Art is a community and a CIDOC (ICOM International Committee for Documentation) Working Group collaborating to define a metadata application profile for describing cultural heritage, and the technical means for conveniently interacting with it (the API).\nhttps://linked.art\n\nCommunity\nLinked Art is an open community initiative where participants collaborate under a shared code of conduct. Ways to engage include attending events, joining the discussion group, participating in the Slack workspace, or contributing to discussions on GitHub.\nA wide range of institutions contribute to Linked Art, including The Metropolitan Museum of Art, J. Paul Getty Trust, Yale University, Smithsonian Institution, Europeana, Canadian Heritage Information Network (CHIN), Oxford University, Victoria and Albert Museum, Rijksmuseum, The Frick Collection, Museum of Modern Art (MoMA), and many more. Since 2019, an editorial board has overseen Linked Art, ensuring diverse representation across institutions and disciplines.\n\n\nData Model\n\n\n\n\nLevel\nLinked Art\n\n\n\n\nConceptual Model\nCIDOC Conceptual Reference Model (CRM)\n\n\nOntology\nRDF encoding of CRM 7.1, plus extensions\n\n\nVocabulary\nGetty Vocabularies, mainly the Art & Architecture Thesaurus (AAT), as well as the Thesaurus of Geographic Names (TGN) and the Union List of Artist Names (ULAN)\n\n\nProfile\nObject-based cultural heritage (mainly art museum oriented)\n\n\nAPI\nJSON-LD 1.1, following REST (representational state transfer) and web patterns\n\n\n\nLinked Art from 50k feet\n\nRaemy et al. (2023)\nDigital Object\n{\n{\n  \"@context\": \"https://linked.art/ns/v1/linked-art.json\",\n  \"id\": \"https://linked.art/example/digital/0\",\n  \"type\": \"DigitalObject\",\n  \"_label\": \"Digital Image of Self-Portrait of Van Gogh\",\n  \"classified_as\": [\n    {\n      \"id\": \"http://vocab.getty.edu/aat/300215302\",\n      \"type\": \"Type\",\n      \"_label\": \"Digital Image\"\n    }\n  ],\n  \"identified_by\": [\n    {\n      \"type\": \"Name\",\n      \"content\": \"Self-Portrait Dedicated to Paul Gauguin\"\n    },\n    {\n      \"type\": \"Identifier\",\n      \"classified_as\": [\n        {\n          \"id\": \"http://vocab.getty.edu/aat/300404621\",\n          \"type\": \"Type\",\n          \"_label\": \"Owner-Assigned Number\"\n        }\n      ],\n      \"content\": \"47174896\"\n    }\n  ],\n  \"dimension\": [\n    {\n      \"type\": \"Dimension\",\n      \"classified_as\": [\n        {\n          \"id\": \"http://vocab.getty.edu/aat/300055644\",\n          \"type\": \"Type\",\n          \"_label\": \"Height\"\n        }\n      ],\n      \"value\": 2550,\n      \"unit\": {\n        \"id\": \"http://vocab.getty.edu/aat/300266190\",\n        \"type\": \"MeasurementUnit\",\n        \"_label\": \"pixels\"\n      }\n    },\n    {\n      \"type\": \"Dimension\",\n      \"classified_as\": [\n        {\n          \"id\": \"http://vocab.getty.edu/aat/300055647\",\n          \"type\": \"Type\",\n          \"_label\": \"Width\"\n        }\n      ],\n      \"value\": 2087,\n      \"unit\": {\n        \"id\": \"http://vocab.getty.edu/aat/300266190\",\n        \"type\": \"MeasurementUnit\",\n        \"_label\": \"pixels\"\n      }\n    }\n  ],\n  \"part_of\": [\n    {\n      \"id\": \"https://iiif.harvardartmuseums.org/manifests/object/299843\",\n      \"type\": \"DigitalObject\",\n      \"_label\": \"IIIF Manifest\"\n    }\n  ],\n  \"member_of\": [\n    {\n      \"id\": \"https://linked.art/example/set/0\",\n      \"type\": \"Set\",\n      \"_label\": \"Images of Self-Portraits of Van Gogh\"\n    }\n  ],\n  \"access_point\": [\n    {\n      \"id\": \"https://ids.lib.harvard.edu/ids/iiif/47174896/full/full/0/default.jpg\",\n      \"type\": \"DigitalObject\"\n    }\n  ],\n  \"digitally_shows\": [\n    {\n      \"type\": \"VisualItem\",\n      \"_label\": \"Visual Content of Self-Portrait of Van Gogh\"\n    }\n  ],\n  \"format\": \"image/jpeg\",\n  \"digitally_available_via\": [\n    {\n      \"type\": \"DigitalService\",\n      \"_label\": \"IIIF Service\",\n      \"access_point\": [\n        {\n          \"id\": \"https://ids.lib.harvard.edu/ids/iiif/47174896\",\n          \"type\": \"DigitalObject\"\n        }\n      ],\n      \"conforms_to\": [\n        {\n          \"id\": \"https://iiif.io/api/image/2/context.json\",\n          \"type\": \"InformationObject\"\n        }\n      ]\n    }\n  ],\n  \"created_by\": {\n    \"type\": \"Creation\",\n    \"carried_out_by\": [\n      {\n        \"id\": \"https://linked.art/example/group/harvardartmuseums.org\",\n        \"type\": \"Group\",\n        \"_label\": \"Harvard Art Museums\"\n      }\n    ],\n    \"used_specific_object\": [\n      {\n        \"id\": \"https://harvardartmuseums.org/collections/object/299843\",\n        \"type\": \"HumanMadeObject\",\n        \"_label\": \"Self-Portrait of Van Gogh\"\n      }\n    ]\n  }\n}\nLinked Art Digital Integration (with IIIF)",
    "crumbs": [
      "Associated Principles"
    ]
  },
  {
    "objectID": "sections/movements.html",
    "href": "sections/movements.html",
    "title": "Associated Movements",
    "section": "",
    "text": "NoteSlide Presentation\n\n\n\nMost of the following content can be found in presentation format: Associated Movements and Principles (slides 74-88). Please note this is the 2024 version of the course and will not be kept updated.",
    "crumbs": [
      "Associated Movements"
    ]
  },
  {
    "objectID": "sections/movements.html#open-access",
    "href": "sections/movements.html#open-access",
    "title": "Associated Movements",
    "section": "Open Access",
    "text": "Open Access\n\nBerlin Declaration on Open Access to Knowledge in the Sciences and Humanities\n\nAuthors and right holders must grant all users a free, irrevocable, worldwide, right of access to, and a license to copy, use, distribute, transmit and display the work publicly and to make and distribute derivative works, in any digital medium for any responsible purpose, subject to proper attribution of authorship as well as the right to make small numbers of printed copies for their personal use.\nA complete version of the work and all supplemental materials, including a copy of the permission as stated above, in an appropriate standard electronic format is deposited in at least one online repository using suitable technical standards.\n\nMax Planck Society & European Cultural Heritage Online (2003)\n\n\nDefinitions\n\nOpen access (OA) is a broad international movement that seeks to grant free and open online access to academic information, such as publications and data. A publication is defined ‘open access’ when there are no financial, legal or technical barriers to accessing it - that is to say when anyone can read, download, copy, distribute, print, search for and search within the information, or use it in education or in any other way within the legal agreements.\n\nhttps://www.openaccess.nl/en/what-is-open-access\n\nOA is a publishing model for scholarly communication that makes research information available to readers at no cost, as opposed to the traditional subscription model in which readers have access to scholarly information by paying a subscription (usually via libraries).\n\nhttps://www.openaccess.nl/en/what-is-open-access\n\n\nGold Open Access\nPublications are made freely accessible by the publisher immediately upon publication. It often involves Article Processing Charges (APCs) paid by the author, their institution, or a funder.\n→ Immediate OA via publisher\n\n\nGreen Open Access (Self-Archiving)\nAuthors publish their work in any journal and then self-archive an earlier version of the article (pre-print) for free public use in a repository (sometimes after an embargo period).\n→ Immediate or delayed OA via self-archiving method/repository\n\n\nHybrid Open Access\nSubscription-based journals allow authors to make their individual articles OA upon payment of an APC.\n→ Immediate OA via publisher\n\n\nDiamond/Platinum Open Access\nJournals do not charge authors APCs and provide immediate OA to all their articles. It operates without direct cost to the authors; funding often comes from institutions, societies, or donations.\n→ Immediate OA via publisher\n\n\nBronze Open Access\nArticles made freely accessible on the publisher’s website without an explicit OA licence.\n\n\nBlue Open Access\nThrough blue OA, authors can archive the post-print or the publisher’s final version. This allows for immediate or delayed free public access to the research, often acting as a variation of Green OA.\n\n\nBlack Open Access\nIt refers to the unauthorised distribution of published content through various channels, such as pirate sites or peer-to-peer networks.",
    "crumbs": [
      "Associated Movements"
    ]
  },
  {
    "objectID": "sections/movements.html#open-science-open-scholarship",
    "href": "sections/movements.html#open-science-open-scholarship",
    "title": "Associated Movements",
    "section": "Open Science / Open Scholarship",
    "text": "Open Science / Open Scholarship\n\nDefinition\n\nOpen Science is the practice of science in such a way that others can collaborate and contribute, where research data, lab notes and other research processes are freely available, under terms that enable reuse, redistribution and reproduction of the research and its underlying data and methods.\n\nFOSTER (2019)\n\n(Morrison, 2021; Persic, 2021)\n\n\nOpen Scholarship: Expanding the Reach of Open Science\n\nBroader Approach\n\nExtends beyond traditional scientific disciplines to include arts and humanities.\nEngages not just the research community but also the wider public, including non-experts, educators, and policymakers.\n\nSupporting Collaboration and Innovation\n\nFacilitates interdisciplinary collaboration across arts, humanities, and other fields.\nEncourages the use of open educational resources for collaborative teaching and learning.\nAdvances open data practices for the sharing and reuse of cultural heritage resources.\n\n\nTennant et al. (2020)",
    "crumbs": [
      "Associated Movements"
    ]
  },
  {
    "objectID": "sections/movements.html#open-source-free-software-floss",
    "href": "sections/movements.html#open-source-free-software-floss",
    "title": "Associated Movements",
    "section": "Open Source / Free Software / F(L)OSS",
    "text": "Open Source / Free Software / F(L)OSS\n\nDefinition and Philosophy\nOpen Source refers to software with source code that can be inspected, modified, and enhanced by anyone. It emphasises collaboration and community-oriented development.\n\n\nKey Characteristics\nIt includes free redistribution, access to source code, and allowance for derived works.\n\n\nCriteria\n\nFree redistribution\nSource code must be included\nDerived works must be allowed\nIntegrity of the author’s source code\nNo discrimation against persons or groups\nNo discrimation against fields of endeavour\nDistribution of licence\nLicence must not be specific to a product\nLicence must not restrict other software\nLicence must be technology-neutral\n\nhttps://opensource.org/osd/\n\n\nFree Software\nFree Software is centred around the idea of user freedom – the freedom to run, study, change, and distribute the software. “Free” refers to freedom, not price.\nIt has four essential freedoms: 1. The freedom to run the program as you wish, for any purpose (freedom 0). 2. The freedom to study how the program works, and change it so it does your computing as you wish (freedom 1). Access to the source code is a precondition for this. 3. The freedom to redistribute copies so you can help others (freedom 2). 4. The freedom to distribute copies of your modified versions to others (freedom 3). By doing this you can give the whole community a chance to benefit from your changes. Access to the source code is a precondition for this.\n\n“Free software” means software that respects users’ freedom and community. Roughly, it means that the users have the freedom to run, copy, distribute, study, change and improve the software. Thus, “free software” is a matter of liberty, not price. To understand the concept, you should think of “free” as in “free speech,” not as in “free beer.” We sometimes call it “libre software,” borrowing the French or Spanish word for “free” as in freedom, to show we do not mean the software is gratis.\n\nhttps://www.gnu.org/philosophy/free-sw.en.html\n\n\nFree/Libre and Open Source Software\n\nThis is software for which the licensee can get the source code, and is allowed to modify this code and to redistribute the software and the modifications. Many terms are used: free, referring to the freedom to use (not to “free of charge”), libre, which is the French translation of Free/freedom, and which is preferred by some writers to avoid the ambiguous reference to free of charge, and open source, which focuses more on the access to the sources than on the freedom to redistribute. In practice, the differences are not great, and more and more scholars are choosing the term FLOSS to name this whole movement.\n\nJullien (2009)\n“Neutral stance”: See https://www.gnu.org/philosophy/floss-and-foss.en.html",
    "crumbs": [
      "Associated Movements"
    ]
  },
  {
    "objectID": "sections/assessment.html",
    "href": "sections/assessment.html",
    "title": "Assessment, Data Quality, and Best Practices",
    "section": "",
    "text": "Since 2015, the European Union has conducted an annual assessment to gauge the progress of European countries in promoting and facilitating the availability and reuse of public sector information – predominantly open government data.\n\n\n\nPolicy – It investigates the open data policies and strategies in place in the participating countries, the national governance models for managing open data and the measures applied to implement those policies and strategies.\nPortal – It investigates the functionality of national open data portals, the extent to which users’ needs and behaviour are examined to improve the portal, the availability of open data across different domains and the approach to ensuring the portal’s sustainability.\nImpact – It analyses the willingness, preparedness and ability of countries to measure both the reuse of open data and the impact created through this reuse.\nQuality – It assesses the measures adopted by portal managers to ensure the systematic harvesting of metadata, the monitoring of metadata quality and compliance with the DCAT-AP metadata standard, and the quality of deployment of the published data on the national portal.\n\nFor more details, please refer to the European Open Data Maturity publication.\n\n\n\nThe 2023 ODM assessment involved 35 participating countries – including the EU-27, three European Free Trade Association countries (Iceland, Norway and Switzerland), and five candidate countries (Bosnia and Herzegovina, Montenegro, Albania, Serbia and Ukraine).\nIn 2023, Switzerland scored 79% in Open Data Maturity, ranking 24th among the participants (Page et al., 2023). Further information is available in the ODM 2023 report.\n\n\n\nThe ODM 2024 assessment marks the 10th edition of this benchmarking initiative. ODM 2024 maintains the same methodology as 2023 but integrates refinements, particularly focusing on high-value datasets (HVDs), metadata quality, and portal performance (Page et al., 2024b).\nSwitzerland ranks 20th with an ODM score of 80 (Page et al., 2024a). Further information is available in the ODM 2024 report.\n\n\n\n\nIn Switzerland, the opendata.swiss platform has leveraged an Impact Monitoring Framework to assess the value of open government data initiatives. This framework employs a structured set of criteria and leverages the Social Return on Investment (SROI) approach to evaluate inputs, outputs, outcomes and overall impact. This systematic method offers a robust means to quantify the social and economic benefits derived from open data projects (Stürmer, 2016).",
    "crumbs": [
      "Assessment, Data Quality, and Best Practices"
    ]
  },
  {
    "objectID": "sections/assessment.html#assessment",
    "href": "sections/assessment.html#assessment",
    "title": "Assessment, Data Quality, and Best Practices",
    "section": "",
    "text": "Since 2015, the European Union has conducted an annual assessment to gauge the progress of European countries in promoting and facilitating the availability and reuse of public sector information – predominantly open government data.\n\n\n\nPolicy – It investigates the open data policies and strategies in place in the participating countries, the national governance models for managing open data and the measures applied to implement those policies and strategies.\nPortal – It investigates the functionality of national open data portals, the extent to which users’ needs and behaviour are examined to improve the portal, the availability of open data across different domains and the approach to ensuring the portal’s sustainability.\nImpact – It analyses the willingness, preparedness and ability of countries to measure both the reuse of open data and the impact created through this reuse.\nQuality – It assesses the measures adopted by portal managers to ensure the systematic harvesting of metadata, the monitoring of metadata quality and compliance with the DCAT-AP metadata standard, and the quality of deployment of the published data on the national portal.\n\nFor more details, please refer to the European Open Data Maturity publication.\n\n\n\nThe 2023 ODM assessment involved 35 participating countries – including the EU-27, three European Free Trade Association countries (Iceland, Norway and Switzerland), and five candidate countries (Bosnia and Herzegovina, Montenegro, Albania, Serbia and Ukraine).\nIn 2023, Switzerland scored 79% in Open Data Maturity, ranking 24th among the participants (Page et al., 2023). Further information is available in the ODM 2023 report.\n\n\n\nThe ODM 2024 assessment marks the 10th edition of this benchmarking initiative. ODM 2024 maintains the same methodology as 2023 but integrates refinements, particularly focusing on high-value datasets (HVDs), metadata quality, and portal performance (Page et al., 2024b).\nSwitzerland ranks 20th with an ODM score of 80 (Page et al., 2024a). Further information is available in the ODM 2024 report.\n\n\n\n\nIn Switzerland, the opendata.swiss platform has leveraged an Impact Monitoring Framework to assess the value of open government data initiatives. This framework employs a structured set of criteria and leverages the Social Return on Investment (SROI) approach to evaluate inputs, outputs, outcomes and overall impact. This systematic method offers a robust means to quantify the social and economic benefits derived from open data projects (Stürmer, 2016).",
    "crumbs": [
      "Assessment, Data Quality, and Best Practices"
    ]
  },
  {
    "objectID": "sections/assessment.html#data-quality-and-best-practices",
    "href": "sections/assessment.html#data-quality-and-best-practices",
    "title": "Assessment, Data Quality, and Best Practices",
    "section": "Data Quality and Best Practices",
    "text": "Data Quality and Best Practices\n\nData Quality\nTracking the state of open government data is crucial. Various tools are available to assess data quality: - The Open Knowledge Foundation (OKFN) Data Quality Index. - The Opquast web quality assurance checklist. - Data Quality Scores provided on platforms such as Data Winnipeg, which evaluate the metadata quality of datasets.\n\n\nBest Practices and Toolkits\nA number of best practice resources and toolkits help guide the effective management of open data: - The Annotated 8 Principles of Open Government Data (OGD) (US), which provide detailed guidelines. - The Open Government Data Toolkit, offering comprehensive resources for implementing open data initiatives.\nThese tools complement broader frameworks such as FAIR, CARE, Collections as Data, and LOUD, all of which are essential for ensuring that open data is both accessible and of high quality.\n\n\nPeriodic Table of Open Data Elements\nThe Periodic Table of Open Data Elements provides a visual summary of the enabling conditions and challenges that affect the success of open data initiatives. It outlines key elements such as:\n\nProblem and Demand Definition\nCapacity and Culture\nGovernance\nPartnerships\nRisks\n\n\nThis table serves as a valuable reference for understanding the multifaceted nature of open data impacts. For further exploration, you can view the English version or the French version.",
    "crumbs": [
      "Assessment, Data Quality, and Best Practices"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "7C2-CT-4A Introduction to Open Data",
    "section": "",
    "text": "The course is designed for undergraduate students in Information Science at the HES-SO University of Applied Sciences and Arts of Western Switzerland, Haute école de gestion de Genève (HEG-GE). It provides a comprehensive introduction to Open Data, covering key aspects such as:\n\nCharacteristics of Open Data\nAssociated Movements\nAssociated Principles\nOpen Data Platforms and Organisations\nAssessment, Data Quality, and Best Practices\nTechniques, Software, and Tools\nShowcases\n\n\n\n\n\n\n\n\n\nTipNavigate the slides\n\n\n\nUse arrow keys or the controls at the bottom to navigate through the presentation. Press f for fullscreen mode."
  },
  {
    "objectID": "index.html#why-open-data-matters-tldr",
    "href": "index.html#why-open-data-matters-tldr",
    "title": "7C2-CT-4A Introduction to Open Data",
    "section": "",
    "text": "TipNavigate the slides\n\n\n\nUse arrow keys or the controls at the bottom to navigate through the presentation. Press f for fullscreen mode."
  },
  {
    "objectID": "exercises/ex-02.html",
    "href": "exercises/ex-02.html",
    "title": "Exercise 2: Up to date with Linked Data",
    "section": "",
    "text": "Linked Data is about publishing structured data on the web so that it can be interlinked and become more useful through semantic queries. It extends standard web technologies (HTTP, URIs) to share information in a machine-readable way.\n\n\nTim Berners-Lee defined four principles for publishing data on the web:\n\nUse URIs as names for things - Give everything a unique web address\nUse HTTP URIs - Make those addresses accessible via the web\nProvide useful information - When someone looks up a URI, return data using standards (RDF, SPARQL)\nInclude links to other URIs - Enable discovery of related information\n\n\n\n\nRDF (Resource Description Framework) represents data as triples: subject-predicate-object statements.\nExample: “Vincent van Gogh created the Starry Night painting”\nsubject:   &lt;http://example.org/artist/vangogh&gt;\npredicate: &lt;http://example.org/vocab/created&gt;\nobject:    &lt;http://example.org/artwork/starrynight&gt;\n\n\n\nTurtle (Terse RDF Triple Language) is a human-readable syntax for RDF. Let’s look at a cultural heritage example:\n@prefix ex: &lt;http://example.org/&gt; .\n@prefix schema: &lt;http://schema.org/&gt; .\n@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; .\n\nex:vangogh a foaf:Person ;\n    foaf:name \"Vincent van Gogh\" ;\n    foaf:birthday \"1853-03-30\" ;\n    schema:nationality \"Dutch\" ;\n    ex:created ex:starrynight .\n\nex:starrynight a schema:Painting ;\n    schema:name \"The Starry Night\" ;\n    schema:dateCreated \"1889-06\" ;\n    schema:material \"Oil on canvas\" ;\n    schema:creator ex:vangogh ;\n    schema:location ex:moma .\n\nex:moma a schema:Museum ;\n    foaf:name \"Museum of Modern Art\" ;\n    schema:location \"New York, USA\" .\nKey elements:\n\n@prefix declares namespace prefixes\na means “is of type”\n; continues statements about the same subject\n. ends a group of statements\n\n\n\n\nSPARQL is the query language for RDF data. It allows you to find patterns in the data.\nBasic SPARQL query structure:\nPREFIX ex: &lt;http://example.org/&gt;\nPREFIX schema: &lt;http://schema.org/&gt;\nPREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;\n\nSELECT ?subject ?predicate ?object\nWHERE {\n    ?subject ?predicate ?object .\n}\nFind all paintings:\nSELECT ?painting ?name\nWHERE {\n    ?painting a schema:Painting ;\n              schema:name ?name .\n}\nFind artworks created by Van Gogh:\nSELECT ?artwork ?title\nWHERE {\n    ex:vangogh ex:created ?artwork .\n    ?artwork schema:name ?title .\n}"
  },
  {
    "objectID": "exercises/ex-02.html#up-to-date-with-linked-data",
    "href": "exercises/ex-02.html#up-to-date-with-linked-data",
    "title": "Exercise 2: Up to date with Linked Data",
    "section": "",
    "text": "Linked Data is about publishing structured data on the web so that it can be interlinked and become more useful through semantic queries. It extends standard web technologies (HTTP, URIs) to share information in a machine-readable way.\n\n\nTim Berners-Lee defined four principles for publishing data on the web:\n\nUse URIs as names for things - Give everything a unique web address\nUse HTTP URIs - Make those addresses accessible via the web\nProvide useful information - When someone looks up a URI, return data using standards (RDF, SPARQL)\nInclude links to other URIs - Enable discovery of related information\n\n\n\n\nRDF (Resource Description Framework) represents data as triples: subject-predicate-object statements.\nExample: “Vincent van Gogh created the Starry Night painting”\nsubject:   &lt;http://example.org/artist/vangogh&gt;\npredicate: &lt;http://example.org/vocab/created&gt;\nobject:    &lt;http://example.org/artwork/starrynight&gt;\n\n\n\nTurtle (Terse RDF Triple Language) is a human-readable syntax for RDF. Let’s look at a cultural heritage example:\n@prefix ex: &lt;http://example.org/&gt; .\n@prefix schema: &lt;http://schema.org/&gt; .\n@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; .\n\nex:vangogh a foaf:Person ;\n    foaf:name \"Vincent van Gogh\" ;\n    foaf:birthday \"1853-03-30\" ;\n    schema:nationality \"Dutch\" ;\n    ex:created ex:starrynight .\n\nex:starrynight a schema:Painting ;\n    schema:name \"The Starry Night\" ;\n    schema:dateCreated \"1889-06\" ;\n    schema:material \"Oil on canvas\" ;\n    schema:creator ex:vangogh ;\n    schema:location ex:moma .\n\nex:moma a schema:Museum ;\n    foaf:name \"Museum of Modern Art\" ;\n    schema:location \"New York, USA\" .\nKey elements:\n\n@prefix declares namespace prefixes\na means “is of type”\n; continues statements about the same subject\n. ends a group of statements\n\n\n\n\nSPARQL is the query language for RDF data. It allows you to find patterns in the data.\nBasic SPARQL query structure:\nPREFIX ex: &lt;http://example.org/&gt;\nPREFIX schema: &lt;http://schema.org/&gt;\nPREFIX foaf: &lt;http://xmlns.com/foaf/0.1/&gt;\n\nSELECT ?subject ?predicate ?object\nWHERE {\n    ?subject ?predicate ?object .\n}\nFind all paintings:\nSELECT ?painting ?name\nWHERE {\n    ?painting a schema:Painting ;\n              schema:name ?name .\n}\nFind artworks created by Van Gogh:\nSELECT ?artwork ?title\nWHERE {\n    ex:vangogh ex:created ?artwork .\n    ?artwork schema:name ?title .\n}"
  },
  {
    "objectID": "exercises/ex-02.html#exercises-15-20-minutes",
    "href": "exercises/ex-02.html#exercises-15-20-minutes",
    "title": "Exercise 2: Up to date with Linked Data",
    "section": "Exercises (15-20 minutes)",
    "text": "Exercises (15-20 minutes)\n\nA: Understanding Turtle Syntax (4-5 minutes)\nLook at the following Turtle snippet describing a manuscript:\n@prefix ex: &lt;http://library.org/&gt; .\n@prefix dc: &lt;http://purl.org/dc/elements/1.1/&gt; .\n@prefix schema: &lt;http://schema.org/&gt; .\n\nex:manuscript_042 a schema:Book ;\n    dc:title \"Grandes Chroniques de France\" ;\n    dc:creator \"Anonymous\" ;\n    schema:dateCreated \"1375\" ;\n    ex:heldBy ex:chateauroux_library .\n\nex:chateauroux_library a schema:Library ;\n    schema:name \"Bibliothèque municipale de Châteauroux\" ;\n    schema:location \"France\" .\n\nWhat type of resource is ex:manuscript_042?\nHow many properties describe the manuscript?\nWhat relationship links the manuscript to the library?\n\n\n\nB: Real-World SPARQL Exploration (6-8 minutes)\nVisit the Wikidata Query Service: https://query.wikidata.org/\nTry this query to find Van Gogh paintings with images:\nSELECT ?painting ?paintingLabel ?image\nWHERE {\n    ?painting wdt:P31 wd:Q3305213 ;    # instance of painting\n              wdt:P170 wd:Q5582 ;       # creator: Vincent van Gogh\n              wdt:P18 ?image .          # has image\n    SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\". }\n}\n\nHow many paintings with images did you find?\nTry modifying the query to find paintings by a different artist (hint: search Wikidata for another artist’s Q-number, e.g., Pablo Picasso is wd:Q5593). What artist did you choose and how many results did you get?\n\n\n\nC: Reflection Questions (5-7 minutes)\n\nWhat are the main advantages of using Linked Data for cultural heritage collections?\nWhat challenges might institutions face when implementing Linked Data?\nBased on your experience with the Wikidata Query Service, what makes a SPARQL endpoint useful or difficult to use?"
  },
  {
    "objectID": "exercises/ex-02.html#additional-resources",
    "href": "exercises/ex-02.html#additional-resources",
    "title": "Exercise 2: Up to date with Linked Data",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nLinked Data Principles: https://www.w3.org/DesignIssues/LinkedData.html\nTurtle Specification: https://www.w3.org/TR/turtle/\nSPARQL Tutorial: https://www.w3.org/TR/sparql11-query/\nWikidata SPARQL Examples: https://www.wikidata.org/wiki/Wikidata:SPARQL_query_service/queries/examples"
  },
  {
    "objectID": "exercises/ex-06.html",
    "href": "exercises/ex-06.html",
    "title": "Exercise 6: Reading Assignment",
    "section": "",
    "text": "(…)"
  },
  {
    "objectID": "exercises/ex-06.html#open-refine",
    "href": "exercises/ex-06.html#open-refine",
    "title": "Exercise 6: Open Refine",
    "section": "",
    "text": "Install the software (https://openrefine.org/docs)\nRun it locally (accessible at http://127.0.0.1:3333/)\nHave a look at the different pages and functionalities\nCreate a new project by importing any supported files\n\n\n\n\n\nCreate a new project by importing the Powerhouse Museum TSV file (https://zenodo.org/records/17047254/files/phm_collection_adapted.tsv) — remember to select “Tab-separated values”\nWhitespace detection: Use Facet by blank on the categories column, then apply Edit cells &gt; Common transforms &gt; Trim leading and trailing whitespace. Observe how “blank” cells are revealed.\nClustering: Create a Text facet on the category column. Click Cluster and use the “key collision” method to merge case inconsistencies (e.g., “Pottery” vs “pottery”).\nMulti-valued cells: Split the categories column by the separator | (pipe character). Count how many objects have more than 3 categories, then rejoin the cells.\n\n\n\n\n\nCreate a new project by importing the Met Museum CSV (https://github.com/metmuseum/openaccess) — use the first 5,000 rows for better performance\nReconcile artists: Select the Artist Display Name column. Start reconciling against Wikidata (service: https://wikidata.reconci.link/en/api, type: Q5 for humans).\nJudgment exercise: Auto-match high confidence scores (&gt;90), manually review medium scores (70-90) to distinguish between homonyms (e.g., different “John Smith” artists), and mark low scores (&lt;70) as “None”.\nExtract QIDs: Transform reconciled cells to extract just the QID number for external linking.\n\n\n\n\n\nCreate a new project by importing the manuscript CSV from https://raw.githubusercontent.com/emmamorlock/workshop/refs/heads/main/exercices/handouts/biblissima.csv\nExplore manuscript metadata: Review columns such as shelfmark, repository, author, and title. Create text facets to identify variations in repository names or author attributions.\nReconcile shelfmarks: Use the Biblissima reconciliation endpoint (https://data.biblissima.fr/api/reconcile, type: Manuscript) to match records against the Biblissima authority file. This connects your local shelfmarks to persistent URIs.\nEnrich with IIIF (optional extension): After reconciliation, use Edit column &gt; Add column by fetching URLs to retrieve JSON data from the reconciled Biblissima URIs. Parse the JSON to extract iiif_manifest_url fields where available.\n\nCf. Sajdak (2024).\n\n\n\n\nCreate a new project by importing a Smithsonian JSON file (not CSV) from https://github.com/Smithsonian/OpenAccess\nFlatten nested JSON: Convert nested paths (e.g., title.content) to flat columns using the transform expression: value.parseJson()['title']\nExtract media: Parse the JSON to find objects with images by extracting online_media.mediaCount\nReconcile topics: Match topic fields against Library of Congress Subject Headings (LCSH) using their reconciliation service.\n\n\n\n\n\nExport your cleaned datasets in both CSV and JSON formats\nExport the project history (OpenRefine project archive) to document your transformation steps\n\nMore information and tutorials on OpenRefine can be found on the following links:\n\nLibrary Carpentry website: https://librarycarpentry.org/lc-open-refine/\nUniversity of Nevada Las Vegas: https://guides.library.unlv.edu/open-refine/getting-started\nUniversity of Illinois Urbana-Champaign: https://guides.library.illinois.edu/openrefine"
  },
  {
    "objectID": "exercises/ex-04.html",
    "href": "exercises/ex-04.html",
    "title": "Exercise 4: Comparing ORD Platforms",
    "section": "",
    "text": "…"
  },
  {
    "objectID": "exercises/ex-04.html#the-reusers-perspective-ogd",
    "href": "exercises/ex-04.html#the-reusers-perspective-ogd",
    "title": "Exercise 4: The Reuser’s Perspective (OGD)",
    "section": "",
    "text": "(…)\n\n\n\nCreate a dashboard on visualize.admin.ch\n\n\n\nGo to the LINDAS SPARQL Endpoint."
  },
  {
    "objectID": "assignments/template.html",
    "href": "assignments/template.html",
    "title": "My title",
    "section": "",
    "text": "NoteLegacy Content\n\n\n\nThe assessment method has been amended. This page is simply being kept for archival purposes."
  },
  {
    "objectID": "assignments/template.html#introduction",
    "href": "assignments/template.html#introduction",
    "title": "My title",
    "section": "Introduction",
    "text": "Introduction\n\nSpecify your assigned use case number (all)\nIdentify your approved dataset(s) (UC15)\nExplain the selection rationale and significance (UC15)\nState your research objectives (UC15)\nIntroduce the context and significance of your analysis (UC01-UC14)"
  },
  {
    "objectID": "assignments/template.html#background",
    "href": "assignments/template.html#background",
    "title": "My title",
    "section": "Background",
    "text": "Background\nFor use case analysis:\n\nRelevant policies and frameworks\nCurrent state of practice\nKey stakeholders\n\nFor dataset analysis:\n\nDataset provenance and context\nData provider background\nCurrent applications"
  },
  {
    "objectID": "assignments/template.html#methodology",
    "href": "assignments/template.html#methodology",
    "title": "My title",
    "section": "Methodology",
    "text": "Methodology\nFor use case analysis:\n\nAnalysis framework\nComparison criteria\nInformation sources\n\nFor dataset analysis:\n\nData processing steps\nAnalysis methods"
  },
  {
    "objectID": "assignments/template.html#discussion",
    "href": "assignments/template.html#discussion",
    "title": "My title",
    "section": "Discussion",
    "text": "Discussion\n\nImplications for stakeholders\nBest practices identified\nRecommendations\nFuture opportunities"
  },
  {
    "objectID": "assignments/template.html#conclusion",
    "href": "assignments/template.html#conclusion",
    "title": "My title",
    "section": "Conclusion",
    "text": "Conclusion\nSummarise key findings and their significance for open data practices."
  },
  {
    "objectID": "assignments.html",
    "href": "assignments.html",
    "title": "Students’ Papers",
    "section": "",
    "text": "NoteLegacy Content\n\n\n\nGiven that the open publication of students’ papers on the website did not prove very successful in 2024–2025, this page is simply being kept for archival purposes.\n\n\n\nStudents’ Papers\nThis space is reserved for work submitted by students of the course 7C2-CT-4A Introduction to Open Data who have agreed to have their short papers published here.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMy title\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2099\n\n\n\n\n\n\n\n\n\n\n\n\nSwiss Public Transportation Data\n\n\nAnalysis of SBB’s Open Data Usage in Third-Party Applications\n\n\n\n\n\n\n\n\nMar 14, 2025\n\n\n\n\n\nNo matching items\n Back to top"
  },
  {
    "objectID": "LICENSE-MIT.html",
    "href": "LICENSE-MIT.html",
    "title": "Introduction to Open Data",
    "section": "",
    "text": "MIT License\nCopyright (c) 2025 Julien A. Raemy\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n Back to top"
  },
  {
    "objectID": "LICENSE-CCBY.html",
    "href": "LICENSE-CCBY.html",
    "title": "Introduction to Open Data",
    "section": "",
    "text": "Attribution 4.0 International\n=======================================================================\nCreative Commons Corporation (“Creative Commons”) is not a law firm and does not provide legal services or legal advice. Distribution of Creative Commons public licenses does not create a lawyer-client or other relationship. Creative Commons makes its licenses and related information available on an “as-is” basis. Creative Commons gives no warranties regarding its licenses, any material licensed under their terms and conditions, or any related information. Creative Commons disclaims all liability for damages resulting from their use to the fullest extent possible.\nUsing Creative Commons Public Licenses\nCreative Commons public licenses provide a standard set of terms and conditions that creators and other rights holders may use to share original works of authorship and other material subject to copyright and certain other rights specified in the public license below. The following considerations are for informational purposes only, are not exhaustive, and do not form part of our licenses.\n Considerations for licensors: Our public licenses are\n intended for use by those authorized to give the public\n permission to use material in ways otherwise restricted by\n copyright and certain other rights. Our licenses are\n irrevocable. Licensors should read and understand the terms\n and conditions of the license they choose before applying it.\n Licensors should also secure all rights necessary before\n applying our licenses so that the public can reuse the\n material as expected. Licensors should clearly mark any\n material not subject to the license. This includes other CC-\n licensed material, or material used under an exception or\n limitation to copyright. More considerations for licensors:\nwiki.creativecommons.org/Considerations_for_licensors\n\n Considerations for the public: By using one of our public\n licenses, a licensor grants the public permission to use the\n licensed material under specified terms and conditions. If\n the licensor's permission is not necessary for any reason--for\n example, because of any applicable exception or limitation to\n copyright--then that use is not regulated by the license. Our\n licenses grant only permissions under copyright and certain\n other rights that a licensor has authority to grant. Use of\n the licensed material may still be restricted for other\n reasons, including because others have copyright or other\n rights in the material. A licensor may make special requests,\n such as asking that all changes be marked or described.\n Although not required by our licenses, you are encouraged to\n respect those requests where reasonable. More_considerations\n for the public:\nwiki.creativecommons.org/Considerations_for_licensees\n=======================================================================\nCreative Commons Attribution 4.0 International Public License\nBy exercising the Licensed Rights (defined below), You accept and agree to be bound by the terms and conditions of this Creative Commons Attribution 4.0 International Public License (“Public License”). To the extent this Public License may be interpreted as a contract, You are granted the Licensed Rights in consideration of Your acceptance of these terms and conditions, and the Licensor grants You such rights in consideration of benefits the Licensor receives from making the Licensed Material available under these terms and conditions.\nSection 1 – Definitions.\n\nAdapted Material means material subject to Copyright and Similar Rights that is derived from or based upon the Licensed Material and in which the Licensed Material is translated, altered, arranged, transformed, or otherwise modified in a manner requiring permission under the Copyright and Similar Rights held by the Licensor. For purposes of this Public License, where the Licensed Material is a musical work, performance, or sound recording, Adapted Material is always produced where the Licensed Material is synched in timed relation with a moving image.\nAdapter’s License means the license You apply to Your Copyright and Similar Rights in Your contributions to Adapted Material in accordance with the terms and conditions of this Public License.\nCopyright and Similar Rights means copyright and/or similar rights closely related to copyright including, without limitation, performance, broadcast, sound recording, and Sui Generis Database Rights, without regard to how the rights are labeled or categorized. For purposes of this Public License, the rights specified in Section 2(b)(1)-(2) are not Copyright and Similar Rights.\nEffective Technological Measures means those measures that, in the absence of proper authority, may not be circumvented under laws fulfilling obligations under Article 11 of the WIPO Copyright Treaty adopted on December 20, 1996, and/or similar international agreements.\nExceptions and Limitations means fair use, fair dealing, and/or any other exception or limitation to Copyright and Similar Rights that applies to Your use of the Licensed Material.\nLicensed Material means the artistic or literary work, database, or other material to which the Licensor applied this Public License.\nLicensed Rights means the rights granted to You subject to the terms and conditions of this Public License, which are limited to all Copyright and Similar Rights that apply to Your use of the Licensed Material and that the Licensor has authority to license.\nLicensor means the individual(s) or entity(ies) granting rights under this Public License.\nShare means to provide material to the public by any means or process that requires permission under the Licensed Rights, such as reproduction, public display, public performance, distribution, dissemination, communication, or importation, and to make material available to the public including in ways that members of the public may access the material from a place and at a time individually chosen by them.\nSui Generis Database Rights means rights other than copyright resulting from Directive 96/9/EC of the European Parliament and of the Council of 11 March 1996 on the legal protection of databases, as amended and/or succeeded, as well as other essentially equivalent rights anywhere in the world.\nYou means the individual or entity exercising the Licensed Rights under this Public License. Your has a corresponding meaning.\n\nSection 2 – Scope.\n\nLicense grant.\n\nSubject to the terms and conditions of this Public License, the Licensor hereby grants You a worldwide, royalty-free, non-sublicensable, non-exclusive, irrevocable license to exercise the Licensed Rights in the Licensed Material to:\n\nreproduce and Share the Licensed Material, in whole or in part; and\nproduce, reproduce, and Share Adapted Material.\n\nExceptions and Limitations. For the avoidance of doubt, where Exceptions and Limitations apply to Your use, this Public License does not apply, and You do not need to comply with its terms and conditions.\nTerm. The term of this Public License is specified in Section 6(a).\nMedia and formats; technical modifications allowed. The Licensor authorizes You to exercise the Licensed Rights in all media and formats whether now known or hereafter created, and to make technical modifications necessary to do so. The Licensor waives and/or agrees not to assert any right or authority to forbid You from making technical modifications necessary to exercise the Licensed Rights, including technical modifications necessary to circumvent Effective Technological Measures. For purposes of this Public License, simply making modifications authorized by this Section 2(a)\n\nnever produces Adapted Material.\n\nDownstream recipients.\n\nOffer from the Licensor – Licensed Material. Every recipient of the Licensed Material automatically receives an offer from the Licensor to exercise the Licensed Rights under the terms and conditions of this Public License.\nNo downstream restrictions. You may not offer or impose any additional or different terms or conditions on, or apply any Effective Technological Measures to, the Licensed Material if doing so restricts exercise of the Licensed Rights by any recipient of the Licensed Material.\n\nNo endorsement. Nothing in this Public License constitutes or may be construed as permission to assert or imply that You are, or that Your use of the Licensed Material is, connected with, or sponsored, endorsed, or granted official status by, the Licensor or others designated to receive attribution as provided in Section 3(a)(1)(A)(i).\n\nOther rights.\n\nMoral rights, such as the right of integrity, are not licensed under this Public License, nor are publicity, privacy, and/or other similar personality rights; however, to the extent possible, the Licensor waives and/or agrees not to assert any such rights held by the Licensor to the limited extent necessary to allow You to exercise the Licensed Rights, but not otherwise.\nPatent and trademark rights are not licensed under this Public License.\nTo the extent possible, the Licensor waives any right to collect royalties from You for the exercise of the Licensed Rights, whether directly or through a collecting society under any voluntary or waivable statutory or compulsory licensing scheme. In all other cases the Licensor expressly reserves any right to collect such royalties.\n\n\nSection 3 – License Conditions.\nYour exercise of the Licensed Rights is expressly made subject to the following conditions.\n\nAttribution.\n\nIf You Share the Licensed Material (including in modified form), You must:\n\nretain the following if it is supplied by the Licensor with the Licensed Material:\n\nidentification of the creator(s) of the Licensed Material and any others designated to receive attribution, in any reasonable manner requested by the Licensor (including by pseudonym if designated);\na copyright notice;\na notice that refers to this Public License;\na notice that refers to the disclaimer of warranties;\na URI or hyperlink to the Licensed Material to the extent reasonably practicable;\n\nindicate if You modified the Licensed Material and retain an indication of any previous modifications; and\nindicate the Licensed Material is licensed under this Public License, and include the text of, or the URI or hyperlink to, this Public License.\n\nYou may satisfy the conditions in Section 3(a)(1) in any reasonable manner based on the medium, means, and context in which You Share the Licensed Material. For example, it may be reasonable to satisfy the conditions by providing a URI or hyperlink to a resource that includes the required information.\nIf requested by the Licensor, You must remove any of the information required by Section 3(a)(1)(A) to the extent reasonably practicable.\nIf You Share Adapted Material You produce, the Adapter’s License You apply must not prevent recipients of the Adapted Material from complying with this Public License.\n\n\nSection 4 – Sui Generis Database Rights.\nWhere the Licensed Rights include Sui Generis Database Rights that apply to Your use of the Licensed Material:\n\nfor the avoidance of doubt, Section 2(a)(1) grants You the right to extract, reuse, reproduce, and Share all or a substantial portion of the contents of the database;\nif You include all or a substantial portion of the database contents in a database in which You have Sui Generis Database Rights, then the database in which You have Sui Generis Database Rights (but not its individual contents) is Adapted Material; and\nYou must comply with the conditions in Section 3(a) if You Share all or a substantial portion of the contents of the database.\n\nFor the avoidance of doubt, this Section 4 supplements and does not replace Your obligations under this Public License where the Licensed Rights include other Copyright and Similar Rights.\nSection 5 – Disclaimer of Warranties and Limitation of Liability.\n\nUNLESS OTHERWISE SEPARATELY UNDERTAKEN BY THE LICENSOR, TO THE EXTENT POSSIBLE, THE LICENSOR OFFERS THE LICENSED MATERIAL AS-IS AND AS-AVAILABLE, AND MAKES NO REPRESENTATIONS OR WARRANTIES OF ANY KIND CONCERNING THE LICENSED MATERIAL, WHETHER EXPRESS, IMPLIED, STATUTORY, OR OTHER. THIS INCLUDES, WITHOUT LIMITATION, WARRANTIES OF TITLE, MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, NON-INFRINGEMENT, ABSENCE OF LATENT OR OTHER DEFECTS, ACCURACY, OR THE PRESENCE OR ABSENCE OF ERRORS, WHETHER OR NOT KNOWN OR DISCOVERABLE. WHERE DISCLAIMERS OF WARRANTIES ARE NOT ALLOWED IN FULL OR IN PART, THIS DISCLAIMER MAY NOT APPLY TO YOU.\nTO THE EXTENT POSSIBLE, IN NO EVENT WILL THE LICENSOR BE LIABLE TO YOU ON ANY LEGAL THEORY (INCLUDING, WITHOUT LIMITATION, NEGLIGENCE) OR OTHERWISE FOR ANY DIRECT, SPECIAL, INDIRECT, INCIDENTAL, CONSEQUENTIAL, PUNITIVE, EXEMPLARY, OR OTHER LOSSES, COSTS, EXPENSES, OR DAMAGES ARISING OUT OF THIS PUBLIC LICENSE OR USE OF THE LICENSED MATERIAL, EVEN IF THE LICENSOR HAS BEEN ADVISED OF THE POSSIBILITY OF SUCH LOSSES, COSTS, EXPENSES, OR DAMAGES. WHERE A LIMITATION OF LIABILITY IS NOT ALLOWED IN FULL OR IN PART, THIS LIMITATION MAY NOT APPLY TO YOU.\nThe disclaimer of warranties and limitation of liability provided above shall be interpreted in a manner that, to the extent possible, most closely approximates an absolute disclaimer and waiver of all liability.\n\nSection 6 – Term and Termination.\n\nThis Public License applies for the term of the Copyright and Similar Rights licensed here. However, if You fail to comply with this Public License, then Your rights under this Public License terminate automatically.\nWhere Your right to use the Licensed Material has terminated under Section 6(a), it reinstates:\n\nautomatically as of the date the violation is cured, provided it is cured within 30 days of Your discovery of the violation; or\nupon express reinstatement by the Licensor.\n\nFor the avoidance of doubt, this Section 6(b) does not affect any right the Licensor may have to seek remedies for Your violations of this Public License.\nFor the avoidance of doubt, the Licensor may also offer the Licensed Material under separate terms or conditions or stop distributing the Licensed Material at any time; however, doing so will not terminate this Public License.\nSections 1, 5, 6, 7, and 8 survive termination of this Public License.\n\nSection 7 – Other Terms and Conditions.\n\nThe Licensor shall not be bound by any additional or different terms or conditions communicated by You unless expressly agreed.\nAny arrangements, understandings, or agreements regarding the Licensed Material not stated herein are separate from and independent of the terms and conditions of this Public License.\n\nSection 8 – Interpretation.\n\nFor the avoidance of doubt, this Public License does not, and shall not be interpreted to, reduce, limit, restrict, or impose conditions on any use of the Licensed Material that could lawfully be made without permission under this Public License.\nTo the extent possible, if any provision of this Public License is deemed unenforceable, it shall be automatically reformed to the minimum extent necessary to make it enforceable. If the provision cannot be reformed, it shall be severed from this Public License without affecting the enforceability of the remaining terms and conditions.\nNo term or condition of this Public License will be waived and no failure to comply consented to unless expressly agreed to by the Licensor.\nNothing in this Public License constitutes or may be interpreted as a limitation upon, or waiver of, any privileges and immunities that apply to the Licensor or You, including from the legal processes of any jurisdiction or authority.\n\n=======================================================================\nCreative Commons is not a party to its public licenses. Notwithstanding, Creative Commons may elect to apply one of its public licenses to material it publishes and in those instances will be considered the “Licensor.” The text of the Creative Commons public licenses is dedicated to the public domain under the CC0 Public Domain Dedication. Except for the limited purpose of indicating that material is shared under a Creative Commons public license or as otherwise permitted by the Creative Commons policies published at creativecommons.org/policies, Creative Commons does not authorize the use of the trademark “Creative Commons” or any other trademark or logo of Creative Commons without its prior written consent including, without limitation, in connection with any unauthorized modifications to any of its public licenses or any other arrangements, understandings, or agreements concerning use of licensed material. For the avoidance of doubt, this paragraph does not form part of the public licenses.\nCreative Commons may be contacted at creativecommons.org.\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is the third iteration of the Introduction to Open Data course and the second in website format. Originally created as a Markdown-based presentation (Raemy, 2024), the course was first adapted into a website and now continues to evolve. While the core content from the original presentation remains valuable, this version introduces a restructured approach to hopefully better serve learners’ needs.\nThis Quarto-based site maintains essential concepts while offering improved layout, accessibility, and the capacity for ongoing refinement as the open data landscape develops."
  },
  {
    "objectID": "about.html#about-this-website",
    "href": "about.html#about-this-website",
    "title": "About",
    "section": "",
    "text": "This is the third iteration of the Introduction to Open Data course and the second in website format. Originally created as a Markdown-based presentation (Raemy, 2024), the course was first adapted into a website and now continues to evolve. While the core content from the original presentation remains valuable, this version introduces a restructured approach to hopefully better serve learners’ needs.\nThis Quarto-based site maintains essential concepts while offering improved layout, accessibility, and the capacity for ongoing refinement as the open data landscape develops."
  },
  {
    "objectID": "about.html#about-the-instructor",
    "href": "about.html#about-the-instructor",
    "title": "About",
    "section": "About the Instructor",
    "text": "About the Instructor\nDr. Julien A. Raemy is a Cultural Heritage and Digital Preservation Expert. He currently works as a Digital Archiving Project Manager at docuteam. He also holds an appointment as an Associate Researcher in Digital Humanities at the University of Bern (Walter Benjamin Kolleg).\nHe completed his PhD in 2024 at the Digital Humanities Lab of the University of Basel with a dissertation on Linked Open Usable Data (LOUD). Previously, he earned a Bachelor’s and Master’s degree in Information Science from the HES-SO University of Applied Sciences and Arts of Western Switzerland.\nJulien A. Raemy has worked extensively in academia and in or for the cultural heritage domain, including as a Photo Archivist for the Montreux Jazz Digital Project at the École Polytechnique Fédérale de Lausanne (EPFL), as a Research and Teaching Assistant at the Haute école de gestion de Genève (HEG-GE), as a Knowledge Graph Engineer at the University of Zurich’s Swiss Art Research Infrastructure (SARI), as an Interoperability Specialist at DaSCH, Swiss National Data and Service Center for the Humanities, as well as a Data Scientist and Project Manager for the Swiss Federal Archives.\nIn addition, he is actively engaged in the International Image Interoperability Framework (IIIF) and is a member of the Linked Art Editorial Board."
  },
  {
    "objectID": "about.html#host-institution",
    "href": "about.html#host-institution",
    "title": "About",
    "section": "Host Institution",
    "text": "Host Institution\nThis course is held at:\nHaute école de gestion de Genève (HEG-GE)  Campus Battelle  Rue de la Tambourine 17  CH-1227 Carouge  Switzerland"
  },
  {
    "objectID": "assignments/OpenData_SBB_Assess_AubD.html",
    "href": "assignments/OpenData_SBB_Assess_AubD.html",
    "title": "Swiss Public Transportation Data",
    "section": "",
    "text": "Public transportation plays a crucial role in Switzerland’s mobility infrastructure, with Swiss Federal Railways (SBB) being a key operator. To enhance transparency, innovation, and efficiency, SBB has adopted an open data policy, allowing public access to a variety of transportation datasets. This initiative aligns with Switzerland’s broader commitment to digital transformation and smart mobility solutions.\nThe SBB Open Data platform provides datasets that include timetables, real-time vehicle positions, historical travel data, and station information. These datasets are used by third-party developers to create applications that improve user experience, optimize travel routes, and integrate multimodal transport options.\nThis assessment aims to analyse the significance of SBB’s open data, examining its use in third-party applications, identifying the benefits and challenges, and discussing its potential for future developments."
  },
  {
    "objectID": "assignments/OpenData_SBB_Assess_AubD.html#overview-of-sbbs-open-data",
    "href": "assignments/OpenData_SBB_Assess_AubD.html#overview-of-sbbs-open-data",
    "title": "Swiss Public Transportation Data",
    "section": "Overview of SBB’s Open Data",
    "text": "Overview of SBB’s Open Data\nThe SBB Open Data initiative provides access to various datasets through APIs and downloadable files. The main types of data include:\n\nGTFS (General Transit Feed Specification): Static timetable data used by route planning applications.\nGTFS-RT (General Transit Feed Specification Real-Time): Live updates on train positions, delays, and disruptions.\nHAFAS Realtime API: High-quality real-time journey planning data.\nStation Information: Details on station facilities, accessibility, and services.\nPassenger Flow Data: Historical data on passenger movements for analysis and optimization.\n\nThese datasets are available in formats such as CSV, JSON, and XML, making them accessible for integration into various digital platforms.\nThe SBB data are available on the following platforms:\n\nOpen data platform mobility Switzerland\nSBB Open Data platform\nSBB API Platform\nopendata.swiss\n\n\nAccessing SBB Data as a user\nFor individuals who wants to explore SBB’s open datasets manually, he can follow these steps:\n\nVisit the SBB Open Data Portal\n\nThe homepage provides an overview of available datasets and categories.\nAll datasets are listed in under the tab “Data”\n\nBrowse or Search for Dataset\n\nUse the search bar or choose the category in the homepage or use the filter datasets available under the tab “Data”\nClick on a dataset to access metadata, descriptions, and downloadable files.\n\nDownload Data\n\nMost datasets are available in formats like CSV, JSON, or XML.\nClick “Download” to retrieve static datasets for analysis in Excel, Python, or other tools.\n\nExplore Data Visualization\n\nSome datasets include built-in charts or maps to provide an interactive preview of the data.\n\n\n\n\nAccessing SBB Data Programmatically (Machines & Developers)\nFor developers and automated systems, SBB provides APIs and machine-readable formats for :\n1. Using APIs for Real-Time Data Access\nSBB offers several APIs through the SBB Developer Portal, which require an authentication :\n\nRegister for API Access\n\nDevelopers must create an account at SBB Developer Portal.\nAPI keys may be required for certain datasets.\n\nFetch Real-Time Data via API Requests\n\nOnce registered, developers can access data via HTTP requests or using Python scripts\n\nData Formats for Integration SBB’s, APIs typically return data in:\n\nJSON: Ideal for web and mobile applications.\nXML: Used in enterprise transport management systems.\nGTFS-RT: Standardized format for public transport apps like Google Maps and Citymapper.\n\n\n2. Downloading Static Datasets\nFor historical analysis or offline applications:\n\nDirect download links (CSV, JSON) are provided in dataset pages.\nExample dataset URL:\n\nOccupancy Forecast Dataset: https://data.opentransportdata.swiss/en/dataset/occupancy-forecast-json-dataset\n\n\n\n\nDemonstration visualization of Train Occupancy Levels\nTo analyze train occupancy levels, I developed an interactive dashboard using Dash and Plotly. The dashboard features two separate pie charts, as shown in Figure 1, illustrating the occupancy distribution for a train journey for first-class and second-class seating.\n\n\n\nFigure 1: First-Class and Second-Class Occupancy Distribution\n\n\n\nDescription of the Visualization\nThe pie charts categorize the occupancy levels into three main groups:\n“unknown”: No forecast available.\n“manySeatsAvailable”: low occupancy, corresponds to one manikin symbol.\n“fewSeatsAvailable”: medium occupancy, corresponds to manikins.\n“standingRoomOnly”: high occupancy, corresponds to three manikins.\nThe following Python code snippet was used to generate the dash board:\nimport os\nimport json\nimport pandas as pd\nimport dash\nfrom dash import dcc, html, dash_table, Input, Output\nimport plotly.express as px\n\n# Define the data directory\ndata_dir = \"file_path//occupancyforecastjson\"\n\n# Initialize Dash app\napp = dash.Dash(__name__)\napp.title = \"SBB Occupancy Forecast Dashboard\"\n\n# Layout\napp.layout = html.Div([\n    html.H1(\"SBB Occupancy Forecast Dashboard\", style={'textAlign': 'center'}),\n    \n    # Date Picker\n    dcc.DatePickerSingle(\n        id='date-picker',\n        min_date_allowed=pd.to_datetime(\"2025-03-11\"),\n        max_date_allowed=pd.to_datetime(\"2025-12-31\"),\n        initial_visible_month=pd.to_datetime(\"2025-03-11\"),\n        date=pd.to_datetime(\"2025-03-11\").date()\n    ),\n    \n    # Dropdowns for filtering\n    dcc.Dropdown(id='train-filter', placeholder=\"Select Train Number\"),\n    dcc.Dropdown(id='station-filter', placeholder=\"Select Station\"),\n    \n    # Data Table\n    dash_table.DataTable(id='train-table',\n                         columns=[\n                             {\"name\": \"Train Number\", \"id\": \"trainNumber\"},\n                             {\"name\": \"Departure\", \"id\": \"departureStationName\"},\n                             {\"name\": \"Destination\", \"id\": \"destinationStationName\"},\n                             {\"name\": \"Departure Time\", \"id\": \"departureTime\"},\n                             {\"name\": \"First Class\", \"id\": \"firstClass\"},\n                             {\"name\": \"Second Class\", \"id\": \"secondClass\"}\n                         ],\n                         page_size=10),\n    \n    # Simple Charts\n    html.Div([\n        dcc.Graph(id='first-class-pie-chart', style={'display': 'inline-block', 'width': '48%'}),\n        dcc.Graph(id='second-class-pie-chart', style={'display': 'inline-block', 'width': '48%'})\n    ])\n])\n\n# Callback to load data based on selected date\n@app.callback(\n    [Output('train-filter', 'options'),\n     Output('station-filter', 'options'),\n     Output('train-table', 'data'),\n     Output('first-class-pie-chart', 'figure'),\n     Output('second-class-pie-chart', 'figure')],\n    [Input('date-picker', 'date'),\n     Input('train-filter', 'value'),\n     Input('station-filter', 'value')]\n)\ndef update_dashboard(selected_date, train_num, station):\n    date_folder = os.path.join(data_dir, selected_date)\n    if not os.path.exists(date_folder):\n        return [], [], [], px.pie(title=\"No Data\"), px.pie(title=\"No Data\")\n    \n    all_data = []\n    for file in os.listdir(date_folder):\n        with open(os.path.join(date_folder, file), 'r') as f:\n            data = json.load(f)\n            for train in data.get(\"trains\", []):\n                for section in train.get(\"sections\", []):\n                    all_data.append({\n                        \"trainNumber\": train[\"trainNumber\"],\n                        \"departureStationName\": section[\"departureStationName\"],\n                        \"destinationStationName\": section[\"destinationStationName\"],\n                        \"departureTime\": section[\"departureTime\"],\n                        \"firstClass\": next((o[\"occupancyLevel\"] for o in section[\"expectedDepartureOccupancies\"] if o[\"fareClass\"] == \"firstClass\"), \"Unknown\"),\n                        \"secondClass\": next((o[\"occupancyLevel\"] for o in section[\"expectedDepartureOccupancies\"] if o[\"fareClass\"] == \"secondClass\"), \"Unknown\")\n                    })\n    \n    df = pd.DataFrame(all_data)\n    \n    # Filtering\n    if train_num:\n        df = df[df['trainNumber'] == train_num]\n    if station:\n        df = df[(df['departureStationName'] == station) | (df['destinationStationName'] == station)]\n    \n    train_options = [{'label': t, 'value': t} for t in df['trainNumber'].unique()]\n    station_options = [{'label': s, 'value': s} for s in pd.concat([df['departureStationName'], df['destinationStationName']]).unique()]\n    \n    # Pie Charts for First and Second Class\n    first_class_counts = df['firstClass'].value_counts().reset_index()\n    first_class_counts.columns = ['Occupancy', 'Count']\n    first_class_pie = px.pie(first_class_counts, names='Occupancy', values='Count', title='First Class Occupancy')\n    \n    second_class_counts = df['secondClass'].value_counts().reset_index()\n    second_class_counts.columns = ['Occupancy', 'Count']\n    second_class_pie = px.pie(second_class_counts, names='Occupancy', values='Count', title='Second Class Occupancy')\n    \n    return train_options, station_options, df.to_dict('records'), first_class_pie, second_class_pie\n\n# Run the app\nif __name__ == '__main__':\n    app.run_server(debug=True)"
  },
  {
    "objectID": "assignments/OpenData_SBB_Assess_AubD.html#use-cases-in-third-party-applications",
    "href": "assignments/OpenData_SBB_Assess_AubD.html#use-cases-in-third-party-applications",
    "title": "Swiss Public Transportation Data",
    "section": "Use Cases in Third-Party Applications",
    "text": "Use Cases in Third-Party Applications\nSBB’s open data has been widely adopted by third-party developers to enhance public transportation accessibility and efficiency. Some key applications include:\n\nPublic Transport Navigation Apps\n\nGoogle Maps & Citymapper: Use SBB’s GTFS data for real-time trip planning, route suggestions, and multimodal transport integration (trains, buses, trams).\nÖV Plus: A Swiss-specific app that provides real-time alerts, ticketing services, and personalized travel recommendations.\nSBB Mobile: While developed by SBB itself, it integrates third-party mobility services (e.g., e-scooters, bike-sharing).\n\nSmart Mobility and Multimodal Transport Solutions\n\nSwiss Travel Guide: Combines SBB train schedules with local tourism insights, helping visitors plan their trips efficiently.\nTrafi & FAIRTIQ: Integrate SBB’s fare and real-time data to provide automatic, ticketless travel payment solutions.\n\nData-Driven Urban Planning & Sustainability Applications\n\nTraffic Flow Analysis: Government agencies and researchers use historical passenger flow data to optimize infrastructure and manage congestion.\nEco-Routing & CO₂ Reduction Apps: Some startups leverage SBB’s data to promote sustainable travel choices by calculating the lowest-emission routes."
  },
  {
    "objectID": "assignments/OpenData_SBB_Assess_AubD.html#benefits-of-sbb-open-data-usage",
    "href": "assignments/OpenData_SBB_Assess_AubD.html#benefits-of-sbb-open-data-usage",
    "title": "Swiss Public Transportation Data",
    "section": "Benefits of SBB Open Data Usage",
    "text": "Benefits of SBB Open Data Usage\n\nFor Improving User Experience\n\nBetter route planning: Users get real-time updates and alternative routes in case of disruptions.\nIncreased accessibility: Third-party apps enable multilingual, user-friendly interfaces.\n\nFor Encouraging Innovation\n\nStartups and developers benefit from free access to transport data, reducing barriers to entry for new mobility solutions.\nIntegration with AI and predictive analytics enables smarter, more efficient public transport systems.\n\nFor Public Sector & Economic Benefits\n\nMore efficient urban planning by municipalities.\nCost savings in infrastructure by optimizing transport flow through data-driven decisions."
  },
  {
    "objectID": "assignments/OpenData_SBB_Assess_AubD.html#challenges-and-limitations",
    "href": "assignments/OpenData_SBB_Assess_AubD.html#challenges-and-limitations",
    "title": "Swiss Public Transportation Data",
    "section": "Challenges and Limitations",
    "text": "Challenges and Limitations\n\nData Quality and Reliability Issues\n\nLatency in real-time updates: Delays in GTFS-RT data can lead to inaccurate predictions.\nIncomplete data sets: Some detailed real-time tracking (e.g., passenger load) is not publicly available.\n\nPrivacy and Security Concerns\n\nSensitive data handling: Apps must ensure compliance with Swiss and EU GDPR regulations to protect user location data.\nPotential misuse: Open data can be exploited for unauthorized commercial purposes.\n\nTechnical and Integration Barriers\n\nData standardization issues: Ensuring compatibility between SBB data and international transport networks (e.g., Deutsche Bahn, SNCF) remains a challenge.\nAPI rate limits: Developers may face restrictions on data requests, affecting large-scale applications."
  },
  {
    "objectID": "exercises/ex-01.html",
    "href": "exercises/ex-01.html",
    "title": "Exercise 1: OA Deep Dive",
    "section": "",
    "text": "You have five minutes to read the section on Open Access (OA) on the Associated Movements page. Then, you can individually take the quiz below.\n\n\n\n\n\n\nNoteInstructions\n\n\n\nThe quiz contains 12 questions with a time limit for each question (15-25 seconds). The maximum possible score is 1200 points, which are awarded based on both accuracy and speed. After completing the quiz, note your total points and number of correct answers for discussion."
  },
  {
    "objectID": "exercises/ex-01.html#oa-deep-dive",
    "href": "exercises/ex-01.html#oa-deep-dive",
    "title": "Exercise 1: OA Deep Dive",
    "section": "",
    "text": "You have five minutes to read the section on Open Access (OA) on the Associated Movements page. Then, you can individually take the quiz below.\n\n\n\n\n\n\nNoteInstructions\n\n\n\nThe quiz contains 12 questions with a time limit for each question (15-25 seconds). The maximum possible score is 1200 points, which are awarded based on both accuracy and speed. After completing the quiz, note your total points and number of correct answers for discussion."
  },
  {
    "objectID": "exercises/ex-05.html",
    "href": "exercises/ex-05.html",
    "title": "Exercise 5: The Reuser’s Perspective (OGD)",
    "section": "",
    "text": "(…)\n\n\n\nCreate a dashboard on visualize.admin.ch\n\n\n\nGo to the LINDAS SPARQL Endpoint."
  },
  {
    "objectID": "exercises/ex-05.html#reading-assignment",
    "href": "exercises/ex-05.html#reading-assignment",
    "title": "Exercise 5: Reading Assignment",
    "section": "",
    "text": "(…)"
  },
  {
    "objectID": "exercises/ex-07.html",
    "href": "exercises/ex-07.html",
    "title": "Exercise 7: Open Refine",
    "section": "",
    "text": "Install the software (https://openrefine.org/docs)\nRun it locally (accessible at http://127.0.0.1:3333/)\nHave a look at the different pages and functionalities\nCreate a new project by importing any supported files\n\n\n\n\n\nCreate a new project by importing the Powerhouse Museum TSV file (https://zenodo.org/records/17047254/files/phm_collection_adapted.tsv) — remember to select “Tab-separated values”\nWhitespace detection: Use Facet by blank on the categories column, then apply Edit cells &gt; Common transforms &gt; Trim leading and trailing whitespace. Observe how “blank” cells are revealed.\nClustering: Create a Text facet on the category column. Click Cluster and use the “key collision” method to merge case inconsistencies (e.g., “Pottery” vs “pottery”).\nMulti-valued cells: Split the categories column by the separator | (pipe character). Count how many objects have more than 3 categories, then rejoin the cells.\n\n\n\n\n\nCreate a new project by importing the Met Museum CSV (https://github.com/metmuseum/openaccess) — use the first 5,000 rows for better performance\nReconcile artists: Select the Artist Display Name column. Start reconciling against Wikidata (service: https://wikidata.reconci.link/en/api, type: Q5 for humans).\nJudgment exercise: Auto-match high confidence scores (&gt;90), manually review medium scores (70-90) to distinguish between homonyms (e.g., different “John Smith” artists), and mark low scores (&lt;70) as “None”.\nExtract QIDs: Transform reconciled cells to extract just the QID number for external linking.\n\n\n\n\n\nCreate a new project by importing the manuscript CSV from https://raw.githubusercontent.com/emmamorlock/workshop/refs/heads/main/exercices/handouts/biblissima.csv\nExplore manuscript metadata: Review columns such as shelfmark, repository, author, and title. Create text facets to identify variations in repository names or author attributions.\nReconcile shelfmarks: Use the Biblissima reconciliation endpoint (https://data.biblissima.fr/api/reconcile, type: Manuscript) to match records against the Biblissima authority file. This connects your local shelfmarks to persistent URIs.\nEnrich with IIIF (optional extension): After reconciliation, use Edit column &gt; Add column by fetching URLs to retrieve JSON data from the reconciled Biblissima URIs. Parse the JSON to extract iiif_manifest_url fields where available.\n\nCf. Sajdak (2024).\n\n\n\n\nCreate a new project by importing a Smithsonian JSON file (not CSV) from https://github.com/Smithsonian/OpenAccess\nFlatten nested JSON: Convert nested paths (e.g., title.content) to flat columns using the transform expression: value.parseJson()['title']\nExtract media: Parse the JSON to find objects with images by extracting online_media.mediaCount\nReconcile topics: Match topic fields against Library of Congress Subject Headings (LCSH) using their reconciliation service.\n\n\n\n\n\nExport your cleaned datasets in both CSV and JSON formats\nExport the project history (OpenRefine project archive) to document your transformation steps\n\nMore information and tutorials on OpenRefine can be found on the following links:\n\nLibrary Carpentry website: https://librarycarpentry.org/lc-open-refine/\nUniversity of Nevada Las Vegas: https://guides.library.unlv.edu/open-refine/getting-started\nUniversity of Illinois Urbana-Champaign: https://guides.library.illinois.edu/openrefine"
  },
  {
    "objectID": "exercises/ex-07.html#iiif-ml",
    "href": "exercises/ex-07.html#iiif-ml",
    "title": "Exercise 7: IIIF & ML",
    "section": "",
    "text": "(…)"
  },
  {
    "objectID": "exercises/ex-03.html",
    "href": "exercises/ex-03.html",
    "title": "Exercise 3: Movements and Principles",
    "section": "",
    "text": "NoteInstructions\n\n\n\nSelect a proposition (A, B, C, etc.) for each framework. When you arere ready, click “Validate All” to see your results. While there may be overlap between them, each proposition corresponds to one main framework.\n\n\n\n\n\n\n\nLetter\nProposition\n\n\n\n\nA\nPersistent identifier assignment\n\n\nB\nCode sharing practices\n\n\nC\nEthical data stewardship\n\n\nD\nDeveloper-centric data accessibility\n\n\nE\nUnrestricted access to scholarly publications\n\n\nF\nDigital object interoperability\n\n\nG\nResearch transparency and reproducibility\n\n\n\n\n\n\n\nValidate All\n\n\n\n\n\n\n\nReset Exercise Show Answer Key\n\n\n\n\n\n\nFramework\n\n\nCorrect Match\n\n\n\n\n1. FLOSS\n\n\nB - Code sharing practices\n\n\n\n\n2. LOUD\n\n\nD - Developer-centric data accessibility\n\n\n\n\n3. OA\n\n\nE - Unrestricted access to scholarly publications\n\n\n\n\n4. FAIR\n\n\nA - Persistent identifier assignment\n\n\n\n\n5. Collections as Data\n\n\nF - Digital object interoperability\n\n\n\n\n6. CARE\n\n\nC - Ethical data stewardship\n\n\n\n\n7. Open Science\n\n\nG - Research transparency and reproducibility"
  },
  {
    "objectID": "exercises/ex-03.html#movements-and-principles",
    "href": "exercises/ex-03.html#movements-and-principles",
    "title": "Exercise 3: Movements and Principles",
    "section": "",
    "text": "NoteInstructions\n\n\n\nSelect a proposition (A, B, C, etc.) for each framework. When you arere ready, click “Validate All” to see your results. While there may be overlap between them, each proposition corresponds to one main framework.\n\n\n\n\n\n\n\nLetter\nProposition\n\n\n\n\nA\nPersistent identifier assignment\n\n\nB\nCode sharing practices\n\n\nC\nEthical data stewardship\n\n\nD\nDeveloper-centric data accessibility\n\n\nE\nUnrestricted access to scholarly publications\n\n\nF\nDigital object interoperability\n\n\nG\nResearch transparency and reproducibility\n\n\n\n\n\n\n\nValidate All\n\n\n\n\n\n\n\nReset Exercise Show Answer Key\n\n\n\n\n\n\nFramework\n\n\nCorrect Match\n\n\n\n\n1. FLOSS\n\n\nB - Code sharing practices\n\n\n\n\n2. LOUD\n\n\nD - Developer-centric data accessibility\n\n\n\n\n3. OA\n\n\nE - Unrestricted access to scholarly publications\n\n\n\n\n4. FAIR\n\n\nA - Persistent identifier assignment\n\n\n\n\n5. Collections as Data\n\n\nF - Digital object interoperability\n\n\n\n\n6. CARE\n\n\nC - Ethical data stewardship\n\n\n\n\n7. Open Science\n\n\nG - Research transparency and reproducibility"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "References\nThis is a comprehensive list of references used in the course materials and additional recommended reading.\n\n\nAlter, G., Rizzolo, F., & Schleidt, K. (2023). View points on data points: A shared vocabulary for cross-domain conversations on data and metadata. IASSIST Quarterly, 47(1), 1–39. https://doi.org/10.29173/iq1051\n\n\nAymon, D., Lam, D.-T., Marti, L., Maury-Laribière, P., Choirat, C., & de Fondeville, R. (2024). Lomas: A Platform for Confidential Analysis of Private Data. https://doi.org/10.48550/ARXIV.2406.17087\n\n\nBeigel, F. (2024, October 31). Cartographies for an inclusive Open Science. https://doi.org/10.1590/SciELOPreprints.10286\n\n\nBeigel, F. (2025, November 21). Towards an Inclusive Open Science. Infoclio.ch Conference 2025: Open Science in History - From Enlightenment to Artificial Intelligence, Bern, Switzerland.\n\n\nBerners-Lee, T. (1991, August 6). WorldWideWeb - executive summary. archive.md. https://archive.md/Lfopj\n\n\nBerners-Lee, T. (2006, July 27). Linked Data. W3C. https://www.w3.org/DesignIssues/LinkedData.html\n\n\nCandela, G. (2024). Browsing Linked Open Data in Cultural Heritage: A shareable visual configuration approach. Journal on Computing and Cultural Heritage, 3707647. https://doi.org/10.1145/3707647\n\n\nCandela, G., Gabriëls, N., Chambers, S., Dobreva, M., Ames, S., Ferriter, M., Fitzgerald, N., Harbo, V., Hofmann, K., Holownia, O., Irollo, A., Mahey, M., Manchester, E., Pham, T.-A., Potter, A., & Van Keer, E. (2023). A checklist to publish collections as data in GLAM institutions. Global Knowledge, Memory and Communication, ahead-of-print. https://doi.org/10.1108/GKMC-06-2023-0195\n\n\nCandela, G., Holownia, O., Odsbjerg, M., Cuper, M., Gabriëls, N., Hofmann, K., Gray, E. J., Chambers, S., & Mahey, M. (2025). Promoting Computational Access to Digital Collections in the Nordic and Baltic Countries: An Icelandic Use Case. Journal of Open Humanities Data, 11, 7. https://doi.org/10.5334/johd.261\n\n\nCarroll, S. R., Garba, I., Figueroa-Rodríguez, O. L., Holbrook, J., Lovett, R., Materechera, S., Parsons, M., Raseroka, K., Rodriguez-Lonebear, D., Rowe, R., Sara, R., Walker, J. D., Anderson, J., & Hudson, M. (2020). The CARE Principles for Indigenous Data Governance. Data Science Journal, 19(1), 43. https://doi.org/10.5334/dsj-2020-043\n\n\nCarroll, S. R., Herczog, E., Hudson, M., Russell, K., & Stall, S. (2021). Operationalizing the CARE and FAIR Principles for Indigenous data futures. Scientific Data, 8(1), 108. https://doi.org/10.1038/s41597-021-00892-0\n\n\nChen, M., & Floridi, L. (2013). An analysis of information visualisation. Synthese, 190(16), 3421–3438. https://doi.org/10.1007/s11229-012-0183-y\n\n\nConcordat Working Group. (2016). Concordat on Open Research Data. UK Research and Innovation. https://www.ukri.org/wp-content/uploads/2020/10/UKRI-020920-ConcordatonOpenResearchData.pdf\n\n\nDişli, M., & Candela, G. (2025). Copyright and Licencing for Cultural Heritage Collections As Data. Journal of Open Humanities Data, 11, 11. https://doi.org/10.5334/johd.263\n\n\nDişli, M., Gabriëls, N., Chambers, S., Ames, S., Knazook, B., & Candela, G. (2025). Exploring the adoption of collections as data in the GLAM context. Information Research an International Electronic Journal, 30, 65–77. https://doi.org/10.47989/ir30CoLIS52252\n\n\nDişli, M., Osti, G., Candela, G., & Zijdeman, R. (2025). From Linked Open Data to Collections as Data: A Reproducible Framework Using Federated Queries. Information Technology and Libraries, 44(4). https://doi.org/10.5860/ital.v44i4.17432\n\n\nEbner, H., & Palmér, M. (2014). An information model for managing resources and their metadata. Semantic Web, 5(3), 237–255. https://doi.org/10.3233/SW-120090\n\n\nFelsing, U., Fornaro, P., Frischknecht, M., & Raemy, J. A. (2023). Community and Interoperability at the Core of Sustaining Image Archives. Digital Humanities in the Nordic and Baltic Countries Publications, 5(1), 40–54. https://doi.org/10.5617/dhnbpub.10649\n\n\nFloridi, L. (2010). Information: A very short introduction. Oxford University Press.\n\n\nFOSTER. (2019). Open Science. In Foster Taxonomy. FACILITATE OPEN SCIENCE TRAINING FOR EUROPEAN RESEARCH. https://www.fosteropenscience.eu/taxonomy/term/100\n\n\nGantet, C. (2025, November 21). Transparence et ouverture ou fermeture : Pratiques et publics de la science, 1660-1800. Infoclio.ch Conference 2025: Open Science in History - From Enlightenment to Artificial Intelligence, Bern, Switzerland. https://www.infoclio.ch/fr/node/191149\n\n\nHaslhofer, B., Simon, R., Sanderson, R., & Sompel, H. V. de. (2011). The Open Annotation Collaboration (OAC) Model. 2011 Workshop on Multimedia on the Web, 5–9. https://doi.org/10.1109/MMWeb.2011.21\n\n\nIdehen, K. U. (2017, July 24). Semantic Web Layer Cake Tweak, Explained. OpenLink Software Blog. https://medium.com/openlink-software-blog/semantic-web-layer-cake-tweak-explained-6ba5c6ac3fab\n\n\nInterview — Explorer et enseigner l’Open Data avec Julien Raemy. (2025). https://www.bfs.admin.ch/content/bfs/fr/home/services/ogd/blog/2025-08-julien-raemy.html\n\n\nJullien, N. (2009). A Historical Analysis of the Emergence of Free Cooperative Software Production: In M. Pagani (Ed.), Encyclopedia of Multimedia Technology and Networking, Second Edition (pp. 605–612). IGI Global. https://doi.org/10.4018/978-1-60566-014-1.ch081\n\n\nKirstein, F., Stefanidis, K., Dittwald, B., Dutkowski, S., Urbanek, S., & Hauswirth, M. (2020). Piveau: A Large-Scale Open Data Management Platform Based on Semantic Web Technologies. In A. Harth, S. Kirrane, A.-C. Ngonga Ngomo, H. Paulheim, A. Rula, A. L. Gentile, P. Haase, & M. Cochez (Eds.), The Semantic Web (Vol. 12123, pp. 648–664). Springer International Publishing. https://doi.org/10.1007/978-3-030-49461-2_38\n\n\nKnöchelmann, M. (2019). Open Science in the Humanities, or: Open Humanities? Publications, 7(4), 65. https://doi.org/10.3390/publications7040065\n\n\nKnöchelmann, M. (2021). The Democratisation Myth: Open Access and the Solidification of Epistemic Injustices. Science & Technology Studies, 34(2), 65–89. https://doi.org/10.23987/sts.94964\n\n\nKnöchelmann, M. (2025, November 21). A Missed Revolution: Open Humanities and the Unforced Force of the Better Argument. Infoclio.ch Conference 2025: Open Science in History - From Enlightenment to Artificial Intelligence, Bern, Switzerland. https://www.infoclio.ch/en/missed-revolution-open-humanities-and-unforced-force-better-argument\n\n\nLoi fédérale sur l’utilisation des moyens électroniques pour l’exécution des tâches des autorités (LMETA), Pub. L. FF 2023 787, Confédération suisse. Secrétariat général DFF (2023). https://fedlex.data.admin.ch/eli/fga/2023/787\n\n\nMax Planck Society, & European Cultural Heritage Online. (2003). Berlin Declaration on Open Access to Knowledge in the Sciences and Humanities. Max Planck Society. https://openaccess.mpg.de/Berlin-Declaration\n\n\nMetcalfe Hurst, E. (2023). LUX: Yale Collections Discovery. ARLIS/NA Multimedia & Technology Reviews, 2023(4), 1–4. https://doi.org/10.17613/3hy1-pv45\n\n\nMJL. (2020). Creative commons license spectrum [Graphic]. https://commons.wikimedia.org/wiki/File:Creative_commons_license_spectrum.svg\n\n\nMoore, S. (2025a). Publishing Beyond the Market: Open Access, Care, and the Commons. University of Michigan Press. https://doi.org/10.3998/mpub.11781635\n\n\nMoore, S. (2025b, November 21). “Morphing” Open Science for the Humanities and Social Sciences. Infoclio.ch Conference 2025: Open Science in History - From Enlightenment to Artificial Intelligence, Bern, Switzerland. https://www.infoclio.ch/en/morphing-open-science-humanities-and-social-sciences\n\n\nMorrison, R. (2021). Redrawn slide from presentation of Ana Persic, Division of Science Policy and Capacity-Building (SC/PCB), UNESCO (France) presentation to Open Science Conference 2021, ZBW — Leibniz Information Centre for Economics, Germany. [Graphic]. https://commons.wikimedia.org/wiki/File:Osc2021-unesco-open-science-no-gray.png\n\n\nMr Gee. (2023, October 12). Day 2 Closing – A multitude of tools. EuropeanaTech 2023. EuropeanaTech 2023. https://youtu.be/pOX9CrvAG7I\n\n\nNewbury, D. (2018). LOUD: Linked Open Usable Data and linked.art. 2018 CIDOC Conference, 1–11. https://cidoc.mini.icom.museum/wp-content/uploads/sites/6/2021/03/CIDOC2018_paper_153.pdf\n\n\nOFS. (2023). Masterplan Open Government Data 2024-2027 (p. 24) [Masterplan OGD]. Office fédérale de la statistique. https://www.newsd.admin.ch/newsd/message/attachments/84864.pdf\n\n\nOpen Knowledge. (2016). The Open Data Handbook. Open Data Handbook. https://opendatahandbook.org/\n\n\nOpen Science Delegation. (2021a). Swiss National Open Research Data Strategy (p. 11). swissuniversities. https://www.swissuniversities.ch/fileadmin/swissuniversities/Dokumente/Hochschulpolitik/ORD/Swiss_National_ORD_Strategy_en.pdf\n\n\nOpen Science Delegation. (2021b). Swiss National Strategy Open Research Data: Action Plan (p. 11). swissuniversities. https://www.swissuniversities.ch/fileadmin/swissuniversities/Dokumente/Hochschulpolitik/ORD/ActionPlanV1.0_December_2021_def.pdf\n\n\nOxford English Dictionary. (2023a). Infrastructure. In Oxford English Dictionary (OED). Oxford University Press. https://doi.org/10.1093/OED/1206711036\n\n\nOxford English Dictionary. (2023b). Metadata. In Oxford English Dictionary (OED). Oxford University Press. https://doi.org/10.1093/OED/7968104326\n\n\nPadilla, T., Allen, L., Frost, H., Potvin, S., Russey Roke, E., & Varner, S. (2017). Always Already Computational: Collections as Data. Collections as Data. https://doi.org/10.17605/OSF.IO/MX6UK\n\n\nPadilla, T., Scates Kettler, H., & Shorish, Y. (2023). Collections as Data: Part to Whole (p. 19) [Final Report]. Always Already Computational - Collections as Data. https://doi.org/10.5281/zenodo.10161976\n\n\nPadilla, T., Scates Kettler, H., Varner, S., & Shorish, Y. (2023). Vancouver Statement on Collections as Data [White paper]. Internet Archive Canada. https://doi.org/10.5281/zenodo.8341519\n\n\nPage, M., Behrooz, A., & Moro, M. (2024a). 2024 Open Data Maturity Report [ODM Report]. European Union. https://doi.org/10.2830/8656811\n\n\nPage, M., Behrooz, A., & Moro, M. (2024b). Assessment Methodology - 2024 Open Data Maturity Report. European Union. https://doi.org/10.2830/7084880\n\n\nPage, M., Hajduk, E., Lincklaen Arriëns, E. N., Cecconi, G., & Brinkhuis, S. (2023). 2023 Open Data Maturity Report [ODM Report]. European Union. https://doi.org/10.2830/384422\n\n\nPersic, A. (Director). (2021, February). Building a Global Consensus on Open Science – the future UNESCO Recommendation on Open Science [Video recording]. https://doi.org/10.5446/53434\n\n\nPichot Damon, E. (2024, January 12). Table périodique : Les facteurs de succès d’un projet d’open data. open Datactivist. https://open.datactivist.coop/docs/tableau-periodique\n\n\nPievatolo, M. C. (2025, November 21). Science as “A Problem Not Yet Fully Resolved”: Universities and the Public Use of Reason Between Kant and Humboldt. Infoclio.ch Conference 2025: Open Science in History - From Enlightenment to Artificial Intelligence, Bern, Switzerland. https://doi.org/10.5281/zenodo.18070386\n\n\nRaemy, J. A. (2023). Characterising the IIIF and Linked Art Communities: Survey report (p. 29) [Report]. University of Basel. https://doi.org/10.5451/unibas-ep95340\n\n\nRaemy, J. A. (2024a). Linked Open Usable Data for Cultural Heritage: Perspectives on Community Practices and Semantic Interoperability [Doctoral Thesis, University of Basel]. https://hdl.handle.net/20.500.14716/148352\n\n\nRaemy, J. A. (2024b, March 12). Introduction to Open Data (2023-2024) [Course]. https://doi.org/10.5281/zenodo.10807519\n\n\nRaemy, Julien Antoine. (2025, April 11). Pédagogie de l’ouverture : Enseigner l’Open Data à la HEG Genève. infoclio.ch: le portail suisse pour les sciences historiques. https://www.infoclio.ch/fr/p%C3%A9dagogie-de-louverture-enseigner-lopen-data-%C3%A0-la-heg-gen%C3%A8ve\n\n\nRaemy, Julien A. (2025, November). Linked Open Usable Data for Cultural Heritage: Community Building and Semantic Interoperability in Practice. 17th Semantic Web in Libraries Conference (SWIB25). https://doi.org/10.48620/92261\n\n\nRaemy, J. A., Gray, T., Collinson, A., & Page, K. R. (2023, July 12). Enabling Participatory Data Perspectives for Image Archives through a Linked Art Workflow (Poster). Digital Humanities 2023 Posters. Digital Humanities 2023. https://doi.org/10.5281/zenodo.7878358\n\n\nRaemy, J. A., & Sanderson, R. (2023, September 28). Analysis of the Usability of Automatically Enriched Cultural Heritage Data. https://doi.org/10.48550/arXiv.2309.16635\n\n\nSajdak, C. (2024). Réconcilier avec OpenRefine. Biblissima+. https://doc.biblissima.fr/api/openrefine/\n\n\nSanderson, R. (2018, May 15). Shout it Out: LOUD. EuropeanaTech Conference 2018, Rotterdam, the Netherlands. https://www.slideshare.net/Europeana/shout-it-out-loud-by-rob-sanderson-europeanatech-conference-2018\n\n\nSanderson, R. (2019). Keynote: Standards and Communities: Connected People, Consistent Data, Usable Applications. 2019 ACM/IEEE Joint Conference on Digital Libraries (JCDL), 28. https://doi.org/10.1109/JCDL.2019.00009\n\n\nSanderson, R. (2023, October 13). Understanding Linked Art. Linked Art face-to-face meeting, Amsterdam, The Netherlands. https://www.slideshare.net/azaroth42/understanding-linked-art\n\n\nSanderson, R. (2024a). Implementing Linked Art in a Multi-Modal Database for Cross-Collection Discovery. Open Library of Humanities, 10(2). https://doi.org/10.16995/olh.15407\n\n\nSanderson, R. (2024b, March 1). Linked Data Enlightenment: Lessons Learned through LUX. Information Access Seminar, UC Berkeley School of Information, Berkeley, CA, USA. https://doi.org/10.5281/zenodo.10759740\n\n\nSanderson, R., Ciccarese, P., & Van de Sompel, H. (2013). Designing the W3C open annotation data model. Proceedings of the 5th Annual ACM Web Science Conference, WebSci ’13, 366–375. https://doi.org/10.1145/2464464.2464474\n\n\nSantos, A. (2020). Données de la recherche : cadre juridique et licences [Mémoire de master, HES-SO University of Applied Sciences and Arts, Haute école de gestion de Genève]. https://doi.org/10.5281/zenodo.3967402\n\n\nScholger, W. (2023, October 20). Legal Aspects of Arts and Humanities Data. DARIAH-CH Study Day 2023, Bern, Switzerland. https://www.dariah.ch/_files/ugd/8756fc_af72e01542284294ac0b7cf5c6064160.pdf\n\n\nSnydman, S., Sanderson, R., & Cramer, T. (2015). The International Image Interoperability Framework (IIIF): A community & technology approach for web-based images. Archiving Conference, 12, 16–21. https://doi.org/10.2352/issn.2168-3204.2015.12.1.art00005\n\n\nStar, S. L. (1999). The Ethnography of Infrastructure. American Behavioral Scientist, 43(3), 377–391. https://doi.org/10.1177/00027649921955326\n\n\nStar, S. L., & Griesemer, J. R. (1989). Institutional Ecology, ’Translations’ and Boundary Objects: Amateurs and Professionals in Berkeley’s Museum of Vertebrate Zoology, 1907-39. Social Studies of Science, 19(3), 387–420. https://www.jstor.org/stable/285080\n\n\nStürmer, M. E. (2016). Measuring the promise of open data: Development of the Impact Monitoring Framework. 1–12. https://doi.org/10.7892/boris.75031\n\n\nTennant, J., Agarwal, R., Baždarić, K., Brassard, D., Crick, T., Dunleavy, D. J., Evans, T. R., Gardner, N., Gonzalez-Marquez, M., Graziotin, D., Greshake Tzovaras, B., Gunnarsson, D., Havemann, J., Hosseini, M., Katz, D. S., Knöchelmann, M., Madan, C. R., Manghi, P., Marocchino, A., … Yarkoni, T. (2020). A tale of two ’opens’: Intersections between Free and Open Source Software and Open Scholarship [Preprint]. SocArXiv. https://doi.org/10.31235/osf.io/2kxq8\n\n\nUNESCO. Culture for Development Indicators. (2014). Methodology Manual. United Nations Educational, Scientific and Cultural Organization. https://n2t.net/ark:/48223/pf0000229608\n\n\nWiel, H. vd, Garassino, F., Li, Z., Fraga-González, G., Furrer, E., & Held, L. (2024, December 23). Stakeholder Engagement for Sustainable Open Research Data Support Services: Insights from Interviews and Surveys in Switzerland. https://doi.org/10.31222/osf.io/3d5we\n\n\nWilkinson, M. D., Dumontier, M., Aalbersberg, Ij. J., Appleton, G., Axton, M., Baak, A., Blomberg, N., Boiten, J.-W., da Silva Santos, L. B., Bourne, P. E., Bouwman, J., Brookes, A. J., Clark, T., Crosas, M., Dillo, I., Dumon, O., Edmunds, S., Evelo, C. T., Finkers, R., … Mons, B. (2016). The FAIR Guiding Principles for scientific data management and stewardship. Scientific Data, 3, 160018. https://doi.org/10.1038/sdata.2016.18\n\n\n\n\n\n\n Back to topReuseCC BY 4.0"
  },
  {
    "objectID": "sections/characteristics.html",
    "href": "sections/characteristics.html",
    "title": "Characteristics of Open Data",
    "section": "",
    "text": "The term Open(ness) can be defined in the following complementary ways:\n\nGeneral Definition:\n\n\nOpen means anyone can freely access, use, modify, and share for any purpose (subject, at most, to requirements that preserve provenance and openness).\n\nThe Open Definition according to the Open Knowledge Network.\n\nPrinciples of Openness:\n\nNo limitations on access: Accessibility must not depend on cost, authentication, or privileges (national, institutional, or otherwise).\nFree and open: Open knowledge should be shared freely, without cost or barriers.\n\n\nDerived from the Open Knowledge Foundation’s principles and scholarly interpretations.\n→ Key takeaway: Knowledge funded by public mandates must benefit the public without restrictions Scholger (2023).\n\n\n\n\nData at its most basic level as the absence of uniformity, whether in the real world or in some symbolic system. Only once such data have some recognisable structure and are given some meaning can they be considered information (Floridi, 2010).\n\n\n(Chen & Floridi, 2013)\n\n\n\n\nData whose purpose is to describe and give information about other data. (Oxford English Dictionary, 2023b)\n\n\n(…) there is no fixed boundary between “data” and “metadata”, and that information viewed as data in one discipline may be metadata in another. (Alter et al., 2023)\n\n\n\n\n\nOpen data and content can be freely used, modified, and shared by anyone for any purpose.\n\nThe Open Definition according to the Open Knowledge Network.",
    "crumbs": [
      "Characteristics of Open Data"
    ]
  },
  {
    "objectID": "sections/characteristics.html#definitions",
    "href": "sections/characteristics.html#definitions",
    "title": "Characteristics of Open Data",
    "section": "",
    "text": "The term Open(ness) can be defined in the following complementary ways:\n\nGeneral Definition:\n\n\nOpen means anyone can freely access, use, modify, and share for any purpose (subject, at most, to requirements that preserve provenance and openness).\n\nThe Open Definition according to the Open Knowledge Network.\n\nPrinciples of Openness:\n\nNo limitations on access: Accessibility must not depend on cost, authentication, or privileges (national, institutional, or otherwise).\nFree and open: Open knowledge should be shared freely, without cost or barriers.\n\n\nDerived from the Open Knowledge Foundation’s principles and scholarly interpretations.\n→ Key takeaway: Knowledge funded by public mandates must benefit the public without restrictions Scholger (2023).\n\n\n\n\nData at its most basic level as the absence of uniformity, whether in the real world or in some symbolic system. Only once such data have some recognisable structure and are given some meaning can they be considered information (Floridi, 2010).\n\n\n(Chen & Floridi, 2013)\n\n\n\n\nData whose purpose is to describe and give information about other data. (Oxford English Dictionary, 2023b)\n\n\n(…) there is no fixed boundary between “data” and “metadata”, and that information viewed as data in one discipline may be metadata in another. (Alter et al., 2023)\n\n\n\n\n\nOpen data and content can be freely used, modified, and shared by anyone for any purpose.\n\nThe Open Definition according to the Open Knowledge Network.",
    "crumbs": [
      "Characteristics of Open Data"
    ]
  },
  {
    "objectID": "sections/characteristics.html#history",
    "href": "sections/characteristics.html#history",
    "title": "Characteristics of Open Data",
    "section": "History",
    "text": "History\n\nRobert K. Merton (1910–2003)\nAmerican sociologist, considered a founding father of modern sociology, said in 1942:\n\nEach researcher must contribute to the ‘common pot’ and give up intellectual property rights to allow knowledge to move forward.\n\nSource: Wikipedia\n\nWhile the term “open data” isn’t even 20 years old, the author puts the concept in a historical context; the idea that scientific research should be free to all was popularized by Robert King Merton in the early 1940s. Research (which produces data) should be shared freely for the common good.\n\nSource: https://data.gov/blog/open-data-history\n\n\nTimeline\n\n1942: The concept starts with Robert K. Merton.\n1995: The term ‘Open Data’ first appeared, related to the sharing of geophysical and environmental data.\nNovember 2005: Open Knowledge Foundation creates the Open Definition.\nDecember 2007: The concept of open public data was discussed and defined in Sebastopol, CA, USA at a meeting of Internet activists. They identified 8 principles.\nFebruary 2009: Tim Berners-Lee presents The Next Web at TED2009. He famously asked for “raw data now”.\n\nhttps://devopedia.org/open-data  https://www.opendatasoft.com/en/what-is-open-data-practical-guide/\n\n\nThe Sebastopol Meeting\nIn December 2007, thirty thinkers and activists of the Internet held a meeting in Sebastopol, north of San Francisco. Their aim was to define the concept of open public data and have it adopted by the US presidential candidates.\nAmong them were:\n\nTim O’Reilly: An American author and editor who defined and popularized concepts such as open source and Web 2.0.\nLawrence Lessig: Professor of Law at Stanford University and founder of Creative Commons licenses.\nAdrian Holovaty: Founder of EveryBlock, a localized information service.\nTom Steinberg: Founder of the FixMyStreet site.\nAaron Swartz: Inventor of RSS and free knowledge activist.\n\nTogether, they created principles to define and evaluate open public data.\nhttps://www.paristechreview.com/2013/03/29/brief-history-open-data/",
    "crumbs": [
      "Characteristics of Open Data"
    ]
  },
  {
    "objectID": "sections/characteristics.html#the-impact-of-open-data-on-disciplines",
    "href": "sections/characteristics.html#the-impact-of-open-data-on-disciplines",
    "title": "Characteristics of Open Data",
    "section": "The Impact of Open Data on Disciplines",
    "text": "The Impact of Open Data on Disciplines\n\nCatalysing Interdisciplinary Progress\n\nA foundation for collaboration and innovation: Open data drives interdisciplinary research by providing universally accessible datasets, fostering collaboration across diverse fields such as information science, digital humanities, and data science.\nEnabling data-driven research: Facilitates advanced analysis and research in disciplines that rely heavily on data, increasing the accuracy and depth of insights and discoveries.\n\n\n\nOpen Data in Information Science, Digital Humanities, and Data Science\n\nInformation Science: Improves data management and accessibility, enabling more efficient data retrieval, archiving, and dissemination practices.\nDigital Humanities: Enables new digital approaches to humanities research, providing new insights into historical, cultural, and linguistic studies through data analysis.\nData Science: Leverages open data for predictive modeling, machine learning, and big data analytics, enabling comprehensive analysis and informed decision-making in diverse fields such as health, finance, and social sciences.",
    "crumbs": [
      "Characteristics of Open Data"
    ]
  },
  {
    "objectID": "sections/characteristics.html#typology",
    "href": "sections/characteristics.html#typology",
    "title": "Characteristics of Open Data",
    "section": "Typology",
    "text": "Typology\n\nMain Sources\n\nResearch: Open Research Data (ORD) / Open Scientific Data\nGovernment: Open Government Data (OGD)\nNon-profit Organisations\nPrivate Organisations\n\n\n\nDisciplines\n\nCultural Heritage\nHealthcare\nEducation\nTransportation\nMeteorology\nGeospatial Information\nEconomic and Finance\nLegal and Criminal Justice\nEtc.",
    "crumbs": [
      "Characteristics of Open Data"
    ]
  },
  {
    "objectID": "sections/characteristics.html#open-research-data-ord",
    "href": "sections/characteristics.html#open-research-data-ord",
    "title": "Characteristics of Open Data",
    "section": "Open Research Data (ORD)",
    "text": "Open Research Data (ORD)\n\nDefinition\n\nResearch data are the evidence that underpins the answer to the research question, and can be used to validate findings regardless of its form (e.g. print, digital, or physical). These might be quantitative information or qualitative statements collected by researchers in the course of their work by experimentation, observation, modeling, interview, or other methods, or information derived from existing evidence Concordat Working Group (2016).\n\n\n\nFor Funding Agencies (and Institutions)\n\nFor the purposes of research assessment, consider the value and impact of all research outputs (including datasets and software) in addition to research publications, and consider a broad range of impact measures including qualitative indicators of research impact, such as influence on policy and practice.\n\n\n\nFor Organizations that Supply Metrics\n\nBe open and transparent by providing data and methods used to calculate all metrics.\n\nProvide the data under a licence that allows unrestricted reuse, and provide computational access to data, where possible.\n\nSan Francisco Declaration on Research Assessment (DORA)\n\n\nORD in Switzerland\n\nSNSF Policy\nThe Swiss National Science Foundation (SNSF) expects all its funded researchers:\n\nto store the research data they have worked on and produced during the course of their research work,\nto share these data with other researchers, unless they are bound by legal, ethical, copyright, confidentiality or other clauses, and\nto deposit their data and metadata onto existing public repositories in formats that anyone can find, access and reuse without restriction.\n\nhttps://www.snf.ch/en/dMILj9t4LNk8NwyR/topic/open-research-data\n\n\nVision\n\nBy facilitating access to and reuse of research data, ORD promotes better, more effective, and more impactful research for the benefit of society as a whole. Through the principles of open access and reusability of research data, ORD practices support transparent and reproducible research findings. Moreover, ORD fosters collaboration by promoting exchange among researchers across disciplines, legal systems and national borders, thus enabling creativity and innovation to thrive (Open Science Delegation, 2021a).\n\n\n\nAction Areas\nThe SNSF has identified four criteria in the action plan (Open Science Delegation, 2021b):\n\nSupport researchers and research communities in imagining and adopting ORD practices\nDevelopment, promotion, and maintenance of financially sustainable basic infrastructures and services for all researchers\nEquipping researchers for ORD skills development and exchange of best practices\nBuilding up systemic und supportive conditions for institutions and research communities\n\n→ for more information, see Wiel et al. (2024)\n\n\n\nResearch Data Management (RDM)\n\nDefinition\nRDM refers to the organisation, storage and preservation of data created during a research project.\n\n\nPurpose\nRDM ensures that research data are well-organised, maintained and accessible for current and future research, thereby improving their reliability, validity and reproducibility.\n\n\n\nData Management Plan (DMP)\n\nDefinition\nA DMP is a formal document that outlines how data will be handled during and after a research project, covering aspects from collection to sharing and preservation.\n\n\nPurpose\nIt serves as a guide for managing data efficiently and meets funding agency requirements for data stewardship. It is now mandatory for most funding agencies to require a DMP as part of the grant application process to secure funding. University libraries often have services and resources to assist researchers in creating these documents, providing expert guidance on best practices in data management.\n\n\n\nRDM and DMP\n\nInterconnected Roles\nRDM encompasses the day-to-day management of research data, while a DMP provides a structured plan for how to manage, share, and preserve data throughout the research project.\n\n\nPlanning and Execution\nA DMP is essentially a blueprint for RDM. It outlines the policies and standards to be applied to the data, ensuring that data management practices are thought through from the outset of the project.\n\n\n\nOpen Governement Data (OGD)\n\nDefinition\n\nThe work of government involves collecting huge amounts of data, much of which is not confidential (economic data, demographic data, spending data, crime data, transport data, etc). The value of much of this data can be greatly enhanced by releasing it as open data, freeing it for re-use by business, research, civil society, data journalists, etc Open Knowledge (2016).\n\nhttps://opendatahandbook.org/glossary/en/terms/government-data/\n\n\n\nOGD in Switzerland\n\nhttps://www.bfs.admin.ch/bfs/fr/home/services/ogd/masterplan.html\n\nLMETA. Art. 10, al. 4\n\nLes données sont mises en ligne gratuitement, en temps utile, sous une forme lisible par machine et dans un format ouvert. Elles peuvent être librement réutilisées, sous réserve d’obligations légales spéciales de mentionner la source des données (Loi fédérale sur l’utilisation des moyens électroniques pour l’exécution des tâches des autorités (LMETA), 2023).\n\n\n\nRelated efforts\n\nNational data management (NaDB): https://www.bfs.admin.ch/bfs/en/home/nadb/nadb.html\ni14y Interoperability platform: https://www.i14y.admin.ch/\nDigital Switzerland Strategy: https://digital.swiss/",
    "crumbs": [
      "Characteristics of Open Data"
    ]
  },
  {
    "objectID": "sections/characteristics.html#purposes-of-open-data",
    "href": "sections/characteristics.html#purposes-of-open-data",
    "title": "Characteristics of Open Data",
    "section": "Purposes of Open Data",
    "text": "Purposes of Open Data\n\nTransparency and democratic control\nParticipation\nSelf-empowerment\nImproved or new private products and services\nInnovation\nImproved efficiency and effectiveness of government services\nImpact measurement of policies\nNew knowledge from combined data sources and patterns in large data volumes\n\nhttps://opendatahandbook.org/guide/en/why-open-data/\n\nOpen Government Data Principles\n\nComplete: All public data is made available. Public data is data that is not subject to valid privacy, security or privilege limitations.\nPrimary: Data is as collected at the source, with the highest possible level of granularity, not in aggregate or modified forms.\nTimely: Data is made available as quickly as necessary to preserve the value of the data.\nAccessible: Data is available to the widest range of users for the widest range of purposes.\nMachine processable: Data is reasonably structured to allow automated processing.\nNon-discriminatory: Data is available to anyone, with no requirement of registration.\nNon-proprietary: Data is available in a format over which no entity has exclusive control.\nLicense-free: Data is not subject to any copyright, patent, trademark or trade secret regulation. Reasonable privacy, security and privilege restrictions may be allowed.\n\nhttps://public.resource.org/8_principles.html",
    "crumbs": [
      "Characteristics of Open Data"
    ]
  },
  {
    "objectID": "sections/characteristics.html#requirements",
    "href": "sections/characteristics.html#requirements",
    "title": "Characteristics of Open Data",
    "section": "Requirements",
    "text": "Requirements\n\nLegally open: available under an open (data) licence that permits anyone freely to access, reuse and redistribute\nTechnically open: data is available for no more than the cost of reproduction and in machine-readable and bulk form.\n\nhttps://opendatahandbook.org/glossary/en/terms/open-data/",
    "crumbs": [
      "Characteristics of Open Data"
    ]
  },
  {
    "objectID": "sections/characteristics.html#licences",
    "href": "sections/characteristics.html#licences",
    "title": "Characteristics of Open Data",
    "section": "Licences",
    "text": "Licences\n\nCopyright and Copyleft\n\nCopyright\n\nGrants creators exclusive rights to control use, reproduction, and distribution.\nDesigned to protect creators’ economic interests; allows monetization of work.\n\n\n\nCopyleft\n\nAllows use, modification, and distribution with the condition of keeping works and derivatives open.\nPromotes freedom, sharing of knowledge, and collaborative improvement.\n\nFor further information about licences → Competence Center in Digital Law: https://www.ccdigitallaw.ch/\n\n\n\nAnglo-Saxon Copyright vs. European Author’s Rights\n\nAnglo-Saxon Copyright\n\nFocuses on economic rights; treats copyright as transferable property.\nDuration based on set years post-creation or author’s life plus years.\n\n\n\nEuropean Author’s Rights (droit d’auteur / Urheberrecht)\n\nEmphasises moral rights alongside economic rights.\nGrants inalienable moral rights to creators; duration includes lifetime plus post-death period (commonly 70 years).\n\n\n\n\nCreative Commons (CC)\n\n CC BY 4.0: Attribution\n CC BY-SA 4.0: Attribution, Share Alike\n CC BY-ND 4.0: Attribution, No Deritave Works\n CC BY-NC 4.0: Attribution, No Commercial Use\n CC BY-NC-SA 4.0: Attribution, No Commercial Use, Share Alike\n CC BY-NC-ND 4.0: Attribution, No Commercial Use, No Derivative Works\n Public Domain Dedication (CC0): No Rights Reserved\n Public Domain Mark: No Known Copyright\n\nhttps://creativecommons.org/\n\nSpectrum\n\nCreative commons license spectrum (MJL, 2020)\n\n\n\nRights Statements\n\n12 different rights statements that can be used by cultural heritage institutions\nThree categories\n\nIn Copyright: statements for works that are in copyright\nNo Copyright: statements for works that are not in copyright\nOther: statements for works where the copyright status is unclear\n\n\nhttps://rightsstatements.org/\n\n\nOpen Data Commons Open Database License (ODbL)\n\nCopyleft licence\nAttribution and Share-Alike for Data/Databases\n\nhttps://opendatacommons.org/licenses/odbl/\nODbL is somewhat equivalent to CC BY-SA (Santos, 2020).\n\n\nPublic Domain Dedication and License (PDDL)\n\nThe PDDL places the data(base) in the public domain (waiving all rights)\n\nhttps://opendatacommons.org/licenses/pddl/\n\n\nLicences for software\n\nGNU General Public License (GPL)\nGNU Affero General Public License (AGPL)\nMozilla Public License (MPL)\nMIT License\nApache License\n\nAnd others… → see for instance https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/licensing-a-repository\n\n\nResponsable AI Licenses (RAIL)\nResponsible AI Licenses (RAIL) are a class of licenses designed to encourage the responsible use of an AI artifact being licensed by including a set of use restrictions applied to AI artifact. RAILs can be more or less restrictive depending on the aims of the licensor. For instance, a license can be RAIL while being a proprietary license, or a license just allowing the use of the AI feature for research purposes and without allowing distribution of derivative versions.\nIn contrast, Open & Responsible AI Licenses (OpenRAIL) are a subclass of RAIL licenses that permit free-of-charge open access and re-use of AI artifacts for commercial purposes, while including usage restrictions. Note that usage restrictions in RAIL Licenses also apply to any derivatives of AI artifact.\nRAILs can be used to license data (D), Apps (A), models (M), and source code (S). depending on the AI feature(s) you are licensing, you will add suffix D, A, M, or S\n\n\nResponsible AI Pubs Licenses\n\nAIPubs Open RAIL-S\nAIPubs Open RAIL-M\nAIPubs Research-Use RAIL-S\nAIPubs Research-Use RAIL-M\n\nResponsible AI End-User License (RAIL-A License)\nResponsible AI Source Code License (Open RAIL-S License)\nBigScience Open RAIL-M License (Open RAIL-M License)\n\nhttps://www.licenses.ai/\n\n\nI Hate AI License (IHAIL)\n\nBased on CC BY 4.0\nIt prohibits the use of the material with Artifical Intelligence (AI) technologies while allowing sharing, adaptation, and commercial use under certain terms.\n\nhttps://ihateailicense.eu/\n\n\nRecommendations for Open (Research) Data\nSantos (2020) suggests assigning Creative Commons licenses to open datasets in the following order of preference:\n\n CC0 (to the fullest extent allowed by law, as a complete waiver is not feasible under Swiss regulations)\n CC BY 4.0\n CC BY-SA 4.0",
    "crumbs": [
      "Characteristics of Open Data"
    ]
  },
  {
    "objectID": "sections/characteristics.html#technical-means",
    "href": "sections/characteristics.html#technical-means",
    "title": "Characteristics of Open Data",
    "section": "Technical means",
    "text": "Technical means\n\nImportant factors in providing structured data for machines\n\nData(set) formats\n\nText-based formats\nBinary-encoded formats\n\nMetadata standards / schemas (to describe the dataset)\nDocumentation\nProtocols\n\nAnd of course the underlying infrastructure…\n\n\nInfrastructure\n\nDefinitions\n\nA collective term for the subordinate parts of an undertaking; substructure, foundation (Oxford English Dictionary, 2023a).\n\n\nPeople commonly envision infrastructure as a system of substrates – railroad, lines, pipes and plumbing, electrical power plants, and wires. It is by definition invisible, part of the background for other kinds of work. It is ready-to-hand. This image holds up well enough for many purposes – turn on the faucet for a drink of water and you use a vast infrastructure of plumbing and water regulation without usually thinking much about it (Star, 1999).\n\n\n\nDimensions\nAccording to Star (1999), infrastructure can be understood through nine interconnected dimensions:\n\nEmbeddedness: Infrastructure is sunk into and inside of other structures, social arrangements, and technologies. People do not necessarily distinguish the several coordinated aspects of infrastructure.\nTransparency: Infrastructure is transparent to use, in the sense that it does not have to be reinvented each time or assembled for each task, but invisibly supports those tasks.\nReach or scope: This may be either spatial or temporal – infrastructure has reach beyond a single event or one-site practice.\nLearned as part of membership: Strangers and outsiders encounter infrastructure as a target object to be learned about. New participants acquire a naturalised familiarity with its objects, as they become members.\nLinks with conventions of practice: Infrastructure both shapes and is shaped by the conventions of a community of practice.\nEmbodiment of standards: Modified by scope and often by conflicting conventions, infrastructure takes on transparency by plugging into other infrastructures and tools in a standardised fashion.\nBuilt on an installed base: Infrastructure does not grow de novo; it wrestles with the inertia of the installed base and inherits strengths and limitations from that base.\nBecomes visible upon breakdown: The normally invisible quality of working infrastructure becomes visible when it breaks: the server is down, the bridge washes out, there is a power blackout.\nIs fixed in modular increments, not all at once or globally: Because infrastructure is big, layered, and complex, and because it means different things locally, it is never changed from above. Changes take time and negotiations, and adjustment with other aspects of the systems are involved.\n\n\n\n\nText-based formats\n\nPlain Text (TXT)\nWSe2            WS2         MoS2    \n\ndk  Intensity   dk  Intensity   dk  Intensity   \n\n855.87628   63  848.96433   -39 855.87628   372\n855.25787   72.25   848.34546   2   855.25787   424\n854.63942   64.25   847.72654   -39 854.63942   460\n854.02093   58  847.10759   -37 854.02093   362\n853.40239   66  846.4886    -28 853.40239   440\nSohier, T., Ponomarev, E., Gibertini, M., Berger, H., Marzari, N., Ubrig, N., & Morpurgo, A. F. (2019). Enhanced Electron-Phonon Interaction in Multivalley Materials [Data set]. Université de Genève, Yareta. https://doi.org/10.26037/yareta:jlzyhiwj6vfjrnbza4bkvobjai\nFile (extract): f1b.txt\n\n\nMarkdown (MD)\n# e-periodica OAI-PMH - Ethnology and Folklore\nThis script was done to download the metadata of [e-periodica](https://www.e-periodica.ch/) through \ntheir OAI-PMH endpoint (`https://www.e-periodica.ch/oai`) that could be interesting to the PIA research \nproject as we want to link our image-based collections to the e-periodica articles. \n\nThere are more than 16k metadata articles which have \nthe 390 `setSpec` (Ethnology, folklore) on e-periodica. Probably, the more relevant articles \ncome from the `Korrespondenzblättern der SGV` (more than 2k articles), divided into these three sources: \n\n- https://www.e-periodica.ch/digbib/volumes?UID=sgv-001 \n- https://www.e-periodica.ch/digbib/volumes?UID=sgv-002\n- https://www.e-periodica.ch/digbib/volumes?UID=sgv-003 \n\n## Records in CSV\n- [All records](data/records.csv)\n- [Extract (SGV)](data/sgv.csv)\nRaemy, J. A. (2023). e-periodica OAI-PMH - Ethnology and Folklore (Version 1.0.0) [Computer software]. https://doi.org/10.5281/zenodo.7777797 File: README.MD\n\n\nComma-separated values (CSV)\n\"TRANSPORT_TYPE\";\"TRANSPORT_MEAN\";\"TRAVEL_REASON\";\"SOCIO_DEMO_VARIABLE_TYPE\";\"SOCIO_DEMO_VARIABLE\";\"PERIOD_REF\";\"UNIT_MEAS\";\"VALUE\";\"OBS_CONFIDENCE\";\"OBS_STATUS\"\n\"TOT\";\"TOT\";\"ALL_REAS\";\"GEO\";\"CH\";2015;\"KM\";36.8318;0.4602;\"A\"\n\"TOT\";\"TOT\";\"WORK\";\"GEO\";\"CH\";2015;\"KM\";8.8512;0.1995;\"A\"\n\"TOT\";\"TOT\";\"SCHOOL\";\"GEO\";\"CH\";2015;\"KM\";1.9104;0.1026;\"A\"\n\"TOT\";\"TOT\";\"SHOP\";\"GEO\";\"CH\";2015;\"KM\";4.7651;0.1346;\"A\"\n\"TOT\";\"TOT\";\"LEISU\";\"GEO\";\"CH\";2015;\"KM\";16.2548;0.3385;\"A\"\n\"TOT\";\"TOT\";\"SERV_ACC\";\"GEO\";\"CH\";2015;\"KM\";1.8462;0.0982;\"A\"\n\"TOT\";\"TOT\";\"BUSIN\";\"GEO\";\"CH\";2015;\"KM\";2.5514;0.1587;\"A\"\n\"TOT\";\"TOT\";\"OTH_REAS\";\"GEO\";\"CH\";2015;\"KM\";0.6527;0.0759;\"A\"\n\"SOFT_MOB\";\"TOT\";\"ALL_REAS\";\"GEO\";\"CH\";2015;\"KM\";2.8031;0.0440;\"A\"\nFederal Statistical Office. Comportement de la population en matière de transports, tableaux de synthèse. https://opendata.swiss/fr/perma/18084205@bundesamt-fur-statistik-bfs\n\n\nExtensible Markup Language (XML)\n&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;\n&lt;rdf:RDF\n  xmlns:foaf=\"http://xmlns.com/foaf/0.1/\"\n  xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\"\n  xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\n  xmlns:dcat=\"http://www.w3.org/ns/dcat#\"\n  xmlns:dct=\"http://purl.org/dc/terms/\"\n  xmlns:vcard=\"http://www.w3.org/2006/vcard/ns#\"&gt;\n  &lt;dcat:Dataset rdf:about=\"https://ckan.opendata.swiss/perma/121911@bundesamt-fur-statistik-bfs\"&gt;\n    &lt;dcat:keyword xml:lang=\"it\"&gt;lavoro-e-reddito&lt;/dcat:keyword&gt;\n    &lt;dct:language&gt;fr&lt;/dct:language&gt;\n    &lt;dcat:distribution&gt;\n      &lt;dcat:Distribution rdf:about=\"https://ckan.opendata.swiss/dataset/90beaddf-4f48-4211-9e34-ff68d4308f98/resource/f9eb3fb4-0a11-4a40-a995-0aa13f377011\"&gt;\n        &lt;dct:rights rdf:resource=\"http://dcat-ap.ch/vocabulary/licenses/terms_by_ask\"/&gt;\n        &lt;dcat:downloadURL rdf:resource=\"https://dam-api.bfs.admin.ch/hub/api/dam/assets/121910/master\"/&gt;\n        &lt;dcat:accessURL rdf:resource=\"https://dam-api.bfs.admin.ch/hub/api/dam/assets/121910/master\"/&gt;\n        &lt;dct:format rdf:resource=\"http://publications.europa.eu/resource/authority/file-type/XLS\"/&gt;\n        &lt;dct:title xml:lang=\"de\"&gt;Kanton Genf: Erwerbsleben und Ausbildung&lt;/dct:title&gt;\n        &lt;dct:identifier&gt;121910-master@bundesamt-fur-statistik-bfs&lt;/dct:identifier&gt;\n        &lt;dct:language&gt;de&lt;/dct:language&gt;\n        &lt;dcat:mediaType rdf:resource=\"http://www.iana.org/assignments/application/vnd.ms-excel\"/&gt;\n        &lt;dct:description xml:lang=\"de\"&gt;Dieser Dataset präsentiert die Zahlen zu Erwerbsleben und Ausbildung (Eidgenössische Volkszählung 2000)&lt;/dct:description&gt;\n        &lt;dct:license rdf:resource=\"http://dcat-ap.ch/vocabulary/licenses/terms_by_ask\"/&gt;\n      &lt;/dcat:Distribution&gt;\nFederal Statistical Office. Canton de Genève: Vie active et formation https://opendata.swiss/fr/perma/121911@bundesamt-fur-statistik-bfs\n\n\nTerse RDF Triple Language (Turtle)\n@prefix ns1: &lt;https://data.tg.ch/ld/ontologies/div-energie-6/&gt; .\n@prefix xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt; .\n\n&lt;https://data.tg.ch/ld/resources/div-energie-6/div-energie-6-record/1740b190a1beca6edcd04e0b143c380b885ee1de/&gt; \n    a ns1:div-energie-6-record ;\n    ns1:andere \"2690\"^^xsd:int ;\n    ns1:einwohner \"266510\"^^xsd:int ;\n    ns1:energiebezugsflaeche \"25055573\"^^xsd:int ;\n    ns1:erdgas \"308728\"^^xsd:int ;\n    ns1:erdoelbrennstoffe \"307734\"^^xsd:int ;\n    ns1:jahr \"2015-01-01\"^^xsd:date ;\n    ns1:kehricht \"78654\"^^xsd:int ;\n    ns1:total \"1291573\"^^xsd:int ;\n    ns1:treibstoffe \"593764\"^^xsd:int .\nKanton Thurgau. CO2-Gesamtemissionen nach Energieträgern (Ebene Kanton) - https://opendata.swiss/de/perma/div-energie-6@kanton-thurgau - https://data.tg.ch/ld/resources/div-energie-6/div-energie-6-record/1740b190a1beca6edcd04e0b143c380b885ee1de/\n\n\nJavaScript Object Notation (JSON)\n[{\n        \"author\": \"Hemingway, Ernest\",\n        \"available_at\": [\n            {\n                \"isil\": \"AG0066\"\n            }\n        ],\n        \"bid\": \"AGR0005487\",\n        \"cited\": [\n            \"VEA1112819\"\n        ],\n        \"citing\": [],\n        \"dewey_classifications\": null,\nEPFL. Citations extracted from monographs about the history of Venice. https://opendata.swiss/de/perma/EPFL-LinkedBooksMonographs@openglam\n\n\nJavaScript Object Notation for Linked Data (JSON-LD)\n{\n  \"id\": \"https://lux.collections.yale.edu/data/group/8b757ad2-f853-425e-a30d-19686aa779ee\",\n  \"type\": \"Group\",\n  \"_label\": \"American Academy of Arts and Sciences\",\n  \"@context\": \"https://linked.art/ns/v1/linked-art.json\",\n  \"formed_by\": {\n    \"type\": \"Formation\",\n    \"timespan\": {\n      \"type\": \"TimeSpan\",\n      \"identified_by\": [\n        {\n          \"type\": \"Name\",\n          \"content\": \"1780-05-04\",\n          \"classified_as\": [\n            {\n              \"id\": \"https://lux.collections.yale.edu/data/concept/5088ec29-065b-4c66-b49e-e61d3c8f3717\",\n              \"type\": \"Type\",\n              \"_label\": \"Display Title\",\n              \"equivalent\": [\n                {\n                  \"id\": \"http://vocab.getty.edu/aat/300404669\",\n                  \"type\": \"Type\",\n                  \"_label\": \"Display Title\"\n                }\n              ]\n            }\n          ]\n        }\n      ],\n      \"end_of_the_end\": \"1780-05-04T23:59:59\",\n      \"begin_of_the_begin\": \"1780-05-04T00:00:00\",\n      \"_seconds_since_epoch_begin_of_the_begin\": -5985100800,\n      \"_seconds_since_epoch_end_of_the_end\": -5985014401\n    },\n    \"carried_out_by\": [\n      {\n        \"id\": \"https://lux.collections.yale.edu/data/person/977a4f7a-5d26-4965-8dd9-3fb0eaa4267e\",\n        \"type\": \"Person\",\n        \"_label\": \"John Adams\"\n      },\n      {\n        \"id\": \"https://lux.collections.yale.edu/data/person/73e7af34-fe41-4771-93df-e74b073d82fb\",\n        \"type\": \"Person\",\n        \"_label\": \"James Bowdoin\"\n      }\n    ]\n  },\n(...)\nLUX (Yale University). American Academy of Arts and Sciences. https://lux.collections.yale.edu/data/group/8b757ad2-f853-425e-a30d-19686aa779ee\n\n\n\nBinary-encoded Formats\nBinary files are used to store non-text data, such as images, audio, or executable programs. These files do not contain human-readable text and are encoded in binary format.\n\nImage Formats: BMP, GIF, JPEG, JPEG2000, PNG, TIFF\nVector Graphics Formats: EPS, PSD, SVG\n3D Formats: 3MF, GLB, GLTF, OBJ, STL\nAudio Formats: AAC, FLAC, MP3, OGG, WAV\nVideo Formats: AVI, FFV1/MKV, MOV, MP4, WEBM\nDocuments: DOCX, ODT, PDF, PDF/A\nScientific Data Formats: CDF, DICOM, FITS\nArchive File Formats: 7-ZIP, GZIP, TAR, ZIP\n\n\n1706-11-30_Verzaglia_Giuseppe-Bernoulli_Johann_I. https://iiif.dasch.swiss/0801/4VjgCwiTn8p-CTaooIqSZBO.jpx/full/max/0/default.jpg\n\n\nMetadata standards / schemas\n\nMetadata standards are sets of rules and guidelines that dictate how metadata should be formatted and used. They ensure consistency and interoperability across different systems and platforms.\n\nCIDOC Conceptual Reference Model (CIDOC-CRM), Dublin Core, Machine-Readable Cataloging (MARC), Preservation Metadata: Implementation Strategies (PREMIS)\n\nMetadata schemas are specific implementations of metadata standards. They outline the structure, elements, and attributes of metadata for a specific purpose.\n\nEncoded Archival Description (EAD), Lightweight Information Describing Object (LIDO), Metadata Object Description Schema (MODS)\n\nWhile standards provide the “what” and “why” of metadata, schemas offer the “how” for specific data types or field needs.\n\n\n\nData Catalog Vocabulary (Application Profiles)\n\nResource Description Framework (RDF) vocabulary to facilitate interoperability between data catalogues published on the Web.\nCurrent version: DCAT 3\n\n\nData Catalog Vocabulary Application Profile (DCAT-AP)\nSpecifications based on DCAT for describing public sector datasets\n\nDCAT Application Profile for data portals in Europe: DCAT-AP 3.0\nDCAT Application Profile for the United States of America: DCAT-US - Version 3\nDCAT Application Profile for Data Portals in Switzerland (DCAT-AP CH): eCH-0200\n\nDCAT-AP CH is a subprofile of DCAT-AP\n\n\nDCAT\nSeven main classes/entities:\n\ndcat:Catalog represents a catalogue, which is a dataset in which each individual item is a metadata record describing some resource\ndcat:Resource represents a dataset, a data service or any other resource that may be described by a metadata record in a catalogue.\ndcat:Dataset represents a collection of data, published or curated by a single agent or identifiable community.\ndcat:Distribution represents an accessible form of a dataset such as a downloadable file.\ndcat:DataService represents a collection of operations accessible through an interface (API) that provide access to one or more datasets or data processing functions.\ndcat:DatasetSeries is a dataset that represents a collection of datasets that are published separately, but share some characteristics that group them.\ndcat:CatalogRecord represents a metadata record in the catalogue, primarily concerning the registration information, such as who added the record and when.\n\n\nhttps://www.w3.org/TR/vocab-dcat-3/#dcat-scope\nex:catalog\n  a dcat:Catalog ;\n  dcterms:title \"Imaginary Catalog\"@en ;\n  dcterms:title \"Catálogo imaginario\"@es ;\n  rdfs:label \"Imaginary Catalog\"@en ;\n  rdfs:label \"Catálogo imaginario\"@es ;\n  foaf:homepage &lt;http://dcat.example.org/catalog&gt; ;\n  dcterms:publisher ex:transparency-office ;\n  dcterms:language &lt;http://id.loc.gov/vocabulary/iso639-1/en&gt;  ;\n  dcat:dataset ex:dataset-001 , ex:dataset-002 , ex:dataset-003 ;\n  .\nhttps://www.w3.org/TR/vocab-dcat-3/#basic-example\n\n\nDCAT-AP CH\n@prefix dcat: &lt;http://www.w3.org/ns/dcat#&gt; .\n@prefix dct: &lt;http://purl.org/dc/terms/&gt; .\n@prefix foaf: &lt;http://xmlns.com/foaf/0.1/&gt; .\n@prefix xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt; .\n\n# ---------- class Catalog --------------------------------------------------\n&lt;https://swisstopo/opendata/catalog&gt;\n  a dcat:Catalog ;\n\n  # mandatory properties\n  dct:description \"Datenkatalog der Stadt Zurich\"@de ;\n  dct:publisher &lt;https://publishers/swisstopo&gt; ;\n  dct:title \"Open Data City of Zurich\"@en ,\n            \"Offene Daten der Stadt Zurich\"@de .\nhttps://www.dcat-ap.ch/releases/2.0/dcat-ap-ch.html#Class:Catalog\n\n\n\nDocumentation\nComprehensive and understandable information about the data, including its source, structure, context, and how to use it effectively.\n\nTypes of Documentation\nClear and comprehensive documentation plays a vital role in maximizing the value of data and systems. It enhances usability by making data more accessible and understandable to a wide range of users, including non-experts and developers. Well-documented data fosters trust by providing transparency about sources, methodologies, and underlying code, while also supporting data integration and application development by enabling seamless combination of data from diverse sources. Below are key types of documentation that contribute to these goals:\n\nData field descriptions/data models\nUser guides\nMetadata\nDeveloper documentation\nSource code documentation\n\n\n\n\nProtocols\nA robust set of rules and standards governs the exchange and accessibility of open data over the internet. These protocols and mechanisms enable accessibility by facilitating standardised and straightforward access to data, which is essential for promoting innovation and transparency. Additionally, they support interoperability, ensuring that data from diverse sources can be efficiently integrated and used together. Below are key technologies and protocols that achieve these goals:\n\nApplication Programming Interface (API): mechanism that enable two software components to communicate with each other\n\nRepresentational State Transfer (REST): a style of API that uses HTTP requests for communication. REST is stateless, i.e. each request from a client to the server is treated as new. There is no stored memory of previous interactions. This means the server does not store any state about the client session on the server side.\nSimple Object Access Protocol (SOAP): a protocol used for exchanging structured information in web services, offering high security and transactional reliability. SOAP can support both stateless and stateful operations.\n\nFile Transfer Protocol (FTP): used for the transfer of data files, particularly large datasets, from one host to another.\nOpen Archives Initiative Protocol for Metadata Harvesting (OAI-PMH): a protocol for harvesting metadata descriptions of records in an archive, particularly used in digital libraries.\nReally Simple Syndication or Rich Site Summary (RSS) / Atom Feeds: used for regularly updating or publishing data that changes frequently. Feeds enable publishers to syndicate data automatically.\nSPARQL Protocol and RDF Query Language (SPARQL): used for querying and manipulating RDF",
    "crumbs": [
      "Characteristics of Open Data"
    ]
  },
  {
    "objectID": "sections/platforms.html",
    "href": "sections/platforms.html",
    "title": "Open Data Platforms and Organisations",
    "section": "",
    "text": "This page features a curated selection of open data platforms and organisations, with a particular emphasis on Switzerland. You can explore various initiatives—ranging from research data repositories like the Registry of Research Data Repositories, SwissUbase, and DaSCH Service Platform to open government data portals such as opendata.swiss, LINDAS Open Data Basel-Stadt, Stadt Zürich Open Data, and the Open Data Portal of Geneva Public Transport.\nIn addition, learn more about community-driven organisations like the Open Knowledge Network, Open Research Data National Strategy Council opendata.ch, and Open Data Beer.\nIt should also be noted that every February around Valentine’s Day, International Love Data Week brings together data enthusiasts around the world - mostly in academia - to explore best practices in data management, sharing and reuse. For example:\n\nSwiss Research Data Support Network (SRDSN): https://www.researchdatasupport.ch/lovedata\nBasel University Library Love Data Week 2026: https://researchdata.unibas.ch/en/news/details/love-data-week-2026/\nUniversity of Geneva Love Data Week 2026: https://www.unige.ch/researchdata/propos/actualites/love-data-week-2026\nFDM im deutschsprachigen Raum: https://forschungsdaten.info/fdm-im-deutschsprachigen-raum/love-data-week-2026/\nUniversity of Michigan - International Love Data Week: https://www.icpsr.umich.edu/sites/icpsr/about/news-events/international-love-data-week.\n\nFor more information about OGD in Switzerland, please see this curated and exhaustive list on GitHub: https://github.com/rnckp/awesome-ogd-switzerland.\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Categories\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\nord\n\n\n\nRegistry: Launched in 2012, this comprehensive registry of research data repositories provides embeddable tools and detailed metadata—including data accessibility, licensing, persistent identifiers, and certification information. All metadata is available under a CC0 license and accessible via an API.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nord\n\n\n\nCross-disciplinary: SwissUbase is a national solution primarily serving the social sciences and linguistics. Operated by FORS, it was launched in 2021 to replace FORSbase and features its own metadata schema for studies, datasets, and data files with Digital Object Identifier (DOI) support at the dataset level.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niiif\n\nlinked data\n\nord\n\n\n\nHumanities: The DaSCH Service Platform is a national research infrastructure dedicated to preserving long-term humanities data. The DaSCH – Swiss National Data and Service Center for the Humanities was initiated by the University of Basel’s Digital Humanities Lab. In 2017, DaSCH was established as a national facility operated by the Swiss Academy of Humanities and Social Sciences (SAGW). Since 2021, it has operated as a national research data infrastructure primarily funded by the Swiss National Science Foundation (SNSF). The platform employs a core ontology (Knora) and provides modern APIs (RESTful JSON-LD and IIIF Image API) along with Archival Resource Keys (ARKs).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nord\n\n\n\nCross-institutional: OLOS is a consultation and archive portal developed under the Data Life-Cycle Management (DLCM) project. It serves multiple institutions and utilizes the Datacite Metadata Schema with DOI assignment at the dataset level.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niiif\n\nlinked data\n\nord\n\n\n\nInstitutional: Yareta is the research data repository developed for Geneva’s higher education institutions. Launched in 2019 and built upon the OLOS platform, it is tailored to manage institutional research data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nord\n\n\n\nGeneric: Developed at CERN, Zenodo is a generalist repository that allows anyone to deposit data. It supports DOI assignment for each version of deposited data, making it a versatile platform for researchers in any discipline.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\n\n\nNational/Registry: opendata.swiss is the central portal for open government data in Switzerland, managed by the Federal Statistical Office (FSO). Originally launched in 2013 by the Swiss Federal Archives as opendata.admin.ch and rebranded in 2016, it aggregates metadata via a JSON API and an XML file compliant with the DCAT-AP CH standard.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlinked data\n\nogd\n\n\n\nLinked Data Service: the service allows public administrations to publish their data in the form of Knowledge Graphs. LINDAS was built between 2017 and 2020 in the Linked Data Platform project of the Swiss Federal Archives (SFA) with the support of the State Secretariat for Economic Affairs (SECO) and in close collaboration with the Federal Office for the Environment (FOEN).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlinked data\n\nogd\n\n\n\nVisualisation: The visualize.admin.ch portal enables the visualisation of Swiss Open Government Data provided by LINDAS, which can then be easily downloaded or integrated into websites and updated automatically. It is operated by the FOEN.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\n\n\nCantonal: Open Data Basel-Stadt is the cantonal portal for open government data from Basel-Stadt. Officially launched in 2019 following a pilot phase, it features a dedicated dashboard, its own metadata schema combining DCAT and DCAT-AP CH properties, and a JSON API.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\n\n\nMunicipal: Launched in 2012, Stadt Zürich Open Data is recognized as Switzerland’s first open government data platform. It provides (Geo)JSON APIs, dedicated GitHub scripts, and employs a metadata schema based on DCAT-AP CH properties to enhance data discovery.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\n\n\nPublic-Law Body: The Open Data Portal of Geneva Public Transport (opendata.tpg) was launched in 2022. Building on an initiative that started in 2015 with real-time transit data, it supports multiple download formats (including DCAT in RDF/XML and JSON) to promote transparency and citizen participation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\n\n\nPublic-Law Body: opentransportdata.swiss is the customer information platform for Swiss public transport and individual mobility.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\nlinked data\n\n\n\nEU: European Data is the official portal for European open data, launched in 2021 after a beta phase starting in 2015. It features datasets with DCAT-AP metadata, multiple APIs (including an SPARQL endpoint), and has its source code available on GitLab.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\n\n\nUSA: DATA.GOV is the U.S. Government’s central portal for open data, launched in 2009. It provides access to datasets from various federal agencies using open source applications like CKAN, and employs the DCAT-US Schema v1.1 for metadata.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfoundation\n\n\n\nGlobal: Founded in 2011, the Open Knowledge Network is a global foundation dedicated to creating a fair, sustainable, and open digital future. It connects multiple chapters, members, and contributors worldwide to promote open knowledge.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nassociation\n\n\n\nAssociation: Open Research Data is a community-driven initiative dedicated to promoting open research data practices in Switzerland. It provides resources, guidelines, and networking opportunities for researchers and institutions, helping to advance the culture of open science and data sharing.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nassociation\n\n\n\nCommunity: opendata.ch is the Swiss Open Data Association—the Swiss chapter of the Open Knowledge Network. Since its inception in 2011, it has supported and coordinated open data initiatives across Switzerland, including a dedicated working group for the cultural heritage sector (OpenGLAM).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nassociation\n\n\n\nUnit: The ORD Unit of the Swiss Academies of Arts and Sciences implements the Swiss National Action Plan for Open Research Data and serves as a representative for Open Science topics.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nassociation\n\n\n\nCommunity: GeoBeer is a roughly quarterly meetup of people interested in geography, GIS, cartography and the latest technologies. This Swiss initiative exists since 2013.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nassociation\n\n\n\nCommunity: Since 2018, Open Data Beer has organised community events that bring together open data practitioners from across Switzerland. Supported by organisations such as the Federal Statistical Office, various cantons, and SBB CFF FFS, these events foster innovation and collaboration.\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Open Data Platforms and Organisations"
    ]
  },
  {
    "objectID": "sections/platforms.html#platforms-and-organisations",
    "href": "sections/platforms.html#platforms-and-organisations",
    "title": "Open Data Platforms and Organisations",
    "section": "",
    "text": "This page features a curated selection of open data platforms and organisations, with a particular emphasis on Switzerland. You can explore various initiatives—ranging from research data repositories like the Registry of Research Data Repositories, SwissUbase, and DaSCH Service Platform to open government data portals such as opendata.swiss, LINDAS Open Data Basel-Stadt, Stadt Zürich Open Data, and the Open Data Portal of Geneva Public Transport.\nIn addition, learn more about community-driven organisations like the Open Knowledge Network, Open Research Data National Strategy Council opendata.ch, and Open Data Beer.\nIt should also be noted that every February around Valentine’s Day, International Love Data Week brings together data enthusiasts around the world - mostly in academia - to explore best practices in data management, sharing and reuse. For example:\n\nSwiss Research Data Support Network (SRDSN): https://www.researchdatasupport.ch/lovedata\nBasel University Library Love Data Week 2026: https://researchdata.unibas.ch/en/news/details/love-data-week-2026/\nUniversity of Geneva Love Data Week 2026: https://www.unige.ch/researchdata/propos/actualites/love-data-week-2026\nFDM im deutschsprachigen Raum: https://forschungsdaten.info/fdm-im-deutschsprachigen-raum/love-data-week-2026/\nUniversity of Michigan - International Love Data Week: https://www.icpsr.umich.edu/sites/icpsr/about/news-events/international-love-data-week.\n\nFor more information about OGD in Switzerland, please see this curated and exhaustive list on GitHub: https://github.com/rnckp/awesome-ogd-switzerland.\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Categories\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\nord\n\n\n\nRegistry: Launched in 2012, this comprehensive registry of research data repositories provides embeddable tools and detailed metadata—including data accessibility, licensing, persistent identifiers, and certification information. All metadata is available under a CC0 license and accessible via an API.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nord\n\n\n\nCross-disciplinary: SwissUbase is a national solution primarily serving the social sciences and linguistics. Operated by FORS, it was launched in 2021 to replace FORSbase and features its own metadata schema for studies, datasets, and data files with Digital Object Identifier (DOI) support at the dataset level.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niiif\n\nlinked data\n\nord\n\n\n\nHumanities: The DaSCH Service Platform is a national research infrastructure dedicated to preserving long-term humanities data. The DaSCH – Swiss National Data and Service Center for the Humanities was initiated by the University of Basel’s Digital Humanities Lab. In 2017, DaSCH was established as a national facility operated by the Swiss Academy of Humanities and Social Sciences (SAGW). Since 2021, it has operated as a national research data infrastructure primarily funded by the Swiss National Science Foundation (SNSF). The platform employs a core ontology (Knora) and provides modern APIs (RESTful JSON-LD and IIIF Image API) along with Archival Resource Keys (ARKs).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nord\n\n\n\nCross-institutional: OLOS is a consultation and archive portal developed under the Data Life-Cycle Management (DLCM) project. It serves multiple institutions and utilizes the Datacite Metadata Schema with DOI assignment at the dataset level.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\niiif\n\nlinked data\n\nord\n\n\n\nInstitutional: Yareta is the research data repository developed for Geneva’s higher education institutions. Launched in 2019 and built upon the OLOS platform, it is tailored to manage institutional research data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nord\n\n\n\nGeneric: Developed at CERN, Zenodo is a generalist repository that allows anyone to deposit data. It supports DOI assignment for each version of deposited data, making it a versatile platform for researchers in any discipline.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\n\n\nNational/Registry: opendata.swiss is the central portal for open government data in Switzerland, managed by the Federal Statistical Office (FSO). Originally launched in 2013 by the Swiss Federal Archives as opendata.admin.ch and rebranded in 2016, it aggregates metadata via a JSON API and an XML file compliant with the DCAT-AP CH standard.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlinked data\n\nogd\n\n\n\nLinked Data Service: the service allows public administrations to publish their data in the form of Knowledge Graphs. LINDAS was built between 2017 and 2020 in the Linked Data Platform project of the Swiss Federal Archives (SFA) with the support of the State Secretariat for Economic Affairs (SECO) and in close collaboration with the Federal Office for the Environment (FOEN).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlinked data\n\nogd\n\n\n\nVisualisation: The visualize.admin.ch portal enables the visualisation of Swiss Open Government Data provided by LINDAS, which can then be easily downloaded or integrated into websites and updated automatically. It is operated by the FOEN.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\n\n\nCantonal: Open Data Basel-Stadt is the cantonal portal for open government data from Basel-Stadt. Officially launched in 2019 following a pilot phase, it features a dedicated dashboard, its own metadata schema combining DCAT and DCAT-AP CH properties, and a JSON API.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\n\n\nMunicipal: Launched in 2012, Stadt Zürich Open Data is recognized as Switzerland’s first open government data platform. It provides (Geo)JSON APIs, dedicated GitHub scripts, and employs a metadata schema based on DCAT-AP CH properties to enhance data discovery.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\n\n\nPublic-Law Body: The Open Data Portal of Geneva Public Transport (opendata.tpg) was launched in 2022. Building on an initiative that started in 2015 with real-time transit data, it supports multiple download formats (including DCAT in RDF/XML and JSON) to promote transparency and citizen participation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\n\n\nPublic-Law Body: opentransportdata.swiss is the customer information platform for Swiss public transport and individual mobility.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\nlinked data\n\n\n\nEU: European Data is the official portal for European open data, launched in 2021 after a beta phase starting in 2015. It features datasets with DCAT-AP metadata, multiple APIs (including an SPARQL endpoint), and has its source code available on GitLab.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\n\n\nUSA: DATA.GOV is the U.S. Government’s central portal for open data, launched in 2009. It provides access to datasets from various federal agencies using open source applications like CKAN, and employs the DCAT-US Schema v1.1 for metadata.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfoundation\n\n\n\nGlobal: Founded in 2011, the Open Knowledge Network is a global foundation dedicated to creating a fair, sustainable, and open digital future. It connects multiple chapters, members, and contributors worldwide to promote open knowledge.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nassociation\n\n\n\nAssociation: Open Research Data is a community-driven initiative dedicated to promoting open research data practices in Switzerland. It provides resources, guidelines, and networking opportunities for researchers and institutions, helping to advance the culture of open science and data sharing.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nassociation\n\n\n\nCommunity: opendata.ch is the Swiss Open Data Association—the Swiss chapter of the Open Knowledge Network. Since its inception in 2011, it has supported and coordinated open data initiatives across Switzerland, including a dedicated working group for the cultural heritage sector (OpenGLAM).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nassociation\n\n\n\nUnit: The ORD Unit of the Swiss Academies of Arts and Sciences implements the Swiss National Action Plan for Open Research Data and serves as a representative for Open Science topics.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nassociation\n\n\n\nCommunity: GeoBeer is a roughly quarterly meetup of people interested in geography, GIS, cartography and the latest technologies. This Swiss initiative exists since 2013.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nassociation\n\n\n\nCommunity: Since 2018, Open Data Beer has organised community events that bring together open data practitioners from across Switzerland. Supported by organisations such as the Federal Statistical Office, various cantons, and SBB CFF FFS, these events foster innovation and collaboration.\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Open Data Platforms and Organisations"
    ]
  },
  {
    "objectID": "sections/showcases.html",
    "href": "sections/showcases.html",
    "title": "Showcases",
    "section": "",
    "text": "Open data enables innovative applications and services across various domains. The following showcases highlight different platforms and projects that leverage open data for public benefit, research, and digital engagement.\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Categories\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\nord\n\n\n\nOur World in Data is a collaborative effort between researchers at the University of Oxford and the non-profit organisation Global Change Data Lab (GCDL). It is a comprehensive online resource that presents empirical research and data on a wide array of global issues, focusing on large-scale problems like poverty, disease, hunger, climate change, war, existential risks, and inequality. The platform aims to provide accessible, comprehensible, and transparent data to inform readers about the state of the world and to support informed decision-making.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhealth\n\nogd\n\n\n\nThe IDD is managed by the Federal Office of Public Health (FOPH). The IDD provides information on cases of infection and illness in Switzerland and the Principality of Liechtenstein caused by various pathogens.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\nsport\n\n\n\nThe sports facility finder shows sports and exercise facilities operated by the canton of Basel-Stadt as well as all cantonal sports facilities outside the cantonal and national borders. The dataset also lists cantonal premises that are used and rented for sports activities.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nord\n\nogd\n\nlinked data\n\n\n\nThe SWITCH Open Data Navigator is a discovery platform that aggregates and transforms metadata from various open data providers to make it better discoverable for researchers and students. It focuses on open data that are not generated in research processes but are relevant for research activities, especially those involving multiple disciplinary fields.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\npolitics\n\n\n\nManaged by the Federal Statistical Office where results of popular votes in Switzerland are continuously updated.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nretail pricing\n\nscraping\n\n\n\nLaunched in 2023 by Mario Zechner, this platform offers a comprehensive comparison of food prices across various supermarkets in Austria, tracking and analysing price trends over time.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncultural heritage\n\ngaming\n\niiif\n\n\n\nAn innovative tool that allows players to integrate virtual art into the Animal Crossing: New Horizons game. It enables users to turn any image from the Getty Museum’s open-access collection (as well as any IIIF-compliant images) into in-game artwork.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncultural heritage\n\ngeoreferencing\n\niiif\n\nlinked data\n\n\n\nAn interactive platform launched in 2020 by the J. Paul Getty Trust to explore Sunset Boulevard through 60 years of Ed Ruscha’s photography (1965–2007). The 65,000 images are IIIF-compliant and linked to the Getty Research Institute.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncultural heritage\n\niiif\n\nlinked data\n\n\n\nLUX provides a unified gateway to over 41 million cultural heritage resources from the Yale University Library, Yale Center for British Art, Yale Peabody Museum, and Yale University Art Gallery. It is built on open standards such as Linked Art, IIIF, and W3C Activity Streams.\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Showcases"
    ]
  },
  {
    "objectID": "sections/showcases.html#showcases",
    "href": "sections/showcases.html#showcases",
    "title": "Showcases",
    "section": "",
    "text": "Open data enables innovative applications and services across various domains. The following showcases highlight different platforms and projects that leverage open data for public benefit, research, and digital engagement.\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Categories\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\nord\n\n\n\nOur World in Data is a collaborative effort between researchers at the University of Oxford and the non-profit organisation Global Change Data Lab (GCDL). It is a comprehensive online resource that presents empirical research and data on a wide array of global issues, focusing on large-scale problems like poverty, disease, hunger, climate change, war, existential risks, and inequality. The platform aims to provide accessible, comprehensible, and transparent data to inform readers about the state of the world and to support informed decision-making.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nhealth\n\nogd\n\n\n\nThe IDD is managed by the Federal Office of Public Health (FOPH). The IDD provides information on cases of infection and illness in Switzerland and the Principality of Liechtenstein caused by various pathogens.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\nsport\n\n\n\nThe sports facility finder shows sports and exercise facilities operated by the canton of Basel-Stadt as well as all cantonal sports facilities outside the cantonal and national borders. The dataset also lists cantonal premises that are used and rented for sports activities.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nord\n\nogd\n\nlinked data\n\n\n\nThe SWITCH Open Data Navigator is a discovery platform that aggregates and transforms metadata from various open data providers to make it better discoverable for researchers and students. It focuses on open data that are not generated in research processes but are relevant for research activities, especially those involving multiple disciplinary fields.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nogd\n\npolitics\n\n\n\nManaged by the Federal Statistical Office where results of popular votes in Switzerland are continuously updated.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nretail pricing\n\nscraping\n\n\n\nLaunched in 2023 by Mario Zechner, this platform offers a comprehensive comparison of food prices across various supermarkets in Austria, tracking and analysing price trends over time.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncultural heritage\n\ngaming\n\niiif\n\n\n\nAn innovative tool that allows players to integrate virtual art into the Animal Crossing: New Horizons game. It enables users to turn any image from the Getty Museum’s open-access collection (as well as any IIIF-compliant images) into in-game artwork.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncultural heritage\n\ngeoreferencing\n\niiif\n\nlinked data\n\n\n\nAn interactive platform launched in 2020 by the J. Paul Getty Trust to explore Sunset Boulevard through 60 years of Ed Ruscha’s photography (1965–2007). The 65,000 images are IIIF-compliant and linked to the Getty Research Institute.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncultural heritage\n\niiif\n\nlinked data\n\n\n\nLUX provides a unified gateway to over 41 million cultural heritage resources from the Yale University Library, Yale Center for British Art, Yale Peabody Museum, and Yale University Art Gallery. It is built on open standards such as Linked Art, IIIF, and W3C Activity Streams.\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Showcases"
    ]
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "This course introduces the foundational principles of Open Data, equipping undergraduate students in Information Science with the knowledge and skills to find, analyse, and effectively reuse open datasets. Through a combination of lectures, practical activities, and assignments, students will explore the benefits and challenges of Open Data and develop a deeper understanding of its potential applications and implications. It is designed with the following objectives:\n\nTo gain an understanding of Open Data, its essential aspects, and the principles of opening data;\nto learn how to find, analyse, and reuse open datasets;\nto learn the processes involved in preparing and publishing open datasets.\n\nThese objectives provide the foundation for the course and guide the learning outcomes."
  },
  {
    "objectID": "syllabus.html#learning-objectives",
    "href": "syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "",
    "text": "This course introduces the foundational principles of Open Data, equipping undergraduate students in Information Science with the knowledge and skills to find, analyse, and effectively reuse open datasets. Through a combination of lectures, practical activities, and assignments, students will explore the benefits and challenges of Open Data and develop a deeper understanding of its potential applications and implications. It is designed with the following objectives:\n\nTo gain an understanding of Open Data, its essential aspects, and the principles of opening data;\nto learn how to find, analyse, and reuse open datasets;\nto learn the processes involved in preparing and publishing open datasets.\n\nThese objectives provide the foundation for the course and guide the learning outcomes."
  },
  {
    "objectID": "syllabus.html#content",
    "href": "syllabus.html#content",
    "title": "Syllabus",
    "section": "Content",
    "text": "Content\nThe topics covered in this course include:\n\nBackground on open data;\nBenefits and risks of opening data;\nModels related to using and publishing open data."
  },
  {
    "objectID": "syllabus.html#methods",
    "href": "syllabus.html#methods",
    "title": "Syllabus",
    "section": "Methods",
    "text": "Methods\nThe course employs the following methods to support learning:\n\nCourse presentations;\nExploration of online services;\nHands-on exercises;\nEngagement with scholarly literature.\n\nThese methods are intended to foster both theoretical understanding and practical application of the course material."
  },
  {
    "objectID": "syllabus.html#course-outline-2025-2026",
    "href": "syllabus.html#course-outline-2025-2026",
    "title": "Syllabus",
    "section": "Course Outline (2025-2026)",
    "text": "Course Outline (2025-2026)\nAn exam will be held at the end of the fourth and final session. It will consist of multiple-choice and open-ended questions, will last a maximum of one hour, and will be conducted through Cyberlearn. All course notes and access to the internet are permitted. However, LLM and communication tools are not permitted.\n\n\n\nDate\nContent\n\n\n\n\n18.02.2026\nCourse OverviewCharacteristics of Open DataExercise 1: OA Deep DiveAssociated MovementsAssociated PrinciplesExercise 2: Up to date with Linked Data\n\n\n25.02.2026\nExercise 3: Movements and PrinciplesOpen Data Platforms and OrganisationsExercise 4: Comparing ORD PlatformsExercise 5: The Reuser’s Perspective (OGD)Exercise 6: Reading Assignment\n\n\n04.03.2026\nExercise 6: Reading Assignment (Follow-up)Assessment, Data Quality, and Best PracticesTechniques, Software, and ToolsExercise 7: Open RefineExercise 8: IIIF & ML\n\n\n11.03.2026\nExercise 8: IIIF & ML (Follow-up)ShowcasesCourse RecapExamination (multiple-choice and open-ended)\n\n\n\n\n\n\n\n\n\nWarningMissed Examination Policy\n\n\n\nIf a student is absent during the last session and misses the examination for legitimate reasons, a substitute assignment will be organised by the tutor."
  },
  {
    "objectID": "principles-slides.html#fair-data-principles",
    "href": "principles-slides.html#fair-data-principles",
    "title": "Associated Principles",
    "section": "FAIR Data Principles",
    "text": "FAIR Data Principles\n\nhttps://www.go-fair.org/fair-principles/\n\nThe FAIR principles were published in 2016 to improve the Findability, Accessibility, Interoperability, and Reusability of digital assets."
  },
  {
    "objectID": "principles-slides.html#fair-findable",
    "href": "principles-slides.html#fair-findable",
    "title": "Associated Principles",
    "section": "FAIR: Findable",
    "text": "FAIR: Findable\n\nF1. (Meta)data are assigned a globally unique and persistent identifier\nF2. Data are described with rich metadata (defined by R1)\nF3. Metadata clearly and explicitly include the identifier of the data they describe\nF4. (Meta)data are registered or indexed in a searchable resource\n\n\nFindability ensures that both humans and machines can discover data and metadata."
  },
  {
    "objectID": "principles-slides.html#fair-accessible",
    "href": "principles-slides.html#fair-accessible",
    "title": "Associated Principles",
    "section": "FAIR: Accessible",
    "text": "FAIR: Accessible\n\nA1. (Meta)data are retrievable by their identifier using a standardised communications protocol\n\nA1.1 The protocol is open, free, and universally implementable\nA1.2 The protocol allows for an authentication and authorisation procedure, where necessary\n\nA2. Metadata are accessible, even when the data are no longer available\n\n\nAccessibility means data can be retrieved through standard protocols, even with proper authentication when needed."
  },
  {
    "objectID": "principles-slides.html#fair-interoperable",
    "href": "principles-slides.html#fair-interoperable",
    "title": "Associated Principles",
    "section": "FAIR: Interoperable",
    "text": "FAIR: Interoperable\n\nI1. (Meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation\nI2. (Meta)data use vocabularies that follow FAIR principles\nI3. (Meta)data include qualified references to other (meta)data\n\n\nInteroperability enables data to work with applications and workflows for analysis, storage, and processing."
  },
  {
    "objectID": "principles-slides.html#fair-reusable",
    "href": "principles-slides.html#fair-reusable",
    "title": "Associated Principles",
    "section": "FAIR: Reusable",
    "text": "FAIR: Reusable\n\nR1. (Meta)data are richly described with a plurality of accurate and relevant attributes\n\nR1.1. (Meta)data are released with a clear and accessible data usage licence\nR1.2. (Meta)data are associated with detailed provenance\nR1.3. (Meta)data meet domain-relevant community standards\n\n\n\nReusability ensures data can be used in future research with clear licensing and provenance information."
  },
  {
    "objectID": "principles-slides.html#care-principles",
    "href": "principles-slides.html#care-principles",
    "title": "Associated Principles",
    "section": "CARE Principles",
    "text": "CARE Principles\n\nCARE Principles for Indigenous Data Governance\nhttps://www.gida-global.org/care\n\nCARE principles complement FAIR by addressing people and purpose in data governance, particularly for Indigenous data."
  },
  {
    "objectID": "principles-slides.html#care-collective-benefit",
    "href": "principles-slides.html#care-collective-benefit",
    "title": "Associated Principles",
    "section": "CARE: Collective Benefit",
    "text": "CARE: Collective Benefit\n\nC1. For inclusive development and innovation\nC2. For improved governance and citizen engagement\nC3. For equitable outcomes\n\n\nData ecosystems should be designed to support Indigenous peoples’ rights and wellbeing."
  },
  {
    "objectID": "principles-slides.html#care-authority-to-control",
    "href": "principles-slides.html#care-authority-to-control",
    "title": "Associated Principles",
    "section": "CARE: Authority to Control",
    "text": "CARE: Authority to Control\n\nA1. Recognising rights and interests\nA2. Data for governance\nA3. Governance of data\n\n\nIndigenous peoples have the right to govern data about their communities, territories, and resources."
  },
  {
    "objectID": "principles-slides.html#care-responsibility",
    "href": "principles-slides.html#care-responsibility",
    "title": "Associated Principles",
    "section": "CARE: Responsibility",
    "text": "CARE: Responsibility\n\nR1. For positive relationships\nR2. For expanding capability and capacity\nR3. For Indigenous languages and worldviews\n\n\nThose working with Indigenous data have responsibilities to share benefits and ensure respectful use."
  },
  {
    "objectID": "principles-slides.html#care-ethics",
    "href": "principles-slides.html#care-ethics",
    "title": "Associated Principles",
    "section": "CARE: Ethics",
    "text": "CARE: Ethics\n\nE1. For minimising harm and maximising benefit\nE2. For justice\nE3. For future use\n\n\nIndigenous data should be used ethically to advance justice and support Indigenous innovation."
  },
  {
    "objectID": "principles-slides.html#operationalising-care-and-fair",
    "href": "principles-slides.html#operationalising-care-and-fair",
    "title": "Associated Principles",
    "section": "Operationalising CARE and FAIR",
    "text": "Operationalising CARE and FAIR\n\n\nCARE and FAIR work together: FAIR focuses on data characteristics, CARE focuses on people and purpose."
  },
  {
    "objectID": "principles-slides.html#collections-as-data",
    "href": "principles-slides.html#collections-as-data",
    "title": "Associated Principles",
    "section": "Collections as Data",
    "text": "Collections as Data\n\nSummits:\n\n2017: Santa Barbara Statement\n2023: Vancouver Statement\n\nMain Outputs:\n\n10 principles\n‘Part to Whole’ Report\nChecklist and initiatives\n\nhttps://collectionsasdata.github.io/\n\nCollections as Data encourages computational use of digitised and born-digital collections."
  },
  {
    "objectID": "principles-slides.html#collections-as-data-principles-1-6",
    "href": "principles-slides.html#collections-as-data-principles-1-6",
    "title": "Associated Principles",
    "section": "Collections as Data: Principles 1-6",
    "text": "Collections as Data: Principles 1-6\n\nCollections as Data development aims to encourage computational use of collections\nStewards are guided by ongoing ethical commitments\nStewards aim to lower barriers to use\nDesigned for everyone serves no one\nShared documentation helps others find a path to doing the work\nShould be made openly accessible by default, except where ethical or legal obligations preclude it\n\n\nThe first six principles focus on access, ethics, and user needs."
  },
  {
    "objectID": "principles-slides.html#collections-as-data-principles-7-10",
    "href": "principles-slides.html#collections-as-data-principles-7-10",
    "title": "Associated Principles",
    "section": "Collections as Data: Principles 7-10",
    "text": "Collections as Data: Principles 7-10\n\nDevelopment values interoperability\nStewards work transparently to develop trustworthy, long-lived collections\nData as well as the data that describe those data are considered in scope\nDevelopment is an ongoing process and does not necessarily conclude with a final version\n\n\nThe remaining principles emphasise interoperability, transparency, and iterative development."
  },
  {
    "objectID": "principles-slides.html#collections-as-data-part-to-whole",
    "href": "principles-slides.html#collections-as-data-part-to-whole",
    "title": "Associated Principles",
    "section": "Collections as Data: Part to Whole",
    "text": "Collections as Data: Part to Whole\n\n\nKey Concepts:\n\nBoundary Object concept\nEthical considerations\nCommunity engagement\nOrganisational support\n\n\nFuture Challenges:\n\nAI integration\nGlobal vs local balance\nResource limitations\nAI training considerations\n\n\n\nThe Part to Whole report explores how collections-as-data serve as flexible tools adaptable to various needs."
  },
  {
    "objectID": "principles-slides.html#collections-as-data-glam-checklist",
    "href": "principles-slides.html#collections-as-data-glam-checklist",
    "title": "Associated Principles",
    "section": "Collections as Data: GLAM Checklist",
    "text": "Collections as Data: GLAM Checklist\n\nClear licence allowing reuse\nCitation suggestion\nDataset documentation\nPublic platform\nUsage examples\nStructured dataset\nMachine-readable metadata\nCollaborative platforms\nAPI access\nPortal page\nTerms of use\n\n\nThis checklist provides practical guidance for GLAM institutions publishing collections as data."
  },
  {
    "objectID": "principles-slides.html#linked-data",
    "href": "principles-slides.html#linked-data",
    "title": "Associated Principles",
    "section": "Linked Data",
    "text": "Linked Data\n\nThe [World Wide Web] project merges the techniques of information retrieval and hypertext to make an easy but powerful global information system. The project started with the philosophy that much academic information should be freely available to anyone.\n\n— Tim Berners-Lee, 1991\n\nThe Web was conceived with open access to information as a core principle."
  },
  {
    "objectID": "principles-slides.html#linked-data-principles",
    "href": "principles-slides.html#linked-data-principles",
    "title": "Associated Principles",
    "section": "Linked Data Principles",
    "text": "Linked Data Principles\n\nUse URIs as names for things\nUse HTTP URIs so that people can look up those names\nWhen someone looks up a URI, provide useful information using standards (RDF, RDFS, SPARQL)\nInclude links to other URIs so that they can discover more things\n\n— Tim Berners-Lee, 2006\n\nThese four principles enable data to be connected and discoverable on the Web."
  },
  {
    "objectID": "principles-slides.html#linked-open-data-lod",
    "href": "principles-slides.html#linked-open-data-lod",
    "title": "Associated Principles",
    "section": "Linked Open Data (LOD)",
    "text": "Linked Open Data (LOD)\n\n5-star deployment scheme for Open Data\nhttps://5stardata.info/\n\nThe 5-star model provides a roadmap from basic open data to fully linked open data."
  },
  {
    "objectID": "principles-slides.html#the-semantic-web",
    "href": "principles-slides.html#the-semantic-web",
    "title": "Associated Principles",
    "section": "The Semantic Web",
    "text": "The Semantic Web\n\nThe Semantic Web extends the World Wide Web through standards to make it machine-readable\n\nThe Semantic Web layer cake shows the technologies that enable machine-readable data."
  },
  {
    "objectID": "principles-slides.html#resource-description-framework-rdf",
    "href": "principles-slides.html#resource-description-framework-rdf",
    "title": "Associated Principles",
    "section": "Resource Description Framework (RDF)",
    "text": "Resource Description Framework (RDF)\nEverything in threes: subject, predicate, object \\((s \\ \\vec{p} \\ o)\\)\n\n\nRDF uses triples to create graphs of linked data with URIs for most components."
  },
  {
    "objectID": "principles-slides.html#linked-open-usable-data-loud",
    "href": "principles-slides.html#linked-open-usable-data-loud",
    "title": "Associated Principles",
    "section": "Linked Open Usable Data (LOUD)",
    "text": "Linked Open Usable Data (LOUD)\nLOUD extends LOD by emphasising usability\n\nCoined by Robert Sanderson (2018, 2019)\nGoal: Achieve the Semantic Web’s intent on a global scale in a usable fashion\nLeverages community-driven and JSON-LD-based specifications\nFive design principles for developer accessibility\n\n\nLOUD makes linked data more accessible to software developers and end users."
  },
  {
    "objectID": "principles-slides.html#loud-design-principles",
    "href": "principles-slides.html#loud-design-principles",
    "title": "Associated Principles",
    "section": "LOUD Design Principles",
    "text": "LOUD Design Principles\n\nThe right Abstraction for the audience\nFew Barriers to entry\nComprehensible by introspection\nDocumentation with working examples\nFew Exceptions, instead many consistent patterns\n\nhttps://linked.art/loud/\n\nThese principles guide the development of usable linked data specifications."
  },
  {
    "objectID": "principles-slides.html#loud-communities",
    "href": "principles-slides.html#loud-communities",
    "title": "Associated Principles",
    "section": "LOUD Communities",
    "text": "LOUD Communities\n\n\nKey Characteristics:\n\nSynergy of social and technical integration\nShared expertise and leadership\nCollaboration across boundaries\nInclusivity and diversity\n\n\nCore Values:\n\nOpenness and friendliness\nTransparency\nOnline and face-to-face meetings\n\n\n\nLOUD communities like IIIF and Linked Art combine strong technical standards with welcoming social practices."
  },
  {
    "objectID": "principles-slides.html#loud-standards",
    "href": "principles-slides.html#loud-standards",
    "title": "Associated Principles",
    "section": "LOUD Standards",
    "text": "LOUD Standards\nThree main specifications follow LOUD principles:\n\nInternational Image Interoperability Framework (IIIF)\nW3C Web Annotation Data Model\nLinked Art\n\nAll use JSON-LD and emphasise developer experience\n\nThese standards demonstrate how LOUD principles can be applied in practice."
  },
  {
    "objectID": "principles-slides.html#iiif-overview",
    "href": "principles-slides.html#iiif-overview",
    "title": "Associated Principles",
    "section": "IIIF Overview",
    "text": "IIIF Overview\n\n\nA model for presenting and annotating content\nA global community developing shared APIs\nImplements software and exposes interoperable content\n\nhttps://iiif.io\n\nIIIF solves the problem of image delivery silos through standardised APIs."
  },
  {
    "objectID": "principles-slides.html#iiif-the-problem",
    "href": "principles-slides.html#iiif-the-problem",
    "title": "Associated Principles",
    "section": "IIIF: The Problem",
    "text": "IIIF: The Problem\n\n\nBefore IIIF:\n\nSiloed image repositories\nDuplication of efforts\nProprietary viewers\nLimited interoperability\n\n\nWith IIIF:\n\nShared infrastructure\nReusable viewers\nInteroperable resources\nGlobal collaboration\n\n\n\nIIIF eliminates the need for each institution to build custom image delivery systems."
  },
  {
    "objectID": "principles-slides.html#iiif-capabilities",
    "href": "principles-slides.html#iiif-capabilities",
    "title": "Associated Principles",
    "section": "IIIF Capabilities",
    "text": "IIIF Capabilities\n\n\n\nDeep zoom with large images\nCompare images\nReunify scattered collections\nSearch within\n\n\n\nStorytelling\nCrowdsourcing\nMachine-generated annotations\nBeyond images (A/V)\n\n\n\nIIIF enables rich interactions with cultural heritage materials."
  },
  {
    "objectID": "principles-slides.html#iiif-specifications",
    "href": "principles-slides.html#iiif-specifications",
    "title": "Associated Principles",
    "section": "IIIF Specifications",
    "text": "IIIF Specifications\nCore APIs:\n\nImage API - Delivers images with region, size, rotation parameters\nPresentation API - Provides structural metadata for viewing\n\nAdditional APIs:\n\nAuthorization Flow, Change Discovery, Content Search, Content State\n\nhttps://iiif.io/api\n\nIIIF’s modular API design allows implementations to choose what they need."
  },
  {
    "objectID": "principles-slides.html#iiif-image-api",
    "href": "principles-slides.html#iiif-image-api",
    "title": "Associated Principles",
    "section": "IIIF Image API",
    "text": "IIIF Image API\n\nURI Syntax:\n{scheme}://{server}{/prefix}/{identifier}/{region}/{size}/{rotation}/{quality}.{format}\nExample:\nhttps://iiif.dasch.swiss/.../full/1000,/0/default.jpg\n\nThe Image API uses URI parameters to deliver images on demand."
  },
  {
    "objectID": "principles-slides.html#iiif-presentation-api",
    "href": "principles-slides.html#iiif-presentation-api",
    "title": "Associated Principles",
    "section": "IIIF Presentation API",
    "text": "IIIF Presentation API\n\nProvides structural metadata using JSON-LD for:\n\nCollections\nManifests\nCanvases\nAnnotation Pages\n\n\nThe Presentation API describes how to display and navigate cultural heritage objects."
  },
  {
    "objectID": "principles-slides.html#web-annotation-data-model",
    "href": "principles-slides.html#web-annotation-data-model",
    "title": "Associated Principles",
    "section": "Web Annotation Data Model",
    "text": "Web Annotation Data Model\n\nThree-part structure:\n\nTarget: The resource being annotated\nBody: The annotation content\nAnnotation: Links body and target\n\nhttps://www.w3.org/TR/annotation-model/\n\nThe W3C Web Annotation model provides a standard way to associate content with resources."
  },
  {
    "objectID": "principles-slides.html#linked-art",
    "href": "principles-slides.html#linked-art",
    "title": "Associated Principles",
    "section": "Linked Art",
    "text": "Linked Art\n\nA community and CIDOC Working Group defining:\n\nMetadata application profile for cultural heritage\nTechnical means for convenient interaction (API)\n\nhttps://linked.art\n\nLinked Art applies LOUD principles to art museum data."
  },
  {
    "objectID": "principles-slides.html#linked-art-data-model",
    "href": "principles-slides.html#linked-art-data-model",
    "title": "Associated Principles",
    "section": "Linked Art Data Model",
    "text": "Linked Art Data Model\n\n\n\nLevel\nTechnology\n\n\n\n\nConceptual Model\nCIDOC-CRM\n\n\nOntology\nRDF encoding of CRM 7.1 + extensions\n\n\nVocabulary\nGetty AAT, TGN, ULAN\n\n\nProfile\nObject-based cultural heritage\n\n\nAPI\nJSON-LD 1.1, REST\n\n\n\n\nLinked Art builds on established cultural heritage standards with a focus on usability."
  },
  {
    "objectID": "principles-slides.html#linked-art-community",
    "href": "principles-slides.html#linked-art-community",
    "title": "Associated Principles",
    "section": "Linked Art Community",
    "text": "Linked Art Community\nMajor Institutions:\n\nThe Metropolitan Museum of Art\nJ. Paul Getty Trust\nYale University\nSmithsonian Institution\nEuropeana\nVictoria and Albert Museum\nAnd many more…\n\n\nLinked Art has strong institutional support from leading museums and cultural organisations."
  },
  {
    "objectID": "principles-slides.html#linked-art-overview",
    "href": "principles-slides.html#linked-art-overview",
    "title": "Associated Principles",
    "section": "Linked Art Overview",
    "text": "Linked Art Overview\n\n\nLinked Art models the full lifecycle of cultural heritage objects and related entities."
  },
  {
    "objectID": "principles-slides.html#iiif-and-linked-art-integration",
    "href": "principles-slides.html#iiif-and-linked-art-integration",
    "title": "Associated Principles",
    "section": "IIIF and Linked Art Integration",
    "text": "IIIF and Linked Art Integration\n\nComplementary roles:\n\nIIIF for digital access\nLinked Art for semantic description\n\n\nIIIF and Linked Art work together to provide both access and rich metadata."
  },
  {
    "objectID": "principles-slides.html#loud-infrastructure-example",
    "href": "principles-slides.html#loud-infrastructure-example",
    "title": "Associated Principles",
    "section": "LOUD Infrastructure Example",
    "text": "LOUD Infrastructure Example\n\n\nLOUD standards enable sophisticated infrastructure for cultural heritage access and research."
  },
  {
    "objectID": "principles-slides.html#loud-in-a-nutshell",
    "href": "principles-slides.html#loud-in-a-nutshell",
    "title": "Associated Principles",
    "section": "LOUD in a Nutshell",
    "text": "LOUD in a Nutshell\n\nCommunity-driven: Grassroots development with transparency\nImplementation-focused: Specifications developed alongside working software\nSemantic interoperability: Even at the cost of ontological purity\nCommon denominators: For institutions, public bodies, and research projects\n\n\nLOUD practices enhance semantic interoperability across cultural heritage\n\n\nLOUD represents a pragmatic approach to linked data that prioritises usability and adoption."
  },
  {
    "objectID": "principles-slides.html#summary",
    "href": "principles-slides.html#summary",
    "title": "Associated Principles",
    "section": "Summary",
    "text": "Summary\n\n\nData Principles:\n\nFAIR for findability and reusability\nCARE for ethical Indigenous data governance\nCollections as Data for computational use\n\n\nTechnical Standards:\n\nLinked Data for connectivity\nLOUD for usability\nIIIF, Web Annotation, Linked Art as implementations\n\n\n\nThese principles and standards work together to enable open, ethical, and usable data"
  },
  {
    "objectID": "exercises/ex-04.html#comparing-ord-platforms",
    "href": "exercises/ex-04.html#comparing-ord-platforms",
    "title": "Exercise 4: Comparing ORD Platforms",
    "section": "",
    "text": "…"
  },
  {
    "objectID": "exercises/ex-05.html#the-reusers-perspective-ogd",
    "href": "exercises/ex-05.html#the-reusers-perspective-ogd",
    "title": "Exercise 5: The Reuser’s Perspective (OGD)",
    "section": "",
    "text": "(…)\n\n\n\nCreate a dashboard on visualize.admin.ch\n\n\n\nGo to the LINDAS SPARQL Endpoint."
  },
  {
    "objectID": "exercises/ex-08.html",
    "href": "exercises/ex-08.html",
    "title": "Exercise 8: IIIF & ML",
    "section": "",
    "text": "(…)"
  },
  {
    "objectID": "exercises/ex-08.html#iiif-ml",
    "href": "exercises/ex-08.html#iiif-ml",
    "title": "Exercise 8: IIIF & ML",
    "section": "",
    "text": "(…)"
  },
  {
    "objectID": "exercises/ex-07.html#open-refine",
    "href": "exercises/ex-07.html#open-refine",
    "title": "Exercise 7: Open Refine",
    "section": "",
    "text": "Install the software (https://openrefine.org/docs)\nRun it locally (accessible at http://127.0.0.1:3333/)\nHave a look at the different pages and functionalities\nCreate a new project by importing any supported files\n\n\n\n\n\nCreate a new project by importing the Powerhouse Museum TSV file (https://zenodo.org/records/17047254/files/phm_collection_adapted.tsv) — remember to select “Tab-separated values”\nWhitespace detection: Use Facet by blank on the categories column, then apply Edit cells &gt; Common transforms &gt; Trim leading and trailing whitespace. Observe how “blank” cells are revealed.\nClustering: Create a Text facet on the category column. Click Cluster and use the “key collision” method to merge case inconsistencies (e.g., “Pottery” vs “pottery”).\nMulti-valued cells: Split the categories column by the separator | (pipe character). Count how many objects have more than 3 categories, then rejoin the cells.\n\n\n\n\n\nCreate a new project by importing the Met Museum CSV (https://github.com/metmuseum/openaccess) — use the first 5,000 rows for better performance\nReconcile artists: Select the Artist Display Name column. Start reconciling against Wikidata (service: https://wikidata.reconci.link/en/api, type: Q5 for humans).\nJudgment exercise: Auto-match high confidence scores (&gt;90), manually review medium scores (70-90) to distinguish between homonyms (e.g., different “John Smith” artists), and mark low scores (&lt;70) as “None”.\nExtract QIDs: Transform reconciled cells to extract just the QID number for external linking.\n\n\n\n\n\nCreate a new project by importing the manuscript CSV from https://raw.githubusercontent.com/emmamorlock/workshop/refs/heads/main/exercices/handouts/biblissima.csv\nExplore manuscript metadata: Review columns such as shelfmark, repository, author, and title. Create text facets to identify variations in repository names or author attributions.\nReconcile shelfmarks: Use the Biblissima reconciliation endpoint (https://data.biblissima.fr/api/reconcile, type: Manuscript) to match records against the Biblissima authority file. This connects your local shelfmarks to persistent URIs.\nEnrich with IIIF (optional extension): After reconciliation, use Edit column &gt; Add column by fetching URLs to retrieve JSON data from the reconciled Biblissima URIs. Parse the JSON to extract iiif_manifest_url fields where available.\n\nCf. Sajdak (2024).\n\n\n\n\nCreate a new project by importing a Smithsonian JSON file (not CSV) from https://github.com/Smithsonian/OpenAccess\nFlatten nested JSON: Convert nested paths (e.g., title.content) to flat columns using the transform expression: value.parseJson()['title']\nExtract media: Parse the JSON to find objects with images by extracting online_media.mediaCount\nReconcile topics: Match topic fields against Library of Congress Subject Headings (LCSH) using their reconciliation service.\n\n\n\n\n\nExport your cleaned datasets in both CSV and JSON formats\nExport the project history (OpenRefine project archive) to document your transformation steps\n\nMore information and tutorials on OpenRefine can be found on the following links:\n\nLibrary Carpentry website: https://librarycarpentry.org/lc-open-refine/\nUniversity of Nevada Las Vegas: https://guides.library.unlv.edu/open-refine/getting-started\nUniversity of Illinois Urbana-Champaign: https://guides.library.illinois.edu/openrefine"
  },
  {
    "objectID": "exercises/ex-06.html#reading-assignment",
    "href": "exercises/ex-06.html#reading-assignment",
    "title": "Exercise 6: Reading Assignment",
    "section": "",
    "text": "(…)"
  }
]